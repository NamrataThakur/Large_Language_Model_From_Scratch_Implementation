[2026-01-30 05:20:56,626.626] Namespace(experiment_name='Pre-Train_Exp_CustomConfig_GQAarch_S_V1', data_path='tinystories', model_type='custom', base_modelName='gpt2_124M', model_name='gpt2_GQA_preTrain_S_V1', pre_save_model='gpt2_GQA_preTrain_S_V1.pth', tokenizer='tiktoken', seed=123, batch_size=16, target_batch_size=256, train_split=0.85, val_split=0.05, optimizer='AdamW', context_length=256, vocab_size=50257, embedding_dimension=512, num_heads=8, num_layers=8, dropout_rate=0.2, token_dropout_rate=0.03, attention_dropout_rate=0.2, ffn_dropout_rate=0.2, qkv_bias=False, ff_hidden_dim=1024, eval_batchSize=64, eval_freq=64, kv_cache=True, weight_decay=0.1, beta1=0.9, beta2=0.95, rms_eps=1e-06, rms_bias=True, theta_base=10000.0, num_kv_groups=4, num_experts=4, num_active_experts=2, max_training_length='model_context_length', max_new_tokens=50, temp=1.0, top_k=30, num_epochs=1, eos_id=50256, arch_type='GQA', train_type='scratch', moe_noise=True, use_warmup=True, use_gradient_clip=True, warmup_steps=0.05, initial_lr=3e-05, min_lr=1e-06, learning_rate=0.0003)
[2026-01-30 05:20:57,568.568] Model to be trained from scratch ..!
[2026-01-30 05:20:57,568.568] Custom GPT2 configuration to be used for pre-training..!
[2026-01-30 05:20:57,569.569] The custom config of the model to be trained : {'vocab_size': 50257, 'embedding_dimension': 512, 'num_heads': 8, 'context_length': 256, 'token_dropout': 0.03, 'attn_dropout': 0.2, 'ffn_dropout': 0.2, 'qkv_bias': False, 'num_layers': 8, 'ff_hidden_dim': 1024, 'rms_eps': 1e-06, 'rms_bias': True, 'theta_base': 10000.0, 'num_kv_groups': 4, 'num_experts': 4, 'num_active_experts': 2, 'moe_noise': True} 
[2026-01-30 05:20:58,179.179] Architecture Type :GQA
[2026-01-30 05:20:58,180.180] Configuration of the custom GPT2 model loaded..!
[2026-01-30 05:20:58,803.803] Total records in Train Data: 2119719 , Validation Data : 21990
[2026-01-30 05:20:58,807.807] Sample Text : One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with
[2026-01-30 05:20:58,807.807] ------------- Data Ingestion Completed. -------------
[2026-01-30 05:20:58,807.807] Loading the dataset class for pre-training...
[2026-01-30 05:20:58,855.855] Device Available: cuda .. ! 
[2026-01-30 05:36:26,287.287] ************** TRAIN DATALOADER ****************************
[2026-01-30 05:36:26,291.291] Length of Train Dataloader (number of batches): 264964
[2026-01-30 05:36:26,291.291] Total Train Tokens : 471872517
[2026-01-30 05:36:31,891.891] torch.Size([16, 256]), torch.Size([16, 256])
[2026-01-30 05:36:31,953.953] ************** VAL DATALOADER ****************************
[2026-01-30 05:36:31,953.953] Length of Val Dataloader (number of batches): 2748
[2026-01-30 05:36:31,953.953] Total Validation Tokens : 4743928
[2026-01-30 05:36:31,960.960] torch.Size([16, 256]), torch.Size([16, 256])
[2026-01-30 05:36:31,961.961] Dataloaders created successfully for pre-training task..!
[2026-01-30 05:36:31,961.961] ---------------------------------------------------------
[2026-01-30 05:36:31,961.961] Model will be trained from scratch..!
[2026-01-30 05:36:31,961.961] Loading the model with random weights for training..!
[2026-01-30 05:36:33,608.608] Model loaded with random weights for training..!
[2026-01-30 05:36:33,610.610] Model Size : 48.838144 millions (M)
[2026-01-30 05:36:33,611.611] Device Available: cuda .. ! 
[2026-01-30 05:36:34,904.904] Training Stage : Model sent to cuda for fine-tuning..!
[2026-01-30 05:36:34,905.905] Training Stage : Training of the model started ..!
[2026-01-30 05:36:38,064.064] Minimum LR : 2.9999999999999997e-05
[2026-01-30 05:36:38,064.064] Gradient Accumulation Steps : 16
[2026-01-30 05:36:38,065.065] Model Training From SCRATCH..
[2026-01-30 05:36:38,066.066] Maximum Learning Rate : 0.0003.
[2026-01-30 05:36:38,066.066] Default Minimum Loss: 10
[2026-01-30 05:36:38,067.067] Total steps to update optimizer : 16561.
[2026-01-30 05:36:38,067.067] Total training steps acc. to train loader : 264964
[2026-01-30 05:36:38,067.067] Warmup Steps : 829
[2026-01-30 05:36:38,067.067] Learning Rate Increment By : 3.256936067551266e-07.
[2026-01-30 05:36:49,898.898] Gradient updated
[2026-01-30 05:36:49,899.899] Current Learning Rate : 3e-05
[2026-01-30 05:36:49,900.900] Global Step : 0
[2026-01-30 05:36:49,900.900] Batch Index : 16
[2026-01-30 05:37:08,443.443] Epoch No: 1, Global Step: 000000, Train Loss: 9.987, Val Loss: 10.091

[2026-01-30 05:37:08,444.444] Total Tokens seen till now: 65472

[2026-01-30 05:37:09,311.311] Once upon a time,PerhapsMSN jazz Phil Rings affair Beetdisabled activate Kardashian replies teamed interpretfull interpret character dislinguished spills lifeott Abby molecules
[2026-01-30 05:37:15,779.779] Gradient updated
[2026-01-30 05:37:15,781.781] Current Learning Rate : 3.032569360675513e-05
[2026-01-30 05:37:15,781.781] Global Step : 1
[2026-01-30 05:37:15,781.781] Batch Index : 32
[2026-01-30 05:37:34,436.436] Epoch No: 1, Global Step: 000001, Train Loss: 9.534, Val Loss: 9.708

[2026-01-30 05:37:34,437.437] Total Tokens seen till now: 131008

[2026-01-30 05:37:35,862.862] BEST model SAVED on iteration 000001 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:37:35,956.956] Once upon a time, butterfly unlocks MosulTur
[2026-01-30 05:37:42,449.449] Gradient updated
[2026-01-30 05:37:42,449.449] Current Learning Rate : 3.0651387213510254e-05
[2026-01-30 05:37:42,449.449] Global Step : 2
[2026-01-30 05:37:42,449.449] Batch Index : 48
[2026-01-30 05:38:01,113.113] Epoch No: 1, Global Step: 000002, Train Loss: 9.245, Val Loss: 9.453

[2026-01-30 05:38:01,114.114] Total Tokens seen till now: 196544

[2026-01-30 05:38:02,301.301] BEST model SAVED on iteration 000002 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:38:02,339.339] Once upon a time, Colombian Yemeni
[2026-01-30 05:38:08,857.857] Gradient updated
[2026-01-30 05:38:08,858.858] Current Learning Rate : 3.097708082026538e-05
[2026-01-30 05:38:08,859.859] Global Step : 3
[2026-01-30 05:38:08,859.859] Batch Index : 64
[2026-01-30 05:38:27,621.621] Epoch No: 1, Global Step: 000003, Train Loss: 8.923, Val Loss: 9.260

[2026-01-30 05:38:27,622.622] Total Tokens seen till now: 262080

[2026-01-30 05:38:28,815.815] BEST model SAVED on iteration 000003 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:38:28,854.854] Once upon a time, Markets
[2026-01-30 05:38:35,367.367] Gradient updated
[2026-01-30 05:38:35,369.369] Current Learning Rate : 3.130277442702051e-05
[2026-01-30 05:38:35,369.369] Global Step : 4
[2026-01-30 05:38:35,369.369] Batch Index : 80
[2026-01-30 05:38:54,273.273] Epoch No: 1, Global Step: 000004, Train Loss: 8.840, Val Loss: 9.104

[2026-01-30 05:38:54,273.273] Total Tokens seen till now: 327616

[2026-01-30 05:38:55,657.657] BEST model SAVED on iteration 000004 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:38:55,731.731] Once upon a time,. a ginger
[2026-01-30 05:39:02,252.252] Gradient updated
[2026-01-30 05:39:02,253.253] Current Learning Rate : 3.162846803377563e-05
[2026-01-30 05:39:02,254.254] Global Step : 5
[2026-01-30 05:39:02,254.254] Batch Index : 96
[2026-01-30 05:39:20,956.956] Epoch No: 1, Global Step: 000005, Train Loss: 8.761, Val Loss: 8.979

[2026-01-30 05:39:20,957.957] Total Tokens seen till now: 393152

[2026-01-30 05:39:22,122.122] BEST model SAVED on iteration 000005 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:39:22,194.194] Once upon a time,verified listing 1862 Connect
[2026-01-30 05:39:28,714.714] Gradient updated
[2026-01-30 05:39:28,715.715] Current Learning Rate : 3.195416164053076e-05
[2026-01-30 05:39:28,715.715] Global Step : 6
[2026-01-30 05:39:28,715.715] Batch Index : 112
[2026-01-30 05:39:47,433.433] Epoch No: 1, Global Step: 000006, Train Loss: 8.577, Val Loss: 8.877

[2026-01-30 05:39:47,434.434] Total Tokens seen till now: 458672

[2026-01-30 05:39:48,568.568] BEST model SAVED on iteration 000006 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:39:48,592.592] Once upon a time,
[2026-01-30 05:39:55,065.065] Gradient updated
[2026-01-30 05:39:55,066.066] Current Learning Rate : 3.227985524728589e-05
[2026-01-30 05:39:55,066.066] Global Step : 7
[2026-01-30 05:39:55,066.066] Batch Index : 128
[2026-01-30 05:40:13,963.963] Epoch No: 1, Global Step: 000007, Train Loss: 8.485, Val Loss: 8.792

[2026-01-30 05:40:13,964.964] Total Tokens seen till now: 523856

[2026-01-30 05:40:15,308.308] BEST model SAVED on iteration 000007 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:40:15,376.376] Once upon a time,atteringTur
[2026-01-30 05:40:21,853.853] Gradient updated
[2026-01-30 05:40:21,854.854] Current Learning Rate : 3.2605548854041016e-05
[2026-01-30 05:40:21,854.854] Global Step : 8
[2026-01-30 05:40:21,854.854] Batch Index : 144
[2026-01-30 05:40:40,617.617] Epoch No: 1, Global Step: 000008, Train Loss: 8.397, Val Loss: 8.717

[2026-01-30 05:40:40,618.618] Total Tokens seen till now: 588912

[2026-01-30 05:40:41,754.754] BEST model SAVED on iteration 000008 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:40:41,804.804] Once upon a time, andWINDOWS a
[2026-01-30 05:40:48,318.318] Gradient updated
[2026-01-30 05:40:48,319.319] Current Learning Rate : 3.293124246079614e-05
[2026-01-30 05:40:48,319.319] Global Step : 9
[2026-01-30 05:40:48,319.319] Batch Index : 160
[2026-01-30 05:41:07,114.114] Epoch No: 1, Global Step: 000009, Train Loss: 8.324, Val Loss: 8.650

[2026-01-30 05:41:07,115.115] Total Tokens seen till now: 654448

[2026-01-30 05:41:08,233.233] BEST model SAVED on iteration 000009 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:41:08,247.247] Once upon a time,
[2026-01-30 05:41:14,768.768] Gradient updated
[2026-01-30 05:41:14,769.769] Current Learning Rate : 3.3256936067551266e-05
[2026-01-30 05:41:14,769.769] Global Step : 10
[2026-01-30 05:41:14,770.770] Batch Index : 176
[2026-01-30 05:41:33,674.674] Epoch No: 1, Global Step: 000010, Train Loss: 8.357, Val Loss: 8.588

[2026-01-30 05:41:33,674.674] Total Tokens seen till now: 719840

[2026-01-30 05:41:34,863.863] BEST model SAVED on iteration 000010 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:41:34,882.882] Once upon a time,
[2026-01-30 05:41:41,420.420] Gradient updated
[2026-01-30 05:41:41,421.421] Current Learning Rate : 3.3582629674306394e-05
[2026-01-30 05:41:41,421.421] Global Step : 11
[2026-01-30 05:41:41,421.421] Batch Index : 192
[2026-01-30 05:42:00,127.127] Epoch No: 1, Global Step: 000011, Train Loss: 8.236, Val Loss: 8.530

[2026-01-30 05:42:00,128.128] Total Tokens seen till now: 785376

[2026-01-30 05:42:01,237.237] BEST model SAVED on iteration 000011 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:42:01,306.306] Once upon a time, Nord and fu Connect
[2026-01-30 05:42:07,828.828] Gradient updated
[2026-01-30 05:42:07,829.829] Current Learning Rate : 3.390832328106152e-05
[2026-01-30 05:42:07,829.829] Global Step : 12
[2026-01-30 05:42:07,829.829] Batch Index : 208
[2026-01-30 05:42:26,622.622] Epoch No: 1, Global Step: 000012, Train Loss: 8.133, Val Loss: 8.474

[2026-01-30 05:42:26,623.623] Total Tokens seen till now: 850912

[2026-01-30 05:42:27,735.735] BEST model SAVED on iteration 000012 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:42:27,819.819] Once upon a time, and... Saunders a
[2026-01-30 05:42:34,310.310] Gradient updated
[2026-01-30 05:42:34,311.311] Current Learning Rate : 3.423401688781665e-05
[2026-01-30 05:42:34,311.311] Global Step : 13
[2026-01-30 05:42:34,311.311] Batch Index : 224
[2026-01-30 05:42:53,063.063] Epoch No: 1, Global Step: 000013, Train Loss: 8.154, Val Loss: 8.420

[2026-01-30 05:42:53,064.064] Total Tokens seen till now: 916032

[2026-01-30 05:42:54,122.122] BEST model SAVED on iteration 000013 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:42:54,224.224] Once upon a time, Knights a.pid Francois Tib dragged
[2026-01-30 05:43:00,741.741] Gradient updated
[2026-01-30 05:43:00,743.743] Current Learning Rate : 3.455971049457177e-05
[2026-01-30 05:43:00,743.743] Global Step : 14
[2026-01-30 05:43:00,743.743] Batch Index : 240
[2026-01-30 05:43:19,499.499] Epoch No: 1, Global Step: 000014, Train Loss: 8.075, Val Loss: 8.367

[2026-01-30 05:43:19,499.499] Total Tokens seen till now: 981568

[2026-01-30 05:43:20,761.761] BEST model SAVED on iteration 000014 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:43:20,911.911] Once upon a time, conversion special.. listing. Barbarian
[2026-01-30 05:43:27,447.447] Gradient updated
[2026-01-30 05:43:27,447.447] Current Learning Rate : 3.48854041013269e-05
[2026-01-30 05:43:27,447.447] Global Step : 15
[2026-01-30 05:43:27,447.447] Batch Index : 256
[2026-01-30 05:43:46,204.204] Epoch No: 1, Global Step: 000015, Train Loss: 8.041, Val Loss: 8.315

[2026-01-30 05:43:46,204.204] Total Tokens seen till now: 1047104

[2026-01-30 05:43:47,258.258] BEST model SAVED on iteration 000015 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:43:47,329.329] Once upon a time,stakes Imperial.XM Omni
[2026-01-30 05:43:53,854.854] Gradient updated
[2026-01-30 05:43:53,855.855] Current Learning Rate : 3.521109770808203e-05
[2026-01-30 05:43:53,855.855] Global Step : 16
[2026-01-30 05:43:53,855.855] Batch Index : 272
[2026-01-30 05:44:12,571.571] Epoch No: 1, Global Step: 000016, Train Loss: 7.987, Val Loss: 8.264

[2026-01-30 05:44:12,572.572] Total Tokens seen till now: 1112640

[2026-01-30 05:44:13,622.622] BEST model SAVED on iteration 000016 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:44:13,690.690] Once upon a time, Barbarian.. poured
[2026-01-30 05:44:20,208.208] Gradient updated
[2026-01-30 05:44:20,209.209] Current Learning Rate : 3.553679131483715e-05
[2026-01-30 05:44:20,209.209] Global Step : 17
[2026-01-30 05:44:20,209.209] Batch Index : 288
[2026-01-30 05:44:39,110.110] Epoch No: 1, Global Step: 000017, Train Loss: 7.853, Val Loss: 8.214

[2026-01-30 05:44:39,110.110] Total Tokens seen till now: 1178112

[2026-01-30 05:44:40,448.448] BEST model SAVED on iteration 000017 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:44:40,569.569] Once upon a time, CONS. to a
[2026-01-30 05:44:47,100.100] Gradient updated
[2026-01-30 05:44:47,101.101] Current Learning Rate : 3.586248492159228e-05
[2026-01-30 05:44:47,101.101] Global Step : 18
[2026-01-30 05:44:47,101.101] Batch Index : 304
[2026-01-30 05:45:05,856.856] Epoch No: 1, Global Step: 000018, Train Loss: 7.856, Val Loss: 8.165

[2026-01-30 05:45:05,856.856] Total Tokens seen till now: 1243648

[2026-01-30 05:45:07,018.018] BEST model SAVED on iteration 000018 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:45:07,185.185] Once upon a time, to. Supporters. the....isha
[2026-01-30 05:45:13,713.713] Gradient updated
[2026-01-30 05:45:13,713.713] Current Learning Rate : 3.6188178528347406e-05
[2026-01-30 05:45:13,714.714] Global Step : 19
[2026-01-30 05:45:13,714.714] Batch Index : 320
[2026-01-30 05:45:32,533.533] Epoch No: 1, Global Step: 000019, Train Loss: 7.800, Val Loss: 8.119

[2026-01-30 05:45:32,533.533] Total Tokens seen till now: 1309184

[2026-01-30 05:45:33,667.667] BEST model SAVED on iteration 000019 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:45:33,821.821] Once upon a time, racing... the... listing said MTA.
[2026-01-30 05:45:40,356.356] Gradient updated
[2026-01-30 05:45:40,356.356] Current Learning Rate : 3.6513872135102534e-05
[2026-01-30 05:45:40,357.357] Global Step : 20
[2026-01-30 05:45:40,357.357] Batch Index : 336
[2026-01-30 05:45:59,238.238] Epoch No: 1, Global Step: 000020, Train Loss: 7.718, Val Loss: 8.076

[2026-01-30 05:45:59,239.239] Total Tokens seen till now: 1374720

[2026-01-30 05:46:00,577.577] BEST model SAVED on iteration 000020 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:46:00,789.789] Once upon a time, the...... the the. and
[2026-01-30 05:46:07,306.306] Gradient updated
[2026-01-30 05:46:07,306.306] Current Learning Rate : 3.683956574185766e-05
[2026-01-30 05:46:07,306.306] Global Step : 21
[2026-01-30 05:46:07,306.306] Batch Index : 352
[2026-01-30 05:46:25,962.962] Epoch No: 1, Global Step: 000021, Train Loss: 7.689, Val Loss: 8.035

[2026-01-30 05:46:25,962.962] Total Tokens seen till now: 1440256

[2026-01-30 05:46:27,080.080] BEST model SAVED on iteration 000021 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:46:27,326.326] Once upon a time, Garage and..... Supportersattering..... Saunders.XM. poured
[2026-01-30 05:46:33,868.868] Gradient updated
[2026-01-30 05:46:33,869.869] Current Learning Rate : 3.7165259348612784e-05
[2026-01-30 05:46:33,869.869] Global Step : 22
[2026-01-30 05:46:33,869.869] Batch Index : 368
[2026-01-30 05:46:52,632.632] Epoch No: 1, Global Step: 000022, Train Loss: 7.704, Val Loss: 7.996

[2026-01-30 05:46:52,633.633] Total Tokens seen till now: 1505792

[2026-01-30 05:46:53,765.765] BEST model SAVED on iteration 000022 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:46:53,889.889] Once upon a time,. the...attering,...
[2026-01-30 05:47:00,431.431] Gradient updated
[2026-01-30 05:47:00,432.432] Current Learning Rate : 3.749095295536791e-05
[2026-01-30 05:47:00,432.432] Global Step : 23
[2026-01-30 05:47:00,432.432] Batch Index : 384
[2026-01-30 05:47:19,272.272] Epoch No: 1, Global Step: 000023, Train Loss: 7.720, Val Loss: 7.960

[2026-01-30 05:47:19,272.272] Total Tokens seen till now: 1571328

[2026-01-30 05:47:20,655.655] BEST model SAVED on iteration 000023 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:47:20,829.829] Once upon a time,.attering. theattering. the.XMXM
[2026-01-30 05:47:27,358.358] Gradient updated
[2026-01-30 05:47:27,359.359] Current Learning Rate : 3.781664656212304e-05
[2026-01-30 05:47:27,359.359] Global Step : 24
[2026-01-30 05:47:27,359.359] Batch Index : 400
[2026-01-30 05:47:46,105.105] Epoch No: 1, Global Step: 000024, Train Loss: 7.597, Val Loss: 7.925

[2026-01-30 05:47:46,106.106] Total Tokens seen till now: 1636864

[2026-01-30 05:47:47,236.236] BEST model SAVED on iteration 000024 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:47:47,584.584] Once upon a time,attering day.... to. and to.. the. poured...Play.... CONS
[2026-01-30 05:47:54,099.099] Gradient updated
[2026-01-30 05:47:54,100.100] Current Learning Rate : 3.814234016887817e-05
[2026-01-30 05:47:54,100.100] Global Step : 25
[2026-01-30 05:47:54,100.100] Batch Index : 416
[2026-01-30 05:48:12,833.833] Epoch No: 1, Global Step: 000025, Train Loss: 7.534, Val Loss: 7.892

[2026-01-30 05:48:12,834.834] Total Tokens seen till now: 1702352

[2026-01-30 05:48:13,969.969] BEST model SAVED on iteration 000025 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:48:14,600.600] Once upon a time, field.. the....... to. friend,. the.......isha.... girl..........
[2026-01-30 05:48:21,226.226] Gradient updated
[2026-01-30 05:48:21,227.227] Current Learning Rate : 3.846803377563329e-05
[2026-01-30 05:48:21,227.227] Global Step : 26
[2026-01-30 05:48:21,227.227] Batch Index : 432
[2026-01-30 05:48:40,046.046] Epoch No: 1, Global Step: 000026, Train Loss: 7.534, Val Loss: 7.859

[2026-01-30 05:48:40,046.046] Total Tokens seen till now: 1767776

[2026-01-30 05:48:41,214.214] BEST model SAVED on iteration 000026 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:48:41,945.945] Once upon a time,,. and.XM.... and.. specialnutrition..... the. the. and.. to was said.attering.. dragged.. the CONS... dragged.. poured.
[2026-01-30 05:48:48,452.452] Gradient updated
[2026-01-30 05:48:48,453.453] Current Learning Rate : 3.879372738238842e-05
[2026-01-30 05:48:48,453.453] Global Step : 27
[2026-01-30 05:48:48,453.453] Batch Index : 448
[2026-01-30 05:49:07,217.217] Epoch No: 1, Global Step: 000027, Train Loss: 7.491, Val Loss: 7.828

[2026-01-30 05:49:07,218.218] Total Tokens seen till now: 1833312

[2026-01-30 05:49:08,258.258] BEST model SAVED on iteration 000027 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:49:08,832.832] Once upon a time, and radios was and.. Supporters. a... and poured.. poured. was.. and.. the.nutrition. special.. from. and... and. poured......
[2026-01-30 05:49:15,340.340] Gradient updated
[2026-01-30 05:49:15,341.341] Current Learning Rate : 3.9119420989143546e-05
[2026-01-30 05:49:15,341.341] Global Step : 28
[2026-01-30 05:49:15,341.341] Batch Index : 464
[2026-01-30 05:49:34,189.189] Epoch No: 1, Global Step: 000028, Train Loss: 7.401, Val Loss: 7.797

[2026-01-30 05:49:34,190.190] Total Tokens seen till now: 1898848

[2026-01-30 05:49:35,386.386] BEST model SAVED on iteration 000028 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:49:35,924.924] Once upon a time,.. soccer. the..s. was,........ a and... andisha a
[2026-01-30 05:49:42,382.382] Gradient updated
[2026-01-30 05:49:42,382.382] Current Learning Rate : 3.9445114595898674e-05
[2026-01-30 05:49:42,382.382] Global Step : 29
[2026-01-30 05:49:42,382.382] Batch Index : 480
[2026-01-30 05:50:01,146.146] Epoch No: 1, Global Step: 000029, Train Loss: 7.369, Val Loss: 7.768

[2026-01-30 05:50:01,146.146] Total Tokens seen till now: 1963968

[2026-01-30 05:50:02,212.212] BEST model SAVED on iteration 000029 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:50:02,538.538] Once upon a time, the poured the?" just. and was.. fight.?",... and. came.. special the
[2026-01-30 05:50:09,045.045] Gradient updated
[2026-01-30 05:50:09,045.045] Current Learning Rate : 3.97708082026538e-05
[2026-01-30 05:50:09,045.045] Global Step : 30
[2026-01-30 05:50:09,045.045] Batch Index : 496
[2026-01-30 05:50:27,788.788] Epoch No: 1, Global Step: 000030, Train Loss: 7.402, Val Loss: 7.739

[2026-01-30 05:50:27,788.788] Total Tokens seen till now: 2029504

[2026-01-30 05:50:28,917.917] BEST model SAVED on iteration 000030 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:50:29,072.072] Once upon a time,. was.. to.......
[2026-01-30 05:50:35,582.582] Gradient updated
[2026-01-30 05:50:35,582.582] Current Learning Rate : 4.0096501809408924e-05
[2026-01-30 05:50:35,582.582] Global Step : 31
[2026-01-30 05:50:35,583.583] Batch Index : 512
[2026-01-30 05:50:54,329.329] Epoch No: 1, Global Step: 000031, Train Loss: 7.393, Val Loss: 7.711

[2026-01-30 05:50:54,329.329] Total Tokens seen till now: 2095040

[2026-01-30 05:50:55,583.583] BEST model SAVED on iteration 000031 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:50:56,447.447] Once upon a time, upon a pacing the.. was to. the. to.. to. a. was. a and,... a.. Lisa....... and. a. a. the the. said.
[2026-01-30 05:51:02,946.946] Gradient updated
[2026-01-30 05:51:02,947.947] Current Learning Rate : 4.042219541616405e-05
[2026-01-30 05:51:02,947.947] Global Step : 32
[2026-01-30 05:51:02,947.947] Batch Index : 528
[2026-01-30 05:51:21,614.614] Epoch No: 1, Global Step: 000032, Train Loss: 7.389, Val Loss: 7.684

[2026-01-30 05:51:21,615.615] Total Tokens seen till now: 2160576

[2026-01-30 05:51:22,722.722] BEST model SAVED on iteration 000032 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:51:23,144.144] Once upon a time,?"attering special It. tree.. came to. grandchildren.. a.. to a came to friend..........
[2026-01-30 05:51:29,646.646] Gradient updated
[2026-01-30 05:51:29,647.647] Current Learning Rate : 4.074788902291918e-05
[2026-01-30 05:51:29,647.647] Global Step : 33
[2026-01-30 05:51:29,647.647] Batch Index : 544
[2026-01-30 05:51:48,417.417] Epoch No: 1, Global Step: 000033, Train Loss: 7.347, Val Loss: 7.656

[2026-01-30 05:51:48,417.417] Total Tokens seen till now: 2226112

[2026-01-30 05:51:49,553.553] BEST model SAVED on iteration 000033 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:51:50,245.245] Once upon a time, a. the. a a.......?" the to, the...... came... the a.... the. running....
[2026-01-30 05:51:56,750.750] Gradient updated
[2026-01-30 05:51:56,750.750] Current Learning Rate : 4.10735826296743e-05
[2026-01-30 05:51:56,750.750] Global Step : 34
[2026-01-30 05:51:56,751.751] Batch Index : 560
[2026-01-30 05:52:15,497.497] Epoch No: 1, Global Step: 000034, Train Loss: 7.288, Val Loss: 7.629

[2026-01-30 05:52:15,498.498] Total Tokens seen till now: 2291648

[2026-01-30 05:52:16,643.643] BEST model SAVED on iteration 000034 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:52:16,989.989] Once upon a time, just of, a and....?" to said.. girl. the and. and., from.
[2026-01-30 05:52:23,498.498] Gradient updated
[2026-01-30 05:52:23,498.498] Current Learning Rate : 4.139927623642943e-05
[2026-01-30 05:52:23,498.498] Global Step : 35
[2026-01-30 05:52:23,499.499] Batch Index : 576
[2026-01-30 05:52:42,177.177] Epoch No: 1, Global Step: 000035, Train Loss: 7.311, Val Loss: 7.602

[2026-01-30 05:52:42,178.178] Total Tokens seen till now: 2357184

[2026-01-30 05:52:43,225.225] BEST model SAVED on iteration 000035 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:52:43,664.664] Once upon a time,.s. was a. a the special.. Amy. was.. girl.. to... not It and to... to.. a...
[2026-01-30 05:52:50,163.163] Gradient updated
[2026-01-30 05:52:50,163.163] Current Learning Rate : 4.172496984318456e-05
[2026-01-30 05:52:50,163.163] Global Step : 36
[2026-01-30 05:52:50,163.163] Batch Index : 592
[2026-01-30 05:53:09,040.040] Epoch No: 1, Global Step: 000036, Train Loss: 7.276, Val Loss: 7.575

[2026-01-30 05:53:09,040.040] Total Tokens seen till now: 2422720

[2026-01-30 05:53:10,198.198] BEST model SAVED on iteration 000036 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:53:11,000.000] Once upon a time, was,?".., tree and got.,..........., said girl....... was running.attering a got the, One
[2026-01-30 05:53:17,508.508] Gradient updated
[2026-01-30 05:53:17,508.508] Current Learning Rate : 4.2050663449939686e-05
[2026-01-30 05:53:17,508.508] Global Step : 37
[2026-01-30 05:53:17,508.508] Batch Index : 608
[2026-01-30 05:53:36,160.160] Epoch No: 1, Global Step: 000037, Train Loss: 7.207, Val Loss: 7.548

[2026-01-30 05:53:36,160.160] Total Tokens seen till now: 2488256

[2026-01-30 05:53:37,254.254] BEST model SAVED on iteration 000037 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:53:37,552.552] Once upon a time, was got.. thing.. a.. Amy came was the. a. got... and said.
[2026-01-30 05:53:44,058.058] Gradient updated
[2026-01-30 05:53:44,058.058] Current Learning Rate : 4.2376357056694814e-05
[2026-01-30 05:53:44,058.058] Global Step : 38
[2026-01-30 05:53:44,058.058] Batch Index : 624
[2026-01-30 05:54:02,694.694] Epoch No: 1, Global Step: 000038, Train Loss: 7.210, Val Loss: 7.521

[2026-01-30 05:54:02,694.694] Total Tokens seen till now: 2553728

[2026-01-30 05:54:03,792.792] BEST model SAVED on iteration 000038 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:54:04,078.078] Once upon a time,........ a and... got thing.. Amy. and.
[2026-01-30 05:54:10,582.582] Gradient updated
[2026-01-30 05:54:10,583.583] Current Learning Rate : 4.2702050663449936e-05
[2026-01-30 05:54:10,583.583] Global Step : 39
[2026-01-30 05:54:10,583.583] Batch Index : 640
[2026-01-30 05:54:29,356.356] Epoch No: 1, Global Step: 000039, Train Loss: 7.198, Val Loss: 7.493

[2026-01-30 05:54:29,356.356] Total Tokens seen till now: 2619264

[2026-01-30 05:54:30,610.610] BEST model SAVED on iteration 000039 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:54:30,747.747] Once upon a time, a?" Amy special.. the
[2026-01-30 05:54:37,190.190] Gradient updated
[2026-01-30 05:54:37,190.190] Current Learning Rate : 4.3027744270205064e-05
[2026-01-30 05:54:37,190.190] Global Step : 40
[2026-01-30 05:54:37,190.190] Batch Index : 656
[2026-01-30 05:54:55,852.852] Epoch No: 1, Global Step: 000040, Train Loss: 7.178, Val Loss: 7.466

[2026-01-30 05:54:55,852.852] Total Tokens seen till now: 2684016

[2026-01-30 05:54:56,900.900] BEST model SAVED on iteration 000040 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:54:57,077.077] Once upon a time, was,...., a One. the. said
[2026-01-30 05:55:03,581.581] Gradient updated
[2026-01-30 05:55:03,581.581] Current Learning Rate : 4.335343787696019e-05
[2026-01-30 05:55:03,581.581] Global Step : 41
[2026-01-30 05:55:03,581.581] Batch Index : 672
[2026-01-30 05:55:22,279.279] Epoch No: 1, Global Step: 000041, Train Loss: 7.147, Val Loss: 7.438

[2026-01-30 05:55:22,279.279] Total Tokens seen till now: 2749552

[2026-01-30 05:55:23,313.313] BEST model SAVED on iteration 000041 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:55:23,874.874] Once upon a time, a to,  to got. the fight..... came. a a. a came.. One. a.. said. ands special?" Tom. appeared... the.. Amy.
[2026-01-30 05:55:30,311.311] Gradient updated
[2026-01-30 05:55:30,311.311] Current Learning Rate : 4.367913148371532e-05
[2026-01-30 05:55:30,311.311] Global Step : 42
[2026-01-30 05:55:30,311.311] Batch Index : 688
[2026-01-30 05:55:49,104.104] Epoch No: 1, Global Step: 000042, Train Loss: 7.118, Val Loss: 7.410

[2026-01-30 05:55:49,104.104] Total Tokens seen till now: 2814336

[2026-01-30 05:55:50,304.304] BEST model SAVED on iteration 000042 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:55:50,562.562] Once upon a time,. was, said One a... just..
[2026-01-30 05:55:57,057.057] Gradient updated
[2026-01-30 05:55:57,058.058] Current Learning Rate : 4.400482509047044e-05
[2026-01-30 05:55:57,058.058] Global Step : 43
[2026-01-30 05:55:57,058.058] Batch Index : 704
[2026-01-30 05:56:15,675.675] Epoch No: 1, Global Step: 000043, Train Loss: 7.057, Val Loss: 7.382

[2026-01-30 05:56:15,675.675] Total Tokens seen till now: 2879872

[2026-01-30 05:56:16,791.791] BEST model SAVED on iteration 000043 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:56:17,356.356] Once upon a time, Lisa a a.. girl. a.... the and to.?" a.... was. to was. came the.. and....,.... came.
[2026-01-30 05:56:23,854.854] Gradient updated
[2026-01-30 05:56:23,855.855] Current Learning Rate : 4.433051869722557e-05
[2026-01-30 05:56:23,855.855] Global Step : 44
[2026-01-30 05:56:23,855.855] Batch Index : 720
[2026-01-30 05:56:42,497.497] Epoch No: 1, Global Step: 000044, Train Loss: 7.017, Val Loss: 7.354

[2026-01-30 05:56:42,498.498] Total Tokens seen till now: 2945376

[2026-01-30 05:56:43,618.618] BEST model SAVED on iteration 000044 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:56:44,075.075] Once upon a time, to a the and girl the.s. and. and. from a..?"...... a. special.. , Tom girl
[2026-01-30 05:56:50,582.582] Gradient updated
[2026-01-30 05:56:50,582.582] Current Learning Rate : 4.46562123039807e-05
[2026-01-30 05:56:50,582.582] Global Step : 45
[2026-01-30 05:56:50,582.582] Batch Index : 736
[2026-01-30 05:57:09,313.313] Epoch No: 1, Global Step: 000045, Train Loss: 7.000, Val Loss: 7.326

[2026-01-30 05:57:09,314.314] Total Tokens seen till now: 3010912

[2026-01-30 05:57:10,727.727] BEST model SAVED on iteration 000045 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:57:11,086.086] Once upon a time, and a. lot lot a a One. was. to.....s a got
[2026-01-30 05:57:17,572.572] Gradient updated
[2026-01-30 05:57:17,572.572] Current Learning Rate : 4.4981905910735826e-05
[2026-01-30 05:57:17,573.573] Global Step : 46
[2026-01-30 05:57:17,573.573] Batch Index : 752
[2026-01-30 05:57:36,186.186] Epoch No: 1, Global Step: 000046, Train Loss: 6.978, Val Loss: 7.297

[2026-01-30 05:57:36,186.186] Total Tokens seen till now: 3076448

[2026-01-30 05:57:37,235.235] BEST model SAVED on iteration 000046 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:57:37,416.416] Once upon a time, was and a. he just to. to, was.
[2026-01-30 05:57:43,897.897] Gradient updated
[2026-01-30 05:57:43,897.897] Current Learning Rate : 4.5307599517490954e-05
[2026-01-30 05:57:43,898.898] Global Step : 47
[2026-01-30 05:57:43,898.898] Batch Index : 768
[2026-01-30 05:58:02,542.542] Epoch No: 1, Global Step: 000047, Train Loss: 6.935, Val Loss: 7.269

[2026-01-30 05:58:02,542.542] Total Tokens seen till now: 3141824

[2026-01-30 05:58:03,685.685] BEST model SAVED on iteration 000047 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:58:03,819.819] Once upon a time, and a  just a...
[2026-01-30 05:58:10,241.241] Gradient updated
[2026-01-30 05:58:10,242.242] Current Learning Rate : 4.563329312424608e-05
[2026-01-30 05:58:10,242.242] Global Step : 48
[2026-01-30 05:58:10,242.242] Batch Index : 784
[2026-01-30 05:58:28,942.942] Epoch No: 1, Global Step: 000048, Train Loss: 6.927, Val Loss: 7.240

[2026-01-30 05:58:28,942.942] Total Tokens seen till now: 3206688

[2026-01-30 05:58:30,128.128] BEST model SAVED on iteration 000048 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:58:30,994.994] Once upon a time, the.., and., and the.. said.. the...... to.. the and The. to was a... from... the. his
[2026-01-30 05:58:37,476.476] Gradient updated
[2026-01-30 05:58:37,476.476] Current Learning Rate : 4.5958986731001204e-05
[2026-01-30 05:58:37,476.476] Global Step : 49
[2026-01-30 05:58:37,476.476] Batch Index : 800
[2026-01-30 05:58:56,179.179] Epoch No: 1, Global Step: 000049, Train Loss: 6.944, Val Loss: 7.211

[2026-01-30 05:58:56,180.180] Total Tokens seen till now: 3272224

[2026-01-30 05:58:57,236.236] BEST model SAVED on iteration 000049 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:58:57,758.758] Once upon a time,. a., came a the. a. One day,s. and and.... got. the".. came was a... girl. a and
[2026-01-30 05:59:04,248.248] Gradient updated
[2026-01-30 05:59:04,249.249] Current Learning Rate : 4.628468033775633e-05
[2026-01-30 05:59:04,249.249] Global Step : 50
[2026-01-30 05:59:04,249.249] Batch Index : 816
[2026-01-30 05:59:22,905.905] Epoch No: 1, Global Step: 000050, Train Loss: 6.862, Val Loss: 7.183

[2026-01-30 05:59:22,906.906] Total Tokens seen till now: 3337760

[2026-01-30 05:59:24,018.018] BEST model SAVED on iteration 000050 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:59:24,592.592] Once upon a time, was.. upon a. a.. to....  as... just. friend. the... got..,.. was. a came. then a. One the...
[2026-01-30 05:59:31,083.083] Gradient updated
[2026-01-30 05:59:31,084.084] Current Learning Rate : 4.6610373944511453e-05
[2026-01-30 05:59:31,085.085] Global Step : 51
[2026-01-30 05:59:31,085.085] Batch Index : 832
[2026-01-30 05:59:49,761.761] Epoch No: 1, Global Step: 000051, Train Loss: 6.788, Val Loss: 7.154

[2026-01-30 05:59:49,761.761] Total Tokens seen till now: 3403216

[2026-01-30 05:59:50,870.870] BEST model SAVED on iteration 000051 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 05:59:51,304.304] Once upon a time, a a a a One was. was the. was day the to. came. and One to.. One....... and was?" got.
[2026-01-30 05:59:57,794.794] Gradient updated
[2026-01-30 05:59:57,795.795] Current Learning Rate : 4.693606755126658e-05
[2026-01-30 05:59:57,795.795] Global Step : 52
[2026-01-30 05:59:57,795.795] Batch Index : 848
[2026-01-30 06:00:16,434.434] Epoch No: 1, Global Step: 000052, Train Loss: 6.795, Val Loss: 7.124

[2026-01-30 06:00:16,435.435] Total Tokens seen till now: 3468752

[2026-01-30 06:00:17,430.430] BEST model SAVED on iteration 000052 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:00:17,829.829] Once upon a time, a a was a. girl.... of just. girl. a the from.. day,... a and special. and. It and?".
[2026-01-30 06:00:24,260.260] Gradient updated
[2026-01-30 06:00:24,261.261] Current Learning Rate : 4.726176115802171e-05
[2026-01-30 06:00:24,261.261] Global Step : 53
[2026-01-30 06:00:24,261.261] Batch Index : 864
[2026-01-30 06:00:42,968.968] Epoch No: 1, Global Step: 000053, Train Loss: 6.799, Val Loss: 7.095

[2026-01-30 06:00:42,969.969] Total Tokens seen till now: 3533664

[2026-01-30 06:00:44,107.107] BEST model SAVED on iteration 000053 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:00:44,435.435] Once upon a time, a to.. The the ... special"... thing special.. got to
[2026-01-30 06:00:50,936.936] Gradient updated
[2026-01-30 06:00:50,936.936] Current Learning Rate : 4.758745476477684e-05
[2026-01-30 06:00:50,936.936] Global Step : 54
[2026-01-30 06:00:50,937.937] Batch Index : 880
[2026-01-30 06:01:09,566.566] Epoch No: 1, Global Step: 000054, Train Loss: 6.715, Val Loss: 7.066

[2026-01-30 06:01:09,567.567] Total Tokens seen till now: 3599200

[2026-01-30 06:01:11,028.028] BEST model SAVED on iteration 000054 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:01:11,094.094] Once upon a time, thing a, was
[2026-01-30 06:01:17,585.585] Gradient updated
[2026-01-30 06:01:17,586.586] Current Learning Rate : 4.7913148371531966e-05
[2026-01-30 06:01:17,586.586] Global Step : 55
[2026-01-30 06:01:17,586.586] Batch Index : 896
[2026-01-30 06:01:36,238.238] Epoch No: 1, Global Step: 000055, Train Loss: 6.694, Val Loss: 7.036

[2026-01-30 06:01:36,239.239] Total Tokens seen till now: 3664736

[2026-01-30 06:01:37,418.418] BEST model SAVED on iteration 000055 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:01:37,663.663] Once upon a time, a a, a and One?".. just and.. and and and.. tried just.
[2026-01-30 06:01:44,156.156] Gradient updated
[2026-01-30 06:01:44,157.157] Current Learning Rate : 4.8238841978287094e-05
[2026-01-30 06:01:44,157.157] Global Step : 56
[2026-01-30 06:01:44,157.157] Batch Index : 912
[2026-01-30 06:02:02,808.808] Epoch No: 1, Global Step: 000056, Train Loss: 6.653, Val Loss: 7.006

[2026-01-30 06:02:02,808.808] Total Tokens seen till now: 3730272

[2026-01-30 06:02:03,980.980] BEST model SAVED on iteration 000056 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:02:04,244.244] Once upon a time, was a came was a.. was. to and.. was. and and and.
[2026-01-30 06:02:10,725.725] Gradient updated
[2026-01-30 06:02:10,726.726] Current Learning Rate : 4.8564535585042216e-05
[2026-01-30 06:02:10,727.727] Global Step : 57
[2026-01-30 06:02:10,727.727] Batch Index : 928
[2026-01-30 06:02:29,534.534] Epoch No: 1, Global Step: 000057, Train Loss: 6.727, Val Loss: 6.976

[2026-01-30 06:02:29,534.534] Total Tokens seen till now: 3795648

[2026-01-30 06:02:30,979.979] BEST model SAVED on iteration 000057 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:02:31,324.324] Once upon a time, a. a a special was a, a. the. the.... special..
[2026-01-30 06:02:37,826.826] Gradient updated
[2026-01-30 06:02:37,827.827] Current Learning Rate : 4.8890229191797344e-05
[2026-01-30 06:02:37,827.827] Global Step : 58
[2026-01-30 06:02:37,827.827] Batch Index : 944
[2026-01-30 06:02:56,478.478] Epoch No: 1, Global Step: 000058, Train Loss: 6.675, Val Loss: 6.946

[2026-01-30 06:02:56,479.479] Total Tokens seen till now: 3861184

[2026-01-30 06:02:57,540.540] BEST model SAVED on iteration 000058 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:02:57,987.987] Once upon a time,, from time a?". to a to... and.. a... and The said One. just. and.. his.
[2026-01-30 06:03:04,473.473] Gradient updated
[2026-01-30 06:03:04,474.474] Current Learning Rate : 4.9215922798552465e-05
[2026-01-30 06:03:04,474.474] Global Step : 59
[2026-01-30 06:03:04,474.474] Batch Index : 960
[2026-01-30 06:03:23,187.187] Epoch No: 1, Global Step: 000059, Train Loss: 6.651, Val Loss: 6.916

[2026-01-30 06:03:23,188.188] Total Tokens seen till now: 3926656

[2026-01-30 06:03:24,324.324] BEST model SAVED on iteration 000059 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:03:24,667.667] Once upon a time, was  lot was a a... girl.?" was. and came not. to.. was from
[2026-01-30 06:03:31,153.153] Gradient updated
[2026-01-30 06:03:31,154.154] Current Learning Rate : 4.9541616405307593e-05
[2026-01-30 06:03:31,154.154] Global Step : 60
[2026-01-30 06:03:31,154.154] Batch Index : 976
[2026-01-30 06:03:49,834.834] Epoch No: 1, Global Step: 000060, Train Loss: 6.607, Val Loss: 6.885

[2026-01-30 06:03:49,835.835] Total Tokens seen till now: 3992128

[2026-01-30 06:03:50,995.995] BEST model SAVED on iteration 000060 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:03:51,246.246] Once upon a time, to Her a tried thes a was and It he a the One the a. came just
[2026-01-30 06:03:57,742.742] Gradient updated
[2026-01-30 06:03:57,742.742] Current Learning Rate : 4.986731001206272e-05
[2026-01-30 06:03:57,743.743] Global Step : 61
[2026-01-30 06:03:57,743.743] Batch Index : 992
[2026-01-30 06:04:16,367.367] Epoch No: 1, Global Step: 000061, Train Loss: 6.591, Val Loss: 6.854

[2026-01-30 06:04:16,368.368] Total Tokens seen till now: 4057664

[2026-01-30 06:04:17,514.514] BEST model SAVED on iteration 000061 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:04:17,922.922] Once upon a time, a came ., The... the. and....s to to the the.. just. said..
[2026-01-30 06:04:24,423.423] Gradient updated
[2026-01-30 06:04:24,424.424] Current Learning Rate : 5.019300361881785e-05
[2026-01-30 06:04:24,424.424] Global Step : 62
[2026-01-30 06:04:24,424.424] Batch Index : 1008
[2026-01-30 06:04:43,098.098] Epoch No: 1, Global Step: 000062, Train Loss: 6.403, Val Loss: 6.822

[2026-01-30 06:04:43,098.098] Total Tokens seen till now: 4123200

[2026-01-30 06:04:44,240.240] BEST model SAVED on iteration 000062 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:04:44,440.440] Once upon a time, a a a. girl the and. girl the. to special.
[2026-01-30 06:04:50,946.946] Gradient updated
[2026-01-30 06:04:50,946.946] Current Learning Rate : 5.051869722557298e-05
[2026-01-30 06:04:50,946.946] Global Step : 63
[2026-01-30 06:04:50,946.946] Batch Index : 1024
[2026-01-30 06:05:09,553.553] Epoch No: 1, Global Step: 000063, Train Loss: 6.493, Val Loss: 6.791

[2026-01-30 06:05:09,553.553] Total Tokens seen till now: 4188736

[2026-01-30 06:05:10,969.969] BEST model SAVED on iteration 000063 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:05:11,086.086] Once upon a time, a a. there her.
[2026-01-30 06:05:17,572.572] Gradient updated
[2026-01-30 06:05:17,572.572] Current Learning Rate : 5.0844390832328106e-05
[2026-01-30 06:05:17,572.572] Global Step : 64
[2026-01-30 06:05:17,572.572] Batch Index : 1040
[2026-01-30 06:05:36,251.251] Epoch No: 1, Global Step: 000064, Train Loss: 6.397, Val Loss: 6.758

[2026-01-30 06:05:36,251.251] Total Tokens seen till now: 4254080

[2026-01-30 06:05:37,415.415] BEST model SAVED on iteration 000064 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:05:37,630.630] Once upon a time, there a a a, from to..,.. to,
[2026-01-30 06:05:44,128.128] Gradient updated
[2026-01-30 06:05:44,128.128] Current Learning Rate : 5.1170084439083234e-05
[2026-01-30 06:05:44,128.128] Global Step : 65
[2026-01-30 06:05:44,128.128] Batch Index : 1056
[2026-01-30 06:06:02,835.835] Epoch No: 1, Global Step: 000065, Train Loss: 6.459, Val Loss: 6.726

[2026-01-30 06:06:02,835.835] Total Tokens seen till now: 4319616

[2026-01-30 06:06:03,984.984] BEST model SAVED on iteration 000065 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:06:04,491.491] Once upon a time, a, lot to a to. feel to girl... feel. to tos the the.. to..s and.,".. and. girl to came..
[2026-01-30 06:06:10,992.992] Gradient updated
[2026-01-30 06:06:10,993.993] Current Learning Rate : 5.1495778045838356e-05
[2026-01-30 06:06:10,993.993] Global Step : 66
[2026-01-30 06:06:10,993.993] Batch Index : 1072
[2026-01-30 06:06:29,671.671] Epoch No: 1, Global Step: 000066, Train Loss: 6.406, Val Loss: 6.692

[2026-01-30 06:06:29,671.671] Total Tokens seen till now: 4385152

[2026-01-30 06:06:31,182.182] BEST model SAVED on iteration 000066 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:06:31,342.342] Once upon a time, as?". to..
[2026-01-30 06:06:37,847.847] Gradient updated
[2026-01-30 06:06:37,847.847] Current Learning Rate : 5.1821471652593484e-05
[2026-01-30 06:06:37,847.847] Global Step : 67
[2026-01-30 06:06:37,847.847] Batch Index : 1088
[2026-01-30 06:06:56,551.551] Epoch No: 1, Global Step: 000067, Train Loss: 6.399, Val Loss: 6.659

[2026-01-30 06:06:56,551.551] Total Tokens seen till now: 4450688

[2026-01-30 06:06:57,703.703] BEST model SAVED on iteration 000067 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:06:57,864.864] Once upon a time,, a a girl and a. to. a.
[2026-01-30 06:07:04,358.358] Gradient updated
[2026-01-30 06:07:04,358.358] Current Learning Rate : 5.2147165259348605e-05
[2026-01-30 06:07:04,359.359] Global Step : 68
[2026-01-30 06:07:04,359.359] Batch Index : 1104
[2026-01-30 06:07:23,023.023] Epoch No: 1, Global Step: 000068, Train Loss: 6.429, Val Loss: 6.625

[2026-01-30 06:07:23,023.023] Total Tokens seen till now: 4516224

[2026-01-30 06:07:24,173.173] BEST model SAVED on iteration 000068 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:07:24,611.611] Once upon a time, a, to. big,, to kept. said. the friend a the from. a to. a to,..
[2026-01-30 06:07:31,100.100] Gradient updated
[2026-01-30 06:07:31,101.101] Current Learning Rate : 5.2472858866103734e-05
[2026-01-30 06:07:31,101.101] Global Step : 69
[2026-01-30 06:07:31,102.102] Batch Index : 1120
[2026-01-30 06:07:49,761.761] Epoch No: 1, Global Step: 000069, Train Loss: 6.328, Val Loss: 6.591

[2026-01-30 06:07:49,761.761] Total Tokens seen till now: 4581760

[2026-01-30 06:07:50,947.947] BEST model SAVED on iteration 000069 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:07:51,126.126] Once upon a time, used was a a a her had. then was got
[2026-01-30 06:07:57,632.632] Gradient updated
[2026-01-30 06:07:57,632.632] Current Learning Rate : 5.279855247285886e-05
[2026-01-30 06:07:57,632.632] Global Step : 70
[2026-01-30 06:07:57,632.632] Batch Index : 1136
[2026-01-30 06:08:16,334.334] Epoch No: 1, Global Step: 000070, Train Loss: 6.258, Val Loss: 6.557

[2026-01-30 06:08:16,335.335] Total Tokens seen till now: 4647296

[2026-01-30 06:08:17,499.499] BEST model SAVED on iteration 000070 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:08:17,622.622] Once upon a time, used a he, there girl.
[2026-01-30 06:08:24,062.062] Gradient updated
[2026-01-30 06:08:24,062.062] Current Learning Rate : 5.312424607961399e-05
[2026-01-30 06:08:24,062.062] Global Step : 71
[2026-01-30 06:08:24,062.062] Batch Index : 1152
[2026-01-30 06:08:42,704.704] Epoch No: 1, Global Step: 000071, Train Loss: 6.215, Val Loss: 6.523

[2026-01-30 06:08:42,704.704] Total Tokens seen till now: 4712224

[2026-01-30 06:08:43,872.872] BEST model SAVED on iteration 000071 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:08:43,962.962] Once upon a time,, there there,,.
[2026-01-30 06:08:50,478.478] Gradient updated
[2026-01-30 06:08:50,478.478] Current Learning Rate : 5.344993968636912e-05
[2026-01-30 06:08:50,479.479] Global Step : 72
[2026-01-30 06:08:50,479.479] Batch Index : 1168
[2026-01-30 06:09:09,278.278] Epoch No: 1, Global Step: 000072, Train Loss: 6.204, Val Loss: 6.489

[2026-01-30 06:09:09,278.278] Total Tokens seen till now: 4777760

[2026-01-30 06:09:10,629.629] BEST model SAVED on iteration 000072 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:09:10,746.746] Once upon a time,,s girl a he friend
[2026-01-30 06:09:17,226.226] Gradient updated
[2026-01-30 06:09:17,226.226] Current Learning Rate : 5.3775633293124246e-05
[2026-01-30 06:09:17,226.226] Global Step : 73
[2026-01-30 06:09:17,226.226] Batch Index : 1184
[2026-01-30 06:09:35,949.949] Epoch No: 1, Global Step: 000073, Train Loss: 6.238, Val Loss: 6.455

[2026-01-30 06:09:35,949.949] Total Tokens seen till now: 4843056

[2026-01-30 06:09:37,102.102] BEST model SAVED on iteration 000073 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:09:37,313.313] Once upon a time, upon a there?" was a and. take, the.
[2026-01-30 06:09:43,814.814] Gradient updated
[2026-01-30 06:09:43,814.814] Current Learning Rate : 5.410132689987937e-05
[2026-01-30 06:09:43,814.814] Global Step : 74
[2026-01-30 06:09:43,814.814] Batch Index : 1200
[2026-01-30 06:10:02,478.478] Epoch No: 1, Global Step: 000074, Train Loss: 6.197, Val Loss: 6.422

[2026-01-30 06:10:02,478.478] Total Tokens seen till now: 4908560

[2026-01-30 06:10:03,653.653] BEST model SAVED on iteration 000074 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:10:03,898.898] Once upon a time, day a a a a.
[2026-01-30 06:10:10,409.409] Gradient updated
[2026-01-30 06:10:10,409.409] Current Learning Rate : 5.4427020506634496e-05
[2026-01-30 06:10:10,409.409] Global Step : 75
[2026-01-30 06:10:10,409.409] Batch Index : 1216
[2026-01-30 06:10:29,207.207] Epoch No: 1, Global Step: 000075, Train Loss: 6.105, Val Loss: 6.389

[2026-01-30 06:10:29,208.208] Total Tokens seen till now: 4974064

[2026-01-30 06:10:30,449.449] BEST model SAVED on iteration 000075 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:10:30,943.943] Once upon a time, time was a, a the just a the., said. girl from.
[2026-01-30 06:10:37,448.448] Gradient updated
[2026-01-30 06:10:37,449.449] Current Learning Rate : 5.475271411338962e-05
[2026-01-30 06:10:37,449.449] Global Step : 76
[2026-01-30 06:10:37,449.449] Batch Index : 1232
[2026-01-30 06:10:56,103.103] Epoch No: 1, Global Step: 000076, Train Loss: 6.073, Val Loss: 6.357

[2026-01-30 06:10:56,104.104] Total Tokens seen till now: 5039504

[2026-01-30 06:10:57,229.229] BEST model SAVED on iteration 000076 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:10:57,254.254] Once upon a time, a
[2026-01-30 06:11:03,738.738] Gradient updated
[2026-01-30 06:11:03,739.739] Current Learning Rate : 5.5078407720144746e-05
[2026-01-30 06:11:03,740.740] Global Step : 77
[2026-01-30 06:11:03,740.740] Batch Index : 1248
[2026-01-30 06:11:22,394.394] Epoch No: 1, Global Step: 000077, Train Loss: 6.060, Val Loss: 6.326

[2026-01-30 06:11:22,395.395] Total Tokens seen till now: 5104912

[2026-01-30 06:11:23,526.526] BEST model SAVED on iteration 000077 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:11:23,660.660] Once upon a time, and a a a girl was,,, and and
[2026-01-30 06:11:30,131.131] Gradient updated
[2026-01-30 06:11:30,132.132] Current Learning Rate : 5.5404101326899874e-05
[2026-01-30 06:11:30,132.132] Global Step : 78
[2026-01-30 06:11:30,132.132] Batch Index : 1264
[2026-01-30 06:11:48,967.967] Epoch No: 1, Global Step: 000078, Train Loss: 6.042, Val Loss: 6.295

[2026-01-30 06:11:48,968.968] Total Tokens seen till now: 5170176

[2026-01-30 06:11:50,242.242] BEST model SAVED on iteration 000078 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:11:50,381.381] Once upon a time,, from a a big.
[2026-01-30 06:11:56,880.880] Gradient updated
[2026-01-30 06:11:56,881.881] Current Learning Rate : 5.5729794933655e-05
[2026-01-30 06:11:56,881.881] Global Step : 79
[2026-01-30 06:11:56,881.881] Batch Index : 1280
[2026-01-30 06:12:15,531.531] Epoch No: 1, Global Step: 000079, Train Loss: 6.040, Val Loss: 6.264

[2026-01-30 06:12:15,532.532] Total Tokens seen till now: 5235712

[2026-01-30 06:12:16,672.672] BEST model SAVED on iteration 000079 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:12:16,895.895] Once upon a time, a a came a from and came had there. He was,
[2026-01-30 06:12:23,403.403] Gradient updated
[2026-01-30 06:12:23,409.409] Current Learning Rate : 5.605548854041013e-05
[2026-01-30 06:12:23,409.409] Global Step : 80
[2026-01-30 06:12:23,409.409] Batch Index : 1296
[2026-01-30 06:12:42,061.061] Epoch No: 1, Global Step: 000080, Train Loss: 5.993, Val Loss: 6.233

[2026-01-30 06:12:42,062.062] Total Tokens seen till now: 5301248

[2026-01-30 06:12:43,201.201] BEST model SAVED on iteration 000080 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:12:43,761.761] Once upon a time, a a, was to. running.
[2026-01-30 06:12:50,271.271] Gradient updated
[2026-01-30 06:12:50,272.272] Current Learning Rate : 5.638118214716526e-05
[2026-01-30 06:12:50,272.272] Global Step : 81
[2026-01-30 06:12:50,272.272] Batch Index : 1312
[2026-01-30 06:13:09,104.104] Epoch No: 1, Global Step: 000081, Train Loss: 5.973, Val Loss: 6.201

[2026-01-30 06:13:09,104.104] Total Tokens seen till now: 5366784

[2026-01-30 06:13:10,364.364] BEST model SAVED on iteration 000081 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:13:10,486.486] Once upon a time,, lot time,,
[2026-01-30 06:13:16,961.961] Gradient updated
[2026-01-30 06:13:16,962.962] Current Learning Rate : 5.6706875753920386e-05
[2026-01-30 06:13:16,962.962] Global Step : 82
[2026-01-30 06:13:16,963.963] Batch Index : 1328
[2026-01-30 06:13:35,562.562] Epoch No: 1, Global Step: 000082, Train Loss: 5.913, Val Loss: 6.169

[2026-01-30 06:13:35,563.563] Total Tokens seen till now: 5431840

[2026-01-30 06:13:36,628.628] BEST model SAVED on iteration 000082 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:13:36,729.729] Once upon a time, was.
[2026-01-30 06:13:43,168.168] Gradient updated
[2026-01-30 06:13:43,169.169] Current Learning Rate : 5.703256936067551e-05
[2026-01-30 06:13:43,170.170] Global Step : 83
[2026-01-30 06:13:43,170.170] Batch Index : 1344
[2026-01-30 06:14:01,870.870] Epoch No: 1, Global Step: 000083, Train Loss: 5.907, Val Loss: 6.137

[2026-01-30 06:14:01,871.871] Total Tokens seen till now: 5496768

[2026-01-30 06:14:02,904.904] BEST model SAVED on iteration 000083 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:14:03,469.469] Once upon a time, was a The the could a not. boy and to The came They" to," go the. his to One to
[2026-01-30 06:14:09,976.976] Gradient updated
[2026-01-30 06:14:09,981.981] Current Learning Rate : 5.7358262967430636e-05
[2026-01-30 06:14:09,981.981] Global Step : 84
[2026-01-30 06:14:09,981.981] Batch Index : 1360
[2026-01-30 06:14:28,803.803] Epoch No: 1, Global Step: 000084, Train Loss: 5.827, Val Loss: 6.106

[2026-01-30 06:14:28,804.804] Total Tokens seen till now: 5562304

[2026-01-30 06:14:29,975.975] BEST model SAVED on iteration 000084 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:14:30,784.784] Once upon a time, a and was a was the the... then friend, . the just had and.
[2026-01-30 06:14:37,273.273] Gradient updated
[2026-01-30 06:14:37,274.274] Current Learning Rate : 5.768395657418576e-05
[2026-01-30 06:14:37,274.274] Global Step : 85
[2026-01-30 06:14:37,274.274] Batch Index : 1376
[2026-01-30 06:14:55,917.917] Epoch No: 1, Global Step: 000085, Train Loss: 5.929, Val Loss: 6.073

[2026-01-30 06:14:55,918.918] Total Tokens seen till now: 5627712

[2026-01-30 06:14:56,966.966] BEST model SAVED on iteration 000085 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:14:57,528.528] Once upon a time, time, came was was Tom a."The was. The girl One. girl. said.
[2026-01-30 06:15:04,027.027] Gradient updated
[2026-01-30 06:15:04,028.028] Current Learning Rate : 5.8009650180940886e-05
[2026-01-30 06:15:04,028.028] Global Step : 86
[2026-01-30 06:15:04,028.028] Batch Index : 1392
[2026-01-30 06:15:22,790.790] Epoch No: 1, Global Step: 000086, Train Loss: 5.834, Val Loss: 6.041

[2026-01-30 06:15:22,791.791] Total Tokens seen till now: 5693216

[2026-01-30 06:15:23,831.831] BEST model SAVED on iteration 000086 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:15:24,008.008] Once upon a time,, there was a came a. He.
[2026-01-30 06:15:30,503.503] Gradient updated
[2026-01-30 06:15:30,507.507] Current Learning Rate : 5.8335343787696014e-05
[2026-01-30 06:15:30,507.507] Global Step : 87
[2026-01-30 06:15:30,507.507] Batch Index : 1408
[2026-01-30 06:15:49,390.390] Epoch No: 1, Global Step: 000087, Train Loss: 5.789, Val Loss: 6.011

[2026-01-30 06:15:49,390.390] Total Tokens seen till now: 5758752

[2026-01-30 06:15:50,796.796] BEST model SAVED on iteration 000087 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:15:51,544.544] Once upon a time,,, was a, to,, to a his. He.TheThe and friend. boy to. to aThe. The to," to
[2026-01-30 06:15:57,988.988] Gradient updated
[2026-01-30 06:15:57,989.989] Current Learning Rate : 5.866103739445114e-05
[2026-01-30 06:15:57,989.989] Global Step : 88
[2026-01-30 06:15:57,989.989] Batch Index : 1424
[2026-01-30 06:16:16,644.644] Epoch No: 1, Global Step: 000088, Train Loss: 5.805, Val Loss: 5.982

[2026-01-30 06:16:16,645.645] Total Tokens seen till now: 5823728

[2026-01-30 06:16:17,708.708] BEST model SAVED on iteration 000088 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:16:18,104.104] Once upon a time, there a. said?" then.The of he?" the It day.
[2026-01-30 06:16:24,545.545] Gradient updated
[2026-01-30 06:16:24,546.546] Current Learning Rate : 5.898673100120627e-05
[2026-01-30 06:16:24,546.546] Global Step : 89
[2026-01-30 06:16:24,546.546] Batch Index : 1440
[2026-01-30 06:16:43,311.311] Epoch No: 1, Global Step: 000089, Train Loss: 5.711, Val Loss: 5.953

[2026-01-30 06:16:43,312.312] Total Tokens seen till now: 5888624

[2026-01-30 06:16:44,429.429] BEST model SAVED on iteration 000089 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:16:44,694.694] Once upon a time, there was a had the. the" to.
[2026-01-30 06:16:51,208.208] Gradient updated
[2026-01-30 06:16:51,209.209] Current Learning Rate : 5.93124246079614e-05
[2026-01-30 06:16:51,209.209] Global Step : 90
[2026-01-30 06:16:51,209.209] Batch Index : 1456
[2026-01-30 06:17:09,964.964] Epoch No: 1, Global Step: 000090, Train Loss: 5.687, Val Loss: 5.923

[2026-01-30 06:17:09,965.965] Total Tokens seen till now: 5954160

[2026-01-30 06:17:11,109.109] BEST model SAVED on iteration 000090 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:17:11,432.432] Once upon a time, a then smiled,, said were to a. He One?"
[2026-01-30 06:17:17,953.953] Gradient updated
[2026-01-30 06:17:17,954.954] Current Learning Rate : 5.963811821471652e-05
[2026-01-30 06:17:17,954.954] Global Step : 91
[2026-01-30 06:17:17,954.954] Batch Index : 1472
[2026-01-30 06:17:36,696.696] Epoch No: 1, Global Step: 000091, Train Loss: 5.621, Val Loss: 5.894

[2026-01-30 06:17:36,697.697] Total Tokens seen till now: 6019696

[2026-01-30 06:17:37,805.805] BEST model SAVED on iteration 000091 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:17:38,301.301] Once upon a time,, could a,.. He. She of. It. He came.. girl. take. She,. She and the his He.
[2026-01-30 06:17:44,812.812] Gradient updated
[2026-01-30 06:17:44,813.813] Current Learning Rate : 5.996381182147165e-05
[2026-01-30 06:17:44,813.813] Global Step : 92
[2026-01-30 06:17:44,813.813] Batch Index : 1488
[2026-01-30 06:18:03,736.736] Epoch No: 1, Global Step: 000092, Train Loss: 5.612, Val Loss: 5.865

[2026-01-30 06:18:03,736.736] Total Tokens seen till now: 6085232

[2026-01-30 06:18:04,794.794] BEST model SAVED on iteration 000092 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:18:05,087.087] Once upon a time, keep got box the the. some and. girl?" The and
[2026-01-30 06:18:11,609.609] Gradient updated
[2026-01-30 06:18:11,609.609] Current Learning Rate : 6.028950542822677e-05
[2026-01-30 06:18:11,609.609] Global Step : 93
[2026-01-30 06:18:11,609.609] Batch Index : 1504
[2026-01-30 06:18:30,327.327] Epoch No: 1, Global Step: 000093, Train Loss: 5.626, Val Loss: 5.836

[2026-01-30 06:18:30,327.327] Total Tokens seen till now: 6150768

[2026-01-30 06:18:31,511.511] BEST model SAVED on iteration 000093 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:18:31,908.908] Once upon a time, girl he. He a. for the.The to. She was to came smiled with then he he?" had and.
[2026-01-30 06:18:38,424.424] Gradient updated
[2026-01-30 06:18:38,425.425] Current Learning Rate : 6.06151990349819e-05
[2026-01-30 06:18:38,425.425] Global Step : 94
[2026-01-30 06:18:38,425.425] Batch Index : 1520
[2026-01-30 06:18:57,151.151] Epoch No: 1, Global Step: 000094, Train Loss: 5.622, Val Loss: 5.809

[2026-01-30 06:18:57,151.151] Total Tokens seen till now: 6216304

[2026-01-30 06:18:58,172.172] BEST model SAVED on iteration 000094 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:18:58,229.229] Once upon a time, there was a could
[2026-01-30 06:19:04,743.743] Gradient updated
[2026-01-30 06:19:04,743.743] Current Learning Rate : 6.0940892641737026e-05
[2026-01-30 06:19:04,743.743] Global Step : 95
[2026-01-30 06:19:04,743.743] Batch Index : 1536
[2026-01-30 06:19:23,629.629] Epoch No: 1, Global Step: 000095, Train Loss: 5.578, Val Loss: 5.780

[2026-01-30 06:19:23,629.629] Total Tokens seen till now: 6281840

[2026-01-30 06:19:24,648.648] BEST model SAVED on iteration 000095 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:19:25,195.195] Once upon a time, there was a a, then to to the,. boy, his girl. a,. She had came,.,"
[2026-01-30 06:19:31,668.668] Gradient updated
[2026-01-30 06:19:31,669.669] Current Learning Rate : 6.126658624849215e-05
[2026-01-30 06:19:31,669.669] Global Step : 96
[2026-01-30 06:19:31,669.669] Batch Index : 1552
[2026-01-30 06:19:50,403.403] Epoch No: 1, Global Step: 000096, Train Loss: 5.532, Val Loss: 5.752

[2026-01-30 06:19:50,404.404] Total Tokens seen till now: 6347056

[2026-01-30 06:19:51,454.454] BEST model SAVED on iteration 000096 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:19:51,522.522] Once upon a time, there there a?" special
[2026-01-30 06:19:58,042.042] Gradient updated
[2026-01-30 06:19:58,043.043] Current Learning Rate : 6.159227985524728e-05
[2026-01-30 06:19:58,043.043] Global Step : 97
[2026-01-30 06:19:58,043.043] Batch Index : 1568
[2026-01-30 06:20:16,741.741] Epoch No: 1, Global Step: 000097, Train Loss: 5.514, Val Loss: 5.724

[2026-01-30 06:20:16,741.741] Total Tokens seen till now: 6412592

[2026-01-30 06:20:17,798.798] BEST model SAVED on iteration 000097 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:20:18,179.179] Once upon a time, there a there was a a boy He boy the. and. the. He He and
[2026-01-30 06:20:24,693.693] Gradient updated
[2026-01-30 06:20:24,694.694] Current Learning Rate : 6.191797346200241e-05
[2026-01-30 06:20:24,694.694] Global Step : 98
[2026-01-30 06:20:24,694.694] Batch Index : 1584
[2026-01-30 06:20:43,529.529] Epoch No: 1, Global Step: 000098, Train Loss: 5.499, Val Loss: 5.697

[2026-01-30 06:20:43,530.530] Total Tokens seen till now: 6478128

[2026-01-30 06:20:44,566.566] BEST model SAVED on iteration 000098 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:20:45,245.245] Once upon a time, your,. He was a" to not. then the he. He of were,. a day to and the
[2026-01-30 06:20:51,762.762] Gradient updated
[2026-01-30 06:20:51,763.763] Current Learning Rate : 6.224366706875754e-05
[2026-01-30 06:20:51,763.763] Global Step : 99
[2026-01-30 06:20:51,763.763] Batch Index : 1600
[2026-01-30 06:21:10,488.488] Epoch No: 1, Global Step: 000099, Train Loss: 5.464, Val Loss: 5.670

[2026-01-30 06:21:10,489.489] Total Tokens seen till now: 6543664

[2026-01-30 06:21:11,540.540] BEST model SAVED on iteration 000099 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:21:12,095.095] Once upon a time, there was a was a boy.. He One. the the the One and were to, and. not was to the. 
[2026-01-30 06:21:18,604.604] Gradient updated
[2026-01-30 06:21:18,605.605] Current Learning Rate : 6.256936067551267e-05
[2026-01-30 06:21:18,605.605] Global Step : 100
[2026-01-30 06:21:18,605.605] Batch Index : 1616
[2026-01-30 06:21:37,295.295] Epoch No: 1, Global Step: 000100, Train Loss: 5.417, Val Loss: 5.643

[2026-01-30 06:21:37,296.296] Total Tokens seen till now: 6609200

[2026-01-30 06:21:38,397.397] BEST model SAVED on iteration 000100 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:21:38,476.476] Once upon a time,, there was a The and
[2026-01-30 06:21:44,942.942] Gradient updated
[2026-01-30 06:21:44,943.943] Current Learning Rate : 6.289505428226778e-05
[2026-01-30 06:21:44,943.943] Global Step : 101
[2026-01-30 06:21:44,943.943] Batch Index : 1632
[2026-01-30 06:22:03,774.774] Epoch No: 1, Global Step: 000101, Train Loss: 5.443, Val Loss: 5.615

[2026-01-30 06:22:03,775.775] Total Tokens seen till now: 6674208

[2026-01-30 06:22:04,841.841] BEST model SAVED on iteration 000101 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:22:05,657.657] Once upon a time,, time, there was and. One. He the had was Tom. went he to One the with to"."..
[2026-01-30 06:22:12,181.181] Gradient updated
[2026-01-30 06:22:12,181.181] Current Learning Rate : 6.322074788902291e-05
[2026-01-30 06:22:12,181.181] Global Step : 102
[2026-01-30 06:22:12,181.181] Batch Index : 1648
[2026-01-30 06:22:30,928.928] Epoch No: 1, Global Step: 000102, Train Loss: 5.431, Val Loss: 5.588

[2026-01-30 06:22:30,929.929] Total Tokens seen till now: 6739744

[2026-01-30 06:22:31,980.980] BEST model SAVED on iteration 000102 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:22:32,547.547] Once upon a time,, there was a was a It. then a.., to. He, to. It the then.. said day back girl was and day day to he.
[2026-01-30 06:22:39,061.061] Gradient updated
[2026-01-30 06:22:39,062.062] Current Learning Rate : 6.354644149577804e-05
[2026-01-30 06:22:39,062.062] Global Step : 103
[2026-01-30 06:22:39,062.062] Batch Index : 1664
[2026-01-30 06:22:57,810.810] Epoch No: 1, Global Step: 000103, Train Loss: 5.394, Val Loss: 5.559

[2026-01-30 06:22:57,811.811] Total Tokens seen till now: 6805280

[2026-01-30 06:22:58,868.868] BEST model SAVED on iteration 000103 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:22:59,366.366] Once upon a time, there was a a One then. It the he with the Tom was not then said girl of came was a, The had the, got girl the to,
[2026-01-30 06:23:05,874.874] Gradient updated
[2026-01-30 06:23:05,875.875] Current Learning Rate : 6.387213510253317e-05
[2026-01-30 06:23:05,875.875] Global Step : 104
[2026-01-30 06:23:05,876.876] Batch Index : 1680
[2026-01-30 06:23:24,606.606] Epoch No: 1, Global Step: 000104, Train Loss: 5.334, Val Loss: 5.532

[2026-01-30 06:23:24,607.607] Total Tokens seen till now: 6870720

[2026-01-30 06:23:26,096.096] BEST model SAVED on iteration 000104 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:23:26,608.608] Once upon a time, there was a got was. It, the girl the One was a was had. One. just the. said day, the
[2026-01-30 06:23:33,126.126] Gradient updated
[2026-01-30 06:23:33,126.126] Current Learning Rate : 6.41978287092883e-05
[2026-01-30 06:23:33,126.126] Global Step : 105
[2026-01-30 06:23:33,127.127] Batch Index : 1696
[2026-01-30 06:23:51,882.882] Epoch No: 1, Global Step: 000105, Train Loss: 5.313, Val Loss: 5.504

[2026-01-30 06:23:51,883.883] Total Tokens seen till now: 6936256

[2026-01-30 06:23:53,028.028] BEST model SAVED on iteration 000105 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:23:53,513.513] Once upon a time, there was a the.The a was a day a. They of. He was. It to was to to the the. and the. boy and..
[2026-01-30 06:23:59,964.964] Gradient updated
[2026-01-30 06:23:59,965.965] Current Learning Rate : 6.452352231604342e-05
[2026-01-30 06:23:59,965.965] Global Step : 106
[2026-01-30 06:23:59,965.965] Batch Index : 1712
[2026-01-30 06:24:18,907.907] Epoch No: 1, Global Step: 000106, Train Loss: 5.298, Val Loss: 5.477

[2026-01-30 06:24:18,908.908] Total Tokens seen till now: 7001088

[2026-01-30 06:24:20,147.147] BEST model SAVED on iteration 000106 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:24:21,010.010] Once upon a time, there was a a. He Tom, One and go to day and. They of. a was to the,." got the he he got said from go.
[2026-01-30 06:24:27,470.470] Gradient updated
[2026-01-30 06:24:27,470.470] Current Learning Rate : 6.484921592279855e-05
[2026-01-30 06:24:27,470.470] Global Step : 107
[2026-01-30 06:24:27,470.470] Batch Index : 1728
[2026-01-30 06:24:46,189.189] Epoch No: 1, Global Step: 000107, Train Loss: 5.290, Val Loss: 5.449

[2026-01-30 06:24:46,190.190] Total Tokens seen till now: 7065984

[2026-01-30 06:24:47,269.269] BEST model SAVED on iteration 000107 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:24:47,458.458] Once upon a time, there was a little.The to the The, girl was
[2026-01-30 06:24:53,973.973] Gradient updated
[2026-01-30 06:24:53,974.974] Current Learning Rate : 6.517490952955368e-05
[2026-01-30 06:24:53,974.974] Global Step : 108
[2026-01-30 06:24:53,974.974] Batch Index : 1744
[2026-01-30 06:25:12,644.644] Epoch No: 1, Global Step: 000108, Train Loss: 5.206, Val Loss: 5.422

[2026-01-30 06:25:12,645.645] Total Tokens seen till now: 7131520

[2026-01-30 06:25:13,789.789] BEST model SAVED on iteration 000108 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:25:14,354.354] Once upon a time, there was a  Tim., there was the." to. could, that said, were. smiled to to back the said.The was so and the, with with the, the.
[2026-01-30 06:25:20,877.877] Gradient updated
[2026-01-30 06:25:20,878.878] Current Learning Rate : 6.550060313630879e-05
[2026-01-30 06:25:20,878.878] Global Step : 109
[2026-01-30 06:25:20,878.878] Batch Index : 1760
[2026-01-30 06:25:39,647.647] Epoch No: 1, Global Step: 000109, Train Loss: 5.232, Val Loss: 5.396

[2026-01-30 06:25:39,647.647] Total Tokens seen till now: 7197056

[2026-01-30 06:25:41,067.067] BEST model SAVED on iteration 000109 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:25:41,619.619] Once upon a time,,?" a is. The.One. came a the was, the and the a girl. He, back.
[2026-01-30 06:25:48,146.146] Gradient updated
[2026-01-30 06:25:48,147.147] Current Learning Rate : 6.582629674306392e-05
[2026-01-30 06:25:48,147.147] Global Step : 110
[2026-01-30 06:25:48,147.147] Batch Index : 1776
[2026-01-30 06:26:06,860.860] Epoch No: 1, Global Step: 000110, Train Loss: 5.183, Val Loss: 5.369

[2026-01-30 06:26:06,860.860] Total Tokens seen till now: 7262592

[2026-01-30 06:26:08,011.011] BEST model SAVED on iteration 000110 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:26:08,581.581] Once upon a time, there was a little One was a was. He was. said. take, a big. He was from the.," was was the a a girl could was and a. had that said, to
[2026-01-30 06:26:15,104.104] Gradient updated
[2026-01-30 06:26:15,105.105] Current Learning Rate : 6.615199034981905e-05
[2026-01-30 06:26:15,105.105] Global Step : 111
[2026-01-30 06:26:15,105.105] Batch Index : 1792
[2026-01-30 06:26:33,913.913] Epoch No: 1, Global Step: 000111, Train Loss: 5.201, Val Loss: 5.342

[2026-01-30 06:26:33,913.913] Total Tokens seen till now: 7328128

[2026-01-30 06:26:35,076.076] BEST model SAVED on iteration 000111 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:26:35,855.855] Once upon a time, there was a was a. They named of. He was. the girl he to had. Tim was.  to the, to the, the he the to. take was a said of was said and the said was from,
[2026-01-30 06:26:42,375.375] Gradient updated
[2026-01-30 06:26:42,375.375] Current Learning Rate : 6.647768395657418e-05
[2026-01-30 06:26:42,375.375] Global Step : 112
[2026-01-30 06:26:42,375.375] Batch Index : 1808
[2026-01-30 06:27:01,137.137] Epoch No: 1, Global Step: 000112, Train Loss: 5.163, Val Loss: 5.317

[2026-01-30 06:27:01,138.138] Total Tokens seen till now: 7393664

[2026-01-30 06:27:02,207.207] BEST model SAVED on iteration 000112 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:27:02,789.789] Once upon a time, there was a little could. to her was and He to." the was a the was a were. smiled and of. boy had, the to the to.
[2026-01-30 06:27:09,294.294] Gradient updated
[2026-01-30 06:27:09,294.294] Current Learning Rate : 6.68033775633293e-05
[2026-01-30 06:27:09,295.295] Global Step : 113
[2026-01-30 06:27:09,295.295] Batch Index : 1824
[2026-01-30 06:27:28,119.119] Epoch No: 1, Global Step: 000113, Train Loss: 5.152, Val Loss: 5.292

[2026-01-30 06:27:28,120.120] Total Tokens seen till now: 7459008

[2026-01-30 06:27:29,193.193] BEST model SAVED on iteration 000113 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:27:29,759.759] Once upon a time, made Tom he he. smiled were a the He, girl, day to. the, said, the of a and the. the and, the his said girl the came was not came.
[2026-01-30 06:27:36,279.279] Gradient updated
[2026-01-30 06:27:36,280.280] Current Learning Rate : 6.712907117008443e-05
[2026-01-30 06:27:36,280.280] Global Step : 114
[2026-01-30 06:27:36,280.280] Batch Index : 1840
[2026-01-30 06:27:55,012.012] Epoch No: 1, Global Step: 000114, Train Loss: 5.103, Val Loss: 5.271

[2026-01-30 06:27:55,012.012] Total Tokens seen till now: 7524544

[2026-01-30 06:27:56,175.175] BEST model SAVED on iteration 000114 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:27:56,245.245] Once upon a time,, a, the a
[2026-01-30 06:28:02,757.757] Gradient updated
[2026-01-30 06:28:02,757.757] Current Learning Rate : 6.745476477683956e-05
[2026-01-30 06:28:02,757.757] Global Step : 115
[2026-01-30 06:28:02,758.758] Batch Index : 1856
[2026-01-30 06:28:21,557.557] Epoch No: 1, Global Step: 000115, Train Loss: 5.105, Val Loss: 5.247

[2026-01-30 06:28:21,557.557] Total Tokens seen till now: 7589856

[2026-01-30 06:28:22,658.658] BEST model SAVED on iteration 000115 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:28:22,737.737] Once upon a time, there was a was a.
[2026-01-30 06:28:29,258.258] Gradient updated
[2026-01-30 06:28:29,259.259] Current Learning Rate : 6.778045838359469e-05
[2026-01-30 06:28:29,259.259] Global Step : 116
[2026-01-30 06:28:29,259.259] Batch Index : 1872
[2026-01-30 06:28:48,013.013] Epoch No: 1, Global Step: 000116, Train Loss: 5.029, Val Loss: 5.221

[2026-01-30 06:28:48,014.014] Total Tokens seen till now: 7655376

[2026-01-30 06:28:49,086.086] BEST model SAVED on iteration 000116 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:28:49,656.656] Once upon a time, there was a had girl. She was and the the and with and so One the. The, the was and to was not. some to the was had got to. and and so, her a could
[2026-01-30 06:28:56,191.191] Gradient updated
[2026-01-30 06:28:56,192.192] Current Learning Rate : 6.810615199034982e-05
[2026-01-30 06:28:56,192.192] Global Step : 117
[2026-01-30 06:28:56,192.192] Batch Index : 1888
[2026-01-30 06:29:15,017.017] Epoch No: 1, Global Step: 000117, Train Loss: 5.041, Val Loss: 5.199

[2026-01-30 06:29:15,018.018] Total Tokens seen till now: 7720912

[2026-01-30 06:29:16,097.097] BEST model SAVED on iteration 000117 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:29:16,665.665] Once upon a time, there was a got could. day a He,, to., the for to. a had, and " the, fun to and her the.The and were had her not and so the He.
[2026-01-30 06:29:23,189.189] Gradient updated
[2026-01-30 06:29:23,190.190] Current Learning Rate : 6.843184559710493e-05
[2026-01-30 06:29:23,190.190] Global Step : 118
[2026-01-30 06:29:23,190.190] Batch Index : 1904
[2026-01-30 06:29:42,017.017] Epoch No: 1, Global Step: 000118, Train Loss: 5.041, Val Loss: 5.178

[2026-01-30 06:29:42,018.018] Total Tokens seen till now: 7786448

[2026-01-30 06:29:43,116.116] BEST model SAVED on iteration 000118 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:29:43,668.668] Once upon a time, there was a then One was of. big to the to the had to. He to, she of and he and the a had..  smiled day and said. and the and the,
[2026-01-30 06:29:50,136.136] Gradient updated
[2026-01-30 06:29:50,138.138] Current Learning Rate : 6.875753920386006e-05
[2026-01-30 06:29:50,138.138] Global Step : 119
[2026-01-30 06:29:50,139.139] Batch Index : 1920
[2026-01-30 06:30:09,021.021] Epoch No: 1, Global Step: 000119, Train Loss: 5.049, Val Loss: 5.154

[2026-01-30 06:30:09,022.022] Total Tokens seen till now: 7851376

[2026-01-30 06:30:10,290.290] BEST model SAVED on iteration 000119 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:30:11,063.063] Once upon a time, there was a to a the with the...The the The go?", day was of to and the He. She and and not the
[2026-01-30 06:30:17,529.529] Gradient updated
[2026-01-30 06:30:17,529.529] Current Learning Rate : 6.908323281061519e-05
[2026-01-30 06:30:17,529.529] Global Step : 120
[2026-01-30 06:30:17,529.529] Batch Index : 1936
[2026-01-30 06:30:36,294.294] Epoch No: 1, Global Step: 000120, Train Loss: 4.988, Val Loss: 5.135

[2026-01-30 06:30:36,294.294] Total Tokens seen till now: 7916176

[2026-01-30 06:30:37,457.457] BEST model SAVED on iteration 000120 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:30:38,011.011] Once upon a time, there was a named to. He It to play to could. He of said had, One her not and so He had said. He was a he he the.The, was with, but a
[2026-01-30 06:30:44,537.537] Gradient updated
[2026-01-30 06:30:44,538.538] Current Learning Rate : 6.940892641737032e-05
[2026-01-30 06:30:44,539.539] Global Step : 121
[2026-01-30 06:30:44,539.539] Batch Index : 1952
[2026-01-30 06:31:03,365.365] Epoch No: 1, Global Step: 000121, Train Loss: 4.937, Val Loss: 5.112

[2026-01-30 06:31:03,365.365] Total Tokens seen till now: 7981712

[2026-01-30 06:31:04,463.463] BEST model SAVED on iteration 000121 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:31:05,148.148] Once upon a time, there was a her. said, so a had. The day, the the of the was he. She,.The, the to. a day was was the day.", was
[2026-01-30 06:31:11,640.640] Gradient updated
[2026-01-30 06:31:11,641.641] Current Learning Rate : 6.973462002412545e-05
[2026-01-30 06:31:11,641.641] Global Step : 122
[2026-01-30 06:31:11,641.641] Batch Index : 1968
[2026-01-30 06:31:30,413.413] Epoch No: 1, Global Step: 000122, Train Loss: 4.926, Val Loss: 5.088

[2026-01-30 06:31:30,414.414] Total Tokens seen till now: 8046992

[2026-01-30 06:31:31,469.469] BEST model SAVED on iteration 000122 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:31:32,031.031] Once upon a time, there was a and named. girl big was a her. It. could day, he play?" He to play. He could to her. It and with the to day, she was a and the the.The were
[2026-01-30 06:31:38,541.541] Gradient updated
[2026-01-30 06:31:38,542.542] Current Learning Rate : 7.006031363088057e-05
[2026-01-30 06:31:38,542.542] Global Step : 123
[2026-01-30 06:31:38,542.542] Batch Index : 1984
[2026-01-30 06:31:57,313.313] Epoch No: 1, Global Step: 000123, Train Loss: 4.959, Val Loss: 5.071

[2026-01-30 06:31:57,314.314] Total Tokens seen till now: 8112368

[2026-01-30 06:31:58,362.362] BEST model SAVED on iteration 000123 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:31:58,935.935] Once upon a time, there was a and.The to had a girl a the the". She, the to the girl the. He day, and. said the. It a,
[2026-01-30 06:32:05,443.443] Gradient updated
[2026-01-30 06:32:05,444.444] Current Learning Rate : 7.03860072376357e-05
[2026-01-30 06:32:05,444.444] Global Step : 124
[2026-01-30 06:32:05,444.444] Batch Index : 2000
[2026-01-30 06:32:24,230.230] Epoch No: 1, Global Step: 000124, Train Loss: 4.957, Val Loss: 5.045

[2026-01-30 06:32:24,231.231] Total Tokens seen till now: 8177680

[2026-01-30 06:32:25,446.446] BEST model SAVED on iteration 000124 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:32:26,211.211] Once upon a time, there was a  girl to that, the, a had the the. One was not, they"" and then, said, the go girl the of the He and. day, had.," a a"
[2026-01-30 06:32:32,729.729] Gradient updated
[2026-01-30 06:32:32,731.731] Current Learning Rate : 7.071170084439083e-05
[2026-01-30 06:32:32,731.731] Global Step : 125
[2026-01-30 06:32:32,731.731] Batch Index : 2016
[2026-01-30 06:32:51,463.463] Epoch No: 1, Global Step: 000125, Train Loss: 4.868, Val Loss: 5.027

[2026-01-30 06:32:51,464.464] Total Tokens seen till now: 8243216

[2026-01-30 06:32:52,473.473] BEST model SAVED on iteration 000125 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:32:53,029.029] Once upon a time, there was a little named some. She he to a the was to the. smiled was a He. her to the had. She the. He was the The, the. girl said, he, had. a
[2026-01-30 06:32:59,548.548] Gradient updated
[2026-01-30 06:32:59,549.549] Current Learning Rate : 7.103739445114595e-05
[2026-01-30 06:32:59,549.549] Global Step : 126
[2026-01-30 06:32:59,549.549] Batch Index : 2032
[2026-01-30 06:33:18,339.339] Epoch No: 1, Global Step: 000126, Train Loss: 4.912, Val Loss: 5.007

[2026-01-30 06:33:18,340.340] Total Tokens seen till now: 8308752

[2026-01-30 06:33:19,413.413] BEST model SAVED on iteration 000126 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:33:20,054.054] Once upon a time, there was a  named girl her. She was and Lily. Tim girl a big that..The was a boy said, ". They was and the was with the not to so  said were to,
[2026-01-30 06:33:26,577.577] Gradient updated
[2026-01-30 06:33:26,578.578] Current Learning Rate : 7.136308805790107e-05
[2026-01-30 06:33:26,578.578] Global Step : 127
[2026-01-30 06:33:26,578.578] Batch Index : 2048
[2026-01-30 06:33:45,332.332] Epoch No: 1, Global Step: 000127, Train Loss: 4.850, Val Loss: 4.988

[2026-01-30 06:33:45,333.333] Total Tokens seen till now: 8374288

[2026-01-30 06:33:46,457.457] BEST model SAVED on iteration 000127 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:33:47,015.015] Once upon a time, there was a little girl One not It and.. He was a to the was with day. One to the and the said. he the, and but the a was a and a little girl and a. She was they then, the and
[2026-01-30 06:33:53,535.535] Gradient updated
[2026-01-30 06:33:53,536.536] Current Learning Rate : 7.16887816646562e-05
[2026-01-30 06:33:53,536.536] Global Step : 128
[2026-01-30 06:33:53,536.536] Batch Index : 2064
[2026-01-30 06:34:12,315.315] Epoch No: 1, Global Step: 000128, Train Loss: 4.866, Val Loss: 4.968

[2026-01-30 06:34:12,316.316] Total Tokens seen till now: 8439824

[2026-01-30 06:34:13,444.444] BEST model SAVED on iteration 000128 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:34:14,014.014] Once upon a time, there was a little." girl was a had. said, a was. boy. She. day, Lily and a to" a,. big girl to the had a and to the were. girl the said,
[2026-01-30 06:34:20,470.470] Gradient updated
[2026-01-30 06:34:20,471.471] Current Learning Rate : 7.201447527141133e-05
[2026-01-30 06:34:20,471.471] Global Step : 129
[2026-01-30 06:34:20,471.471] Batch Index : 2080
[2026-01-30 06:34:39,340.340] Epoch No: 1, Global Step: 000129, Train Loss: 4.849, Val Loss: 4.949

[2026-01-30 06:34:39,340.340] Total Tokens seen till now: 8504672

[2026-01-30 06:34:40,604.604] BEST model SAVED on iteration 000129 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:34:41,067.067] Once upon a time, there was a The named was the. She to the said her a The and said, her. The a was to the had and a
[2026-01-30 06:34:47,598.598] Gradient updated
[2026-01-30 06:34:47,598.598] Current Learning Rate : 7.234016887816646e-05
[2026-01-30 06:34:47,598.598] Global Step : 130
[2026-01-30 06:34:47,598.598] Batch Index : 2096
[2026-01-30 06:35:06,356.356] Epoch No: 1, Global Step: 000130, Train Loss: 4.807, Val Loss: 4.929

[2026-01-30 06:35:06,358.358] Total Tokens seen till now: 8570208

[2026-01-30 06:35:07,455.455] BEST model SAVED on iteration 000130 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:35:08,014.014] Once upon a time, there was a some.  big was a named Itmy and said. He was went a It was a little it. He to the was his to the had a boy. then a were.The,
[2026-01-30 06:35:14,535.535] Gradient updated
[2026-01-30 06:35:14,536.536] Current Learning Rate : 7.266586248492159e-05
[2026-01-30 06:35:14,536.536] Global Step : 131
[2026-01-30 06:35:14,536.536] Batch Index : 2112
[2026-01-30 06:35:33,382.382] Epoch No: 1, Global Step: 000131, Train Loss: 4.822, Val Loss: 4.911

[2026-01-30 06:35:33,383.383] Total Tokens seen till now: 8635744

[2026-01-30 06:35:34,491.491] BEST model SAVED on iteration 000131 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:35:35,161.161] Once upon a time, there was a little girl of named named for. She It was a play.", " his Ben, day, the a had the the.. They to the. They a with a a he
[2026-01-30 06:35:41,641.641] Gradient updated
[2026-01-30 06:35:41,642.642] Current Learning Rate : 7.299155609167671e-05
[2026-01-30 06:35:41,643.643] Global Step : 132
[2026-01-30 06:35:41,643.643] Batch Index : 2128
[2026-01-30 06:36:00,518.518] Epoch No: 1, Global Step: 000132, Train Loss: 4.718, Val Loss: 4.893

[2026-01-30 06:36:00,518.518] Total Tokens seen till now: 8701008

[2026-01-30 06:36:01,579.579] BEST model SAVED on iteration 000132 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:36:01,669.669] Once upon a time, there was a little girl could named
[2026-01-30 06:36:08,192.192] Gradient updated
[2026-01-30 06:36:08,193.193] Current Learning Rate : 7.331724969843184e-05
[2026-01-30 06:36:08,193.193] Global Step : 133
[2026-01-30 06:36:08,193.193] Batch Index : 2144
[2026-01-30 06:36:26,984.984] Epoch No: 1, Global Step: 000133, Train Loss: 4.785, Val Loss: 4.874

[2026-01-30 06:36:26,985.985] Total Tokens seen till now: 8766544

[2026-01-30 06:36:28,117.117] BEST model SAVED on iteration 000133 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:36:28,208.208] Once upon a time, there was a little girl named
[2026-01-30 06:36:34,730.730] Gradient updated
[2026-01-30 06:36:34,730.730] Current Learning Rate : 7.364294330518697e-05
[2026-01-30 06:36:34,730.730] Global Step : 134
[2026-01-30 06:36:34,731.731] Batch Index : 2160
[2026-01-30 06:36:53,710.710] Epoch No: 1, Global Step: 000134, Train Loss: 4.702, Val Loss: 4.857

[2026-01-30 06:36:53,711.711] Total Tokens seen till now: 8832080

[2026-01-30 06:36:54,880.880] BEST model SAVED on iteration 000134 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:36:55,760.760] Once upon a time, there was a is back. They and hadmy and". and then. He a was a said, the his a girl the to. The and the his., I the had a. a
[2026-01-30 06:37:02,291.291] Gradient updated
[2026-01-30 06:37:02,292.292] Current Learning Rate : 7.396863691194209e-05
[2026-01-30 06:37:02,292.292] Global Step : 135
[2026-01-30 06:37:02,292.292] Batch Index : 2176
[2026-01-30 06:37:21,031.031] Epoch No: 1, Global Step: 000135, Train Loss: 4.715, Val Loss: 4.835

[2026-01-30 06:37:21,031.031] Total Tokens seen till now: 8897616

[2026-01-30 06:37:22,149.149] BEST model SAVED on iteration 000135 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:37:22,717.717] Once upon a time, there day the girl a the a, the big a. to.  Ben and went then,.The the and a the the were girl the. I. She was. One the
[2026-01-30 06:37:29,188.188] Gradient updated
[2026-01-30 06:37:29,189.189] Current Learning Rate : 7.429433051869721e-05
[2026-01-30 06:37:29,189.189] Global Step : 136
[2026-01-30 06:37:29,189.189] Batch Index : 2192
[2026-01-30 06:37:47,926.926] Epoch No: 1, Global Step: 000136, Train Loss: 4.689, Val Loss: 4.816

[2026-01-30 06:37:47,927.927] Total Tokens seen till now: 8962704

[2026-01-30 06:37:49,107.107] BEST model SAVED on iteration 000136 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:37:49,696.696] Once upon a time, there was a little big. boy was a. One was a.. She was a big his to play to they the The, his with he. He. had was a,, " of not. It was
[2026-01-30 06:37:56,223.223] Gradient updated
[2026-01-30 06:37:56,224.224] Current Learning Rate : 7.462002412545234e-05
[2026-01-30 06:37:56,224.224] Global Step : 137
[2026-01-30 06:37:56,224.224] Batch Index : 2208
[2026-01-30 06:38:15,094.094] Epoch No: 1, Global Step: 000137, Train Loss: 4.657, Val Loss: 4.799

[2026-01-30 06:38:15,095.095] Total Tokens seen till now: 9028240

[2026-01-30 06:38:16,243.243] BEST model SAVED on iteration 000137 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:38:16,814.814] Once upon a time, there was a little named boy.. She was a little girl. to it it a Tim he. and day, One was a big is to the could a.The day, the it. She was day, "
[2026-01-30 06:38:23,422.422] Gradient updated
[2026-01-30 06:38:23,423.423] Current Learning Rate : 7.494571773220747e-05
[2026-01-30 06:38:23,423.423] Global Step : 138
[2026-01-30 06:38:23,423.423] Batch Index : 2224
[2026-01-30 06:38:42,150.150] Epoch No: 1, Global Step: 000138, Train Loss: 4.683, Val Loss: 4.779

[2026-01-30 06:38:42,151.151] Total Tokens seen till now: 9093344

[2026-01-30 06:38:43,225.225] BEST model SAVED on iteration 000138 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:38:43,779.779] Once upon a time, there was a little girl was so that. the It was she she said to. boy feltmy could. He was a said, day,. day the and the." a big and
[2026-01-30 06:38:50,309.309] Gradient updated
[2026-01-30 06:38:50,310.310] Current Learning Rate : 7.52714113389626e-05
[2026-01-30 06:38:50,310.310] Global Step : 139
[2026-01-30 06:38:50,310.310] Batch Index : 2240
[2026-01-30 06:39:09,171.171] Epoch No: 1, Global Step: 000139, Train Loss: 4.668, Val Loss: 4.762

[2026-01-30 06:39:09,172.172] Total Tokens seen till now: 9158880

[2026-01-30 06:39:10,364.364] BEST model SAVED on iteration 000139 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:39:11,183.183] Once upon a time, there was a girl was. She was a so One and he had a of he day. It loved to a big were theOne he, the He, and day, to the..The was, and
[2026-01-30 06:39:17,716.716] Gradient updated
[2026-01-30 06:39:17,716.716] Current Learning Rate : 7.559710494571773e-05
[2026-01-30 06:39:17,716.716] Global Step : 140
[2026-01-30 06:39:17,716.716] Batch Index : 2256
[2026-01-30 06:39:36,524.524] Epoch No: 1, Global Step: 000140, Train Loss: 4.671, Val Loss: 4.748

[2026-01-30 06:39:36,525.525] Total Tokens seen till now: 9224416

[2026-01-30 06:39:37,660.660] BEST model SAVED on iteration 000140 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:39:37,864.864] Once upon a time, there was a named big little. She with was a to go go of the
[2026-01-30 06:39:44,353.353] Gradient updated
[2026-01-30 06:39:44,354.354] Current Learning Rate : 7.592279855247285e-05
[2026-01-30 06:39:44,354.354] Global Step : 141
[2026-01-30 06:39:44,354.354] Batch Index : 2272
[2026-01-30 06:40:03,114.114] Epoch No: 1, Global Step: 000141, Train Loss: 4.594, Val Loss: 4.727

[2026-01-30 06:40:03,114.114] Total Tokens seen till now: 9289504

[2026-01-30 06:40:04,292.292] BEST model SAVED on iteration 000141 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:40:04,908.908] Once upon a time, there was a little girl named She. She was a She day, " that to play to. She was her the with the, he to day, and a big a her big. She she,, " the at
[2026-01-30 06:40:11,392.392] Gradient updated
[2026-01-30 06:40:11,393.393] Current Learning Rate : 7.624849215922798e-05
[2026-01-30 06:40:11,394.394] Global Step : 142
[2026-01-30 06:40:11,394.394] Batch Index : 2288
[2026-01-30 06:40:30,127.127] Epoch No: 1, Global Step: 000142, Train Loss: 4.628, Val Loss: 4.709

[2026-01-30 06:40:30,128.128] Total Tokens seen till now: 9354624

[2026-01-30 06:40:31,222.222] BEST model SAVED on iteration 000142 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:40:31,779.779] Once upon a time, there was a little girl named named. a day, ", " she was a day.One day, " Lily a girl a, for you a big and to take his he at of the.The could the
[2026-01-30 06:40:38,264.264] Gradient updated
[2026-01-30 06:40:38,265.265] Current Learning Rate : 7.65741857659831e-05
[2026-01-30 06:40:38,265.265] Global Step : 143
[2026-01-30 06:40:38,265.265] Batch Index : 2304
[2026-01-30 06:40:57,047.047] Epoch No: 1, Global Step: 000143, Train Loss: 4.620, Val Loss: 4.692

[2026-01-30 06:40:57,048.048] Total Tokens seen till now: 9419584

[2026-01-30 06:40:58,112.112] BEST model SAVED on iteration 000143 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:40:58,663.663] Once upon a time, there was a little girl. He was a to to the day, the little, was. It was day. One to do, the." and said, the so the girl and the big. She the of the were was a
[2026-01-30 06:41:05,192.192] Gradient updated
[2026-01-30 06:41:05,195.195] Current Learning Rate : 7.689987937273823e-05
[2026-01-30 06:41:05,195.195] Global Step : 144
[2026-01-30 06:41:05,195.195] Batch Index : 2320
[2026-01-30 06:41:24,133.133] Epoch No: 1, Global Step: 000144, Train Loss: 4.565, Val Loss: 4.671

[2026-01-30 06:41:24,133.133] Total Tokens seen till now: 9485120

[2026-01-30 06:41:25,386.386] BEST model SAVED on iteration 000144 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:41:26,161.161] Once upon a time, there was a little boy. She went to in the her a. day, had a had a big. He was. so day. He was the to the big. It day, " her to the little girl and. 
[2026-01-30 06:41:32,691.691] Gradient updated
[2026-01-30 06:41:32,692.692] Current Learning Rate : 7.722557297949335e-05
[2026-01-30 06:41:32,692.692] Global Step : 145
[2026-01-30 06:41:32,692.692] Batch Index : 2336
[2026-01-30 06:41:51,449.449] Epoch No: 1, Global Step: 000145, Train Loss: 4.554, Val Loss: 4.656

[2026-01-30 06:41:51,450.450] Total Tokens seen till now: 9550656

[2026-01-30 06:41:52,610.610] BEST model SAVED on iteration 000145 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:41:52,801.801] Once upon a time, there was a little named named. One was her to the and they he
[2026-01-30 06:41:59,327.327] Gradient updated
[2026-01-30 06:41:59,328.328] Current Learning Rate : 7.755126658624848e-05
[2026-01-30 06:41:59,328.328] Global Step : 146
[2026-01-30 06:41:59,328.328] Batch Index : 2352
[2026-01-30 06:42:18,096.096] Epoch No: 1, Global Step: 000146, Train Loss: 4.547, Val Loss: 4.638

[2026-01-30 06:42:18,097.097] Total Tokens seen till now: 9616192

[2026-01-30 06:42:19,263.263] BEST model SAVED on iteration 000146 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:42:19,849.849] Once upon a time, there was a little girl?" Lily. He was a small to the had a big and the and the big. then, " had to hermy were.", they a big. girl a was a.. He
[2026-01-30 06:42:26,380.380] Gradient updated
[2026-01-30 06:42:26,381.381] Current Learning Rate : 7.787696019300361e-05
[2026-01-30 06:42:26,381.381] Global Step : 147
[2026-01-30 06:42:26,381.381] Batch Index : 2368
[2026-01-30 06:42:45,174.174] Epoch No: 1, Global Step: 000147, Train Loss: 4.581, Val Loss: 4.618

[2026-01-30 06:42:45,175.175] Total Tokens seen till now: 9681728

[2026-01-30 06:42:46,257.257] BEST model SAVED on iteration 000147 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:42:46,654.654] Once upon a time, there named day " to. to the, he day, was a" a, but, ", the went a not a big.The little girl and the
[2026-01-30 06:42:53,180.180] Gradient updated
[2026-01-30 06:42:53,181.181] Current Learning Rate : 7.820265379975874e-05
[2026-01-30 06:42:53,181.181] Global Step : 148
[2026-01-30 06:42:53,181.181] Batch Index : 2384
[2026-01-30 06:43:11,974.974] Epoch No: 1, Global Step: 000148, Train Loss: 4.519, Val Loss: 4.605

[2026-01-30 06:43:11,975.975] Total Tokens seen till now: 9747264

[2026-01-30 06:43:13,086.086] BEST model SAVED on iteration 000148 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:43:13,642.642] Once upon a time, there was a little" girl day, the for a. He to" He, of the girl and said a little girl to.The were was was of the girl to the the too, day. a felt of
[2026-01-30 06:43:20,172.172] Gradient updated
[2026-01-30 06:43:20,173.173] Current Learning Rate : 7.852834740651387e-05
[2026-01-30 06:43:20,173.173] Global Step : 149
[2026-01-30 06:43:20,173.173] Batch Index : 2400
[2026-01-30 06:43:39,039.039] Epoch No: 1, Global Step: 000149, Train Loss: 4.545, Val Loss: 4.587

[2026-01-30 06:43:39,039.039] Total Tokens seen till now: 9812736

[2026-01-30 06:43:40,228.228] BEST model SAVED on iteration 000149 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:43:41,017.017] Once upon a time, there was a little girl named Lily. He was a big to to play. One day, day, her to they, they. The went was said, a little,. One day, a is a, big girl to go the little girl
[2026-01-30 06:43:47,498.498] Gradient updated
[2026-01-30 06:43:47,498.498] Current Learning Rate : 7.8854041013269e-05
[2026-01-30 06:43:47,498.498] Global Step : 150
[2026-01-30 06:43:47,498.498] Batch Index : 2416
[2026-01-30 06:44:06,235.235] Epoch No: 1, Global Step: 000150, Train Loss: 4.525, Val Loss: 4.569

[2026-01-30 06:44:06,236.236] Total Tokens seen till now: 9877920

[2026-01-30 06:44:07,358.358] BEST model SAVED on iteration 000150 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:44:07,934.934] Once upon a time, there was a little that. She saw a little girl. She and she was so that the boy. She was to play little girl was said, day, and she was the girl, and and and the with a to her
[2026-01-30 06:44:14,450.450] Gradient updated
[2026-01-30 06:44:14,451.451] Current Learning Rate : 7.917973462002412e-05
[2026-01-30 06:44:14,451.451] Global Step : 151
[2026-01-30 06:44:14,451.451] Batch Index : 2432
[2026-01-30 06:44:33,277.277] Epoch No: 1, Global Step: 000151, Train Loss: 4.466, Val Loss: 4.554

[2026-01-30 06:44:33,278.278] Total Tokens seen till now: 9943296

[2026-01-30 06:44:34,361.361] BEST model SAVED on iteration 000151 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:44:34,965.965] Once upon a time, there was a little girl named named what. He loved to play. She was so to the big. They to Tim to her with to the big. She said, ",, he was she to the very't the it. She of the
[2026-01-30 06:44:41,440.440] Gradient updated
[2026-01-30 06:44:41,441.441] Current Learning Rate : 7.950542822677924e-05
[2026-01-30 06:44:41,441.441] Global Step : 152
[2026-01-30 06:44:41,441.441] Batch Index : 2448
[2026-01-30 06:45:00,205.205] Epoch No: 1, Global Step: 000152, Train Loss: 4.430, Val Loss: 4.537

[2026-01-30 06:45:00,206.206] Total Tokens seen till now: 10008240

[2026-01-30 06:45:01,332.332] BEST model SAVED on iteration 000152 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:45:01,914.914] Once upon a time, there was a was so girl little girl. She was with something a girl to play and. He said, day, he was her went and a very she said, so his and a big. The was so said, a had she little
[2026-01-30 06:45:08,388.388] Gradient updated
[2026-01-30 06:45:08,389.389] Current Learning Rate : 7.983112183353437e-05
[2026-01-30 06:45:08,389.389] Global Step : 153
[2026-01-30 06:45:08,390.390] Batch Index : 2464
[2026-01-30 06:45:27,189.189] Epoch No: 1, Global Step: 000153, Train Loss: 4.465, Val Loss: 4.522

[2026-01-30 06:45:27,189.189] Total Tokens seen till now: 10073232

[2026-01-30 06:45:28,219.219] BEST model SAVED on iteration 000153 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:45:28,773.773] Once upon a time, there was a little girl named He. He and was a big.. One day, and the little Tim. The day, the. He to the big.The to the the was a. He saw the
[2026-01-30 06:45:35,307.307] Gradient updated
[2026-01-30 06:45:35,309.309] Current Learning Rate : 8.01568154402895e-05
[2026-01-30 06:45:35,309.309] Global Step : 154
[2026-01-30 06:45:35,309.309] Batch Index : 2480
[2026-01-30 06:45:54,234.234] Epoch No: 1, Global Step: 000154, Train Loss: 4.444, Val Loss: 4.506

[2026-01-30 06:45:54,234.234] Total Tokens seen till now: 10138768

[2026-01-30 06:45:55,442.442] BEST model SAVED on iteration 000154 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:45:56,214.214] Once upon a time, there was a a little girl named She. One they to day, to do girl to the and the little girl was to the. He was happy and and her and Lily not a big of a big, but wanted to.One day
[2026-01-30 06:46:02,702.702] Gradient updated
[2026-01-30 06:46:02,702.702] Current Learning Rate : 8.048250904704462e-05
[2026-01-30 06:46:02,702.702] Global Step : 155
[2026-01-30 06:46:02,702.702] Batch Index : 2496
[2026-01-30 06:46:21,492.492] Epoch No: 1, Global Step: 000155, Train Loss: 4.445, Val Loss: 4.489

[2026-01-30 06:46:21,492.492] Total Tokens seen till now: 10203920

[2026-01-30 06:46:22,651.651] BEST model SAVED on iteration 000155 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:46:23,233.233] Once upon a time, there was a little girl named a Timmy. She loved to a big, and the said, with. She to play to the had the day big. LilyOne day, he was had a of her you can that of the.
[2026-01-30 06:46:29,771.771] Gradient updated
[2026-01-30 06:46:29,772.772] Current Learning Rate : 8.080820265379975e-05
[2026-01-30 06:46:29,772.772] Global Step : 156
[2026-01-30 06:46:29,772.772] Batch Index : 2512
[2026-01-30 06:46:48,655.655] Epoch No: 1, Global Step: 000156, Train Loss: 4.454, Val Loss: 4.473

[2026-01-30 06:46:48,656.656] Total Tokens seen till now: 10269456

[2026-01-30 06:46:49,777.777] BEST model SAVED on iteration 000156 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:46:50,572.572] Once upon a time, there was a little girl named he. One was happy to her a a day, and it, he was to you big. She she could to, " of the can, said, and was to play with be. theily
[2026-01-30 06:46:57,088.088] Gradient updated
[2026-01-30 06:46:57,089.089] Current Learning Rate : 8.113389626055488e-05
[2026-01-30 06:46:57,089.089] Global Step : 157
[2026-01-30 06:46:57,089.089] Batch Index : 2528
[2026-01-30 06:47:15,846.846] Epoch No: 1, Global Step: 000157, Train Loss: 4.385, Val Loss: 4.459

[2026-01-30 06:47:15,846.846] Total Tokens seen till now: 10334768

[2026-01-30 06:47:16,927.927] BEST model SAVED on iteration 000157 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:47:17,493.493] Once upon a time, there was a little girl was a little girl. She, to and was a big, but the was a little girl. She was little girl were. She was she and her her said, so the were girl was so it. She in the
[2026-01-30 06:47:24,022.022] Gradient updated
[2026-01-30 06:47:24,023.023] Current Learning Rate : 8.145958986731e-05
[2026-01-30 06:47:24,023.023] Global Step : 158
[2026-01-30 06:47:24,023.023] Batch Index : 2544
[2026-01-30 06:47:42,850.850] Epoch No: 1, Global Step: 000158, Train Loss: 4.397, Val Loss: 4.442

[2026-01-30 06:47:42,851.851] Total Tokens seen till now: 10400304

[2026-01-30 06:47:44,002.002] BEST model SAVED on iteration 000158 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:47:44,592.592] Once upon a time, there was a little girl named day, and the and Lily. She was an so the is a special to his!The boy a day, the little girl was a big at." The was so it, and so wanted
[2026-01-30 06:47:51,113.113] Gradient updated
[2026-01-30 06:47:51,114.114] Current Learning Rate : 8.178528347406513e-05
[2026-01-30 06:47:51,114.114] Global Step : 159
[2026-01-30 06:47:51,114.114] Batch Index : 2560
[2026-01-30 06:48:09,983.983] Epoch No: 1, Global Step: 000159, Train Loss: 4.353, Val Loss: 4.430

[2026-01-30 06:48:09,983.983] Total Tokens seen till now: 10465840

[2026-01-30 06:48:11,095.095] BEST model SAVED on iteration 000159 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:48:11,662.662] Once upon a time, there was a little girl named Lily. One play was so Timmy to was and had a. He was too. a big and. They was so happy" little girl and and.The day, she. He
[2026-01-30 06:48:18,145.145] Gradient updated
[2026-01-30 06:48:18,146.146] Current Learning Rate : 8.211097708082025e-05
[2026-01-30 06:48:18,146.146] Global Step : 160
[2026-01-30 06:48:18,146.146] Batch Index : 2576
[2026-01-30 06:48:37,024.024] Epoch No: 1, Global Step: 000160, Train Loss: 4.388, Val Loss: 4.413

[2026-01-30 06:48:37,025.025] Total Tokens seen till now: 10531024

[2026-01-30 06:48:38,194.194] BEST model SAVED on iteration 000160 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:48:38,776.776] Once upon a time, there was a little girl named boy. Butmy was and a saw a big and the. The was so a big, of, Lily with a He in the a big the a big. The little girlM to play
[2026-01-30 06:48:45,250.250] Gradient updated
[2026-01-30 06:48:45,251.251] Current Learning Rate : 8.243667068757538e-05
[2026-01-30 06:48:45,251.251] Global Step : 161
[2026-01-30 06:48:45,251.251] Batch Index : 2592
[2026-01-30 06:49:04,231.231] Epoch No: 1, Global Step: 000161, Train Loss: 4.343, Val Loss: 4.400

[2026-01-30 06:49:04,231.231] Total Tokens seen till now: 10595984

[2026-01-30 06:49:05,442.442] BEST model SAVED on iteration 000161 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:49:06,312.312] Once upon a time, there was a little what named Ben. One day, ". She had to play. One day, " bird, he was so, a little girl was a big. He, it was so go, Lily." they.
[2026-01-30 06:49:12,845.845] Gradient updated
[2026-01-30 06:49:12,845.845] Current Learning Rate : 8.27623642943305e-05
[2026-01-30 06:49:12,845.845] Global Step : 162
[2026-01-30 06:49:12,845.845] Batch Index : 2608
[2026-01-30 06:49:31,730.730] Epoch No: 1, Global Step: 000162, Train Loss: 4.345, Val Loss: 4.384

[2026-01-30 06:49:31,731.731] Total Tokens seen till now: 10661520

[2026-01-30 06:49:32,815.815] BEST model SAVED on iteration 000162 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:49:33,382.382] Once upon a time, there was a little girl named Lily. Lily. She with her with the bird. She and day, she felt not go to to the at the big.  the saw a big his mom. She was so it went and a
[2026-01-30 06:49:37,299.299] BEST model SAVED on iteration 000162 to model/gpt2_GQA_preTrain_S_V1.pth..! 
[2026-01-30 06:49:37,301.301] Training completed in 88.66 minutes.
[2026-01-30 06:49:37,301.301] BEST Pre-trained custom model saved in model/gpt2_GQA_preTrain_S_V1.pth..!
[2026-01-30 06:49:37,301.301] Saving the plots of the metrics tracked ..!
[2026-01-30 06:49:38,274.274] Pipeline completed in 88.68 minutes.
