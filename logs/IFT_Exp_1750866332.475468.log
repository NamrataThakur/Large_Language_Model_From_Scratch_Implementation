[2025-06-25 21:15:32,475.475] Namespace(experiment_name='IFT_Exp', base_modelName='gpt2_355M', data_path='instruction-data-NT.json', training_type='IFT', peft_type=None, load_weights=True, pre_save_model=None, model_name='gpt2_355M_instruct_FineTuned', tokenizer='tiktoken', seed=123, batch_size=8, train_split=0.85, val_split=0.05, context_length=1024, max_new_tokens=100, temp=1, top_k=5, trainable_layers='None', num_epochs=2, max_training_length='longest_training_example', prompt_style='alpaca', ignore_index=-100, mask_instruction=True)
[2025-06-25 21:15:36,457.457] Configuration of the gpt2_355M base model loaded..!
[2025-06-25 21:15:36,457.457] Extention detected for the training file is "json".
[2025-06-25 21:15:36,457.457] Reading for .json files..!
[2025-06-25 21:15:36,457.457] Number of entries : 1100. 
[2025-06-25 21:15:36,457.457] Example of data for Instruct Fine-Tune :: 
 {'instruction': 'Name three forms of water.', 'input': '', 'output': 'The three forms of water are solid (ice), liquid (water), and gas (steam).'}
[2025-06-25 21:15:36,473.473] Training, Validation and Test Data created from the training file. Train data: 935, Val Data: 55, Test Data: 110
[2025-06-25 21:15:36,473.473] Loading the dataset class for instruction fine-tuning task...
[2025-06-25 21:15:37,715.715] ************** TRAIN DATALOADER ****************************
[2025-06-25 21:15:37,716.716] Length of Train Dataloader (number of batches): 116
[2025-06-25 21:15:38,327.327] torch.Size([8, 62]), torch.Size([8, 62])
[2025-06-25 21:15:38,327.327] torch.Size([8, 77]), torch.Size([8, 77])
[2025-06-25 21:15:38,327.327] torch.Size([8, 74]), torch.Size([8, 74])
[2025-06-25 21:15:38,327.327] torch.Size([8, 69]), torch.Size([8, 69])
[2025-06-25 21:15:38,327.327] torch.Size([8, 66]), torch.Size([8, 66])
[2025-06-25 21:15:38,327.327] ************** VAL DATALOADER ****************************
[2025-06-25 21:15:38,327.327] Length of Val Dataloader (number of batches): 6
[2025-06-25 21:15:38,340.340] torch.Size([8, 63]), torch.Size([8, 63])
[2025-06-25 21:15:38,341.341] torch.Size([8, 84]), torch.Size([8, 84])
[2025-06-25 21:15:38,341.341] torch.Size([8, 59]), torch.Size([8, 59])
[2025-06-25 21:15:38,341.341] torch.Size([8, 70]), torch.Size([8, 70])
[2025-06-25 21:15:38,341.341] torch.Size([8, 67]), torch.Size([8, 67])
[2025-06-25 21:15:38,341.341] ************** TEST DATALOADER ****************************
[2025-06-25 21:15:38,341.341] Length of Test Dataloader (number of batches): 13
[2025-06-25 21:15:38,341.341] torch.Size([8, 77]), torch.Size([8, 77])
[2025-06-25 21:15:38,341.341] torch.Size([8, 69]), torch.Size([8, 69])
[2025-06-25 21:15:38,341.341] torch.Size([8, 69]), torch.Size([8, 69])
[2025-06-25 21:15:38,341.341] torch.Size([8, 65]), torch.Size([8, 65])
[2025-06-25 21:15:38,341.341] torch.Size([8, 73]), torch.Size([8, 73])
[2025-06-25 21:15:38,341.341] Dataloaders created successfully for fine-tuning task..!
[2025-06-25 21:15:38,341.341] ---------------------------------------------------------
[2025-06-25 21:15:38,341.341] Loading the weights of the base model : gpt2_355M..!
[2025-06-25 21:15:38,355.355] Model present in the path: model/gpt2
[2025-06-25 21:26:59,470.470] Model weights loaded successfully..!
[2025-06-25 21:27:24,711.711] Generating a text :: 
Once upon a time, there were two things in the world. One was the earth, and another was the sun. The earth was the center of the universe, and the sun was its center. The moon was a reflection of the sun, but its light could not reach the earth, and it remained a shadow on the horizon. The sun, however, could not be seen from outside because its light could not reach it. The earth, then, was an invisible sphere, and the sun and moon, as the center
[2025-06-25 21:27:24,711.711] Instruction Fine-tuning the base model: gpt2_355M ..!
