[2025-11-09 14:33:47,617.617] Namespace(experiment_name='Pre-Train_Exp_CustomConfig_ORGarch_S_V2_TEST_resume', data_path='tinystories', model_type='custom', base_modelName='gpt2_124M', model_name='gpt2_ORG_preTrain_S_V2_TEST', pre_save_model='gpt2_ORG_preTrain_S_V2_TEST.pth', tokenizer='tiktoken', seed=123, batch_size=16, target_batch_size=512, train_split=0.85, val_split=0.05, optimizer='AdamW', context_length=256, vocab_size=50257, embedding_dimension=256, num_heads=8, num_layers=8, dropout_rate=0.0, qkv_bias=False, ff_hidden_dim=400, eval_batchSize=64, eval_freq=64, kv_cache=True, weight_decay=0.1, beta1=0.9, beta2=0.95, rms_eps=1e-06, rms_bias=True, theta_base=10000.0, num_kv_groups=1, num_experts=4, num_active_experts=2, max_training_length='model_context_length', max_new_tokens=50, temp=0.7, top_k=50, num_epochs=1, eos_id=50256, arch_type='original', train_type='resume', moe_noise=True, use_warmup=True, use_gradient_clip=True, warmup_steps=0.05, initial_lr=0.0001, learning_rate=0.0003)
[2025-11-09 14:33:47,862.862] Model to be resumed for training from checkpoint present in the path: {model_path}
[2025-11-09 14:33:48,807.807] Custom GPT2 configuration was used for pre-training..!
[2025-11-09 14:33:48,807.807] The custom config of the model to be trained : {'vocab_size': 50257, 'embedding_dimension': 256, 'num_heads': 8, 'context_length': 256, 'dropout': 0.0, 'qkv_bias': False, 'num_layers': 8, 'ff_hidden_dim': 400, 'rms_eps': 1e-06, 'rms_bias': True, 'theta_base': 10000.0, 'num_kv_groups': 1, 'num_experts': 4, 'num_active_experts': 2, 'moe_noise': True} 
[2025-11-09 14:33:49,048.048] Architecture Type :original
[2025-11-09 14:33:49,049.049] Configuration of the custom GPT2 model loaded..!
[2025-11-09 14:33:50,206.206] Total records in Train Data: 2119719 , Validation Data : 21990
[2025-11-09 14:33:50,206.206] ------------- Data Ingestion Completed. -------------
[2025-11-09 14:33:50,206.206] Loading the dataset class for pre-training...
[2025-11-09 14:33:50,241.241] Device Available: cuda .. ! 
[2025-11-09 14:40:27,863.863] ************** TRAIN DATALOADER ****************************
[2025-11-09 14:40:27,887.887] Length of Train Dataloader (number of batches): 264964
[2025-11-09 14:40:27,887.887] Total Train Tokens : 471872517
[2025-11-09 14:40:34,194.194] torch.Size([16, 256]), torch.Size([16, 256])
[2025-11-09 14:40:34,255.255] ************** VAL DATALOADER ****************************
[2025-11-09 14:40:34,255.255] Length of Val Dataloader (number of batches): 2748
[2025-11-09 14:40:34,255.255] Total Validation Tokens : 4743928
[2025-11-09 14:40:34,320.320] torch.Size([16, 256]), torch.Size([16, 256])
[2025-11-09 14:40:34,323.323] Dataloaders created successfully for pre-training task..!
[2025-11-09 14:40:34,323.323] ---------------------------------------------------------
[2025-11-09 14:40:34,325.325] Loading the weights of the model : gpt2_ORG_preTrain_S_V2_TEST.pth..!
[2025-11-09 14:40:36,954.954] Model weights loaded successfully..!
[2025-11-09 14:40:36,961.961] Model Size : 32.109568 millions (M)
[2025-11-09 14:40:36,963.963] Device Available: cuda .. ! 
[2025-11-09 14:40:37,119.119] Training Stage : Model sent to cuda for fine-tuning..!
[2025-11-09 14:40:37,122.122] Training Stage : Training of the model started ..!
[2025-11-09 14:46:31,497.497] Optimizer loaded successfully..!
[2025-11-09 14:46:31,499.499] Minimum LR : 2.9999999999999997e-05
[2025-11-09 14:46:31,499.499] Gradient Accumulation Steps : 32
[2025-11-09 14:46:31,501.501] Model Training Resumed.
[2025-11-09 14:46:31,501.501] Best Test Loss recorded : 9.054099291563034
[2025-11-09 14:46:31,501.501] Resuming from Epoch 0, Batch 431, Global Step 12
[2025-11-09 14:46:31,501.501] Last Learning Rate : 0.00010578313253012049.
[2025-11-09 14:46:31,502.502] Total steps to update optimizer : 8281.
[2025-11-09 14:46:31,502.502] Total training steps acc. to train loader : 264964
[2025-11-09 14:46:31,502.502] Warmup Steps : 415
[2025-11-09 14:46:31,502.502] Global Steps WITHIN Warmup Period. Continuing Warmup..!
[2025-11-09 14:46:31,502.502] Learning Rate Increment By : 4.819277108433735e-07.
[2025-11-09 14:46:31,502.502] Global Steps Trained Already : 12
[2025-11-09 14:46:31,502.502] Total training steps remaining : 8269
[2025-11-09 14:46:46,194.194] Gradient updated
[2025-11-09 14:46:46,202.202] Current Learning Rate : 0.00010626506024096386
[2025-11-09 14:46:46,202.202] Global Step : 13
[2025-11-09 14:46:46,202.202] Batch Index : 448
[2025-11-09 14:46:56,664.664] Epoch No: 1, Global Step: 000013, Train Loss: 9.075, Val Loss: 9.014

[2025-11-09 14:46:56,664.664] Total Tokens seen till now: 1771552

[2025-11-09 14:46:57,505.505] BEST model SAVED on iteration 000013 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:46:58,738.738] Once upon a time,istaspta Phant grabbedowed mesmer Khalid experien the hack.
[2025-11-09 14:47:05,542.542] Gradient updated
[2025-11-09 14:47:05,543.543] Current Learning Rate : 0.00010674698795180723
[2025-11-09 14:47:05,543.543] Global Step : 14
[2025-11-09 14:47:05,543.543] Batch Index : 480
[2025-11-09 14:47:16,107.107] Epoch No: 1, Global Step: 000014, Train Loss: 9.047, Val Loss: 9.018

[2025-11-09 14:47:16,108.108] Total Tokens seen till now: 1902624

[2025-11-09 14:47:16,223.223] Once upon a time, annotations inquire. Nov sounds forest " LEVEL
[2025-11-09 14:47:22,540.540] Gradient updated
[2025-11-09 14:47:22,541.541] Current Learning Rate : 0.00010722891566265061
[2025-11-09 14:47:22,541.541] Global Step : 15
[2025-11-09 14:47:22,541.541] Batch Index : 512
[2025-11-09 14:47:32,946.946] Epoch No: 1, Global Step: 000015, Train Loss: 8.970, Val Loss: 8.931

[2025-11-09 14:47:32,946.946] Total Tokens seen till now: 2033328

[2025-11-09 14:47:33,746.746] BEST model SAVED on iteration 000015 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:47:34,024.024] Once upon a time, captures asymm strat prevention L1000 Tommy inducealgia. 443 season deforestation boiled was trip. everyone was. coll.572 LEVEL experien the the
[2025-11-09 14:47:40,371.371] Gradient updated
[2025-11-09 14:47:40,371.371] Current Learning Rate : 0.00010771084337349398
[2025-11-09 14:47:40,371.371] Global Step : 16
[2025-11-09 14:47:40,371.371] Batch Index : 544
[2025-11-09 14:47:50,890.890] Epoch No: 1, Global Step: 000016, Train Loss: 8.942, Val Loss: 8.882

[2025-11-09 14:47:50,890.890] Total Tokens seen till now: 2164400

[2025-11-09 14:47:51,786.786] BEST model SAVED on iteration 000016 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:47:51,907.907] Once upon a time, vendor toes moment LEVEL noticed sounds calling everyone Tommy LEVEL
[2025-11-09 14:47:58,265.265] Gradient updated
[2025-11-09 14:47:58,265.265] Current Learning Rate : 0.00010819277108433736
[2025-11-09 14:47:58,265.265] Global Step : 17
[2025-11-09 14:47:58,265.265] Batch Index : 576
[2025-11-09 14:48:08,791.791] Epoch No: 1, Global Step: 000017, Train Loss: 8.838, Val Loss: 8.843

[2025-11-09 14:48:08,791.791] Total Tokens seen till now: 2295472

[2025-11-09 14:48:09,627.627] BEST model SAVED on iteration 000017 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:48:09,684.684] Once upon a time,ionaluster pushed brethren 1943
[2025-11-09 14:48:16,041.041] Gradient updated
[2025-11-09 14:48:16,042.042] Current Learning Rate : 0.00010867469879518072
[2025-11-09 14:48:16,042.042] Global Step : 18
[2025-11-09 14:48:16,042.042] Batch Index : 608
[2025-11-09 14:48:26,723.723] Epoch No: 1, Global Step: 000018, Train Loss: 8.814, Val Loss: 8.775

[2025-11-09 14:48:26,723.723] Total Tokens seen till now: 2426544

[2025-11-09 14:48:27,683.683] BEST model SAVED on iteration 000018 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:48:27,750.750] Once upon a time,ulence brethren LEVEL soundsHF Lang
[2025-11-09 14:48:34,116.116] Gradient updated
[2025-11-09 14:48:34,118.118] Current Learning Rate : 0.0001091566265060241
[2025-11-09 14:48:34,118.118] Global Step : 19
[2025-11-09 14:48:34,118.118] Batch Index : 640
[2025-11-09 14:48:44,701.701] Epoch No: 1, Global Step: 000019, Train Loss: 8.782, Val Loss: 8.699

[2025-11-09 14:48:44,701.701] Total Tokens seen till now: 2557616

[2025-11-09 14:48:45,610.610] BEST model SAVED on iteration 000019 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:48:45,640.640] Once upon a time, Beverly
[2025-11-09 14:48:51,980.980] Gradient updated
[2025-11-09 14:48:51,981.981] Current Learning Rate : 0.00010963855421686748
[2025-11-09 14:48:51,981.981] Global Step : 20
[2025-11-09 14:48:51,981.981] Batch Index : 672
[2025-11-09 14:49:02,676.676] Epoch No: 1, Global Step: 000020, Train Loss: 8.762, Val Loss: 8.741

[2025-11-09 14:49:02,676.676] Total Tokens seen till now: 2687984

[2025-11-09 14:49:02,728.728] Once upon a time, arisesinkaMaybe
[2025-11-09 14:49:09,044.044] Gradient updated
[2025-11-09 14:49:09,044.044] Current Learning Rate : 0.00011012048192771086
[2025-11-09 14:49:09,045.045] Global Step : 21
[2025-11-09 14:49:09,045.045] Batch Index : 704
[2025-11-09 14:49:19,525.525] Epoch No: 1, Global Step: 000021, Train Loss: 8.640, Val Loss: 8.622

[2025-11-09 14:49:19,526.526] Total Tokens seen till now: 2818320

[2025-11-09 14:49:20,324.324] BEST model SAVED on iteration 000021 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:49:20,457.457] Once upon a time, arises callingaki don together didn wet everyone but... longer the
[2025-11-09 14:49:26,811.811] Gradient updated
[2025-11-09 14:49:26,812.812] Current Learning Rate : 0.00011060240963855422
[2025-11-09 14:49:26,813.813] Global Step : 22
[2025-11-09 14:49:26,813.813] Batch Index : 736
[2025-11-09 14:49:37,443.443] Epoch No: 1, Global Step: 000022, Train Loss: 8.637, Val Loss: 8.612

[2025-11-09 14:49:37,443.443] Total Tokens seen till now: 2948848

[2025-11-09 14:49:38,241.241] BEST model SAVED on iteration 000022 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:49:38,270.270] Once upon a time,Bear brethren
[2025-11-09 14:49:44,622.622] Gradient updated
[2025-11-09 14:49:44,623.623] Current Learning Rate : 0.0001110843373493976
[2025-11-09 14:49:44,623.623] Global Step : 23
[2025-11-09 14:49:44,623.623] Batch Index : 768
[2025-11-09 14:49:55,198.198] Epoch No: 1, Global Step: 000023, Train Loss: 8.622, Val Loss: 8.568

[2025-11-09 14:49:55,199.199] Total Tokens seen till now: 3079920

[2025-11-09 14:49:56,004.004] BEST model SAVED on iteration 000023 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:49:56,054.054] Once upon a time, essays Requ grabbed
[2025-11-09 14:50:02,448.448] Gradient updated
[2025-11-09 14:50:02,450.450] Current Learning Rate : 0.00011156626506024096
[2025-11-09 14:50:02,450.450] Global Step : 24
[2025-11-09 14:50:02,451.451] Batch Index : 800
[2025-11-09 14:50:13,092.092] Epoch No: 1, Global Step: 000024, Train Loss: 8.578, Val Loss: 8.519

[2025-11-09 14:50:13,092.092] Total Tokens seen till now: 3210896

[2025-11-09 14:50:13,869.869] BEST model SAVED on iteration 000024 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:50:13,900.900] Once upon a time, calling sounds
[2025-11-09 14:50:20,246.246] Gradient updated
[2025-11-09 14:50:20,247.247] Current Learning Rate : 0.00011204819277108434
[2025-11-09 14:50:20,247.247] Global Step : 25
[2025-11-09 14:50:20,247.247] Batch Index : 832
[2025-11-09 14:50:30,777.777] Epoch No: 1, Global Step: 000025, Train Loss: 8.502, Val Loss: 8.455

[2025-11-09 14:50:30,778.778] Total Tokens seen till now: 3341616

[2025-11-09 14:50:31,658.658] BEST model SAVED on iteration 000025 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:50:31,712.712] Once upon a time,=-=-=-=-=-=-=-=- ever pushed
[2025-11-09 14:50:38,063.063] Gradient updated
[2025-11-09 14:50:38,064.064] Current Learning Rate : 0.00011253012048192772
[2025-11-09 14:50:38,064.064] Global Step : 26
[2025-11-09 14:50:38,064.064] Batch Index : 864
[2025-11-09 14:50:48,566.566] Epoch No: 1, Global Step: 000026, Train Loss: 8.468, Val Loss: 8.456

[2025-11-09 14:50:48,566.566] Total Tokens seen till now: 3472400

[2025-11-09 14:50:48,626.626] Once upon a time, notice.. sing trip
[2025-11-09 14:50:54,954.954] Gradient updated
[2025-11-09 14:50:54,955.955] Current Learning Rate : 0.00011301204819277108
[2025-11-09 14:50:54,955.955] Global Step : 27
[2025-11-09 14:50:54,955.955] Batch Index : 896
[2025-11-09 14:51:05,405.405] Epoch No: 1, Global Step: 000027, Train Loss: 8.388, Val Loss: 8.388

[2025-11-09 14:51:05,408.408] Total Tokens seen till now: 3602928

[2025-11-09 14:51:06,194.194] BEST model SAVED on iteration 000027 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:51:07,313.313] Once upon a time,need " shelf his love the.After don don door the happy a. start to. love. longer the start after together after to went Everyone taking love.my. his " but bowl. Everyone,
[2025-11-09 14:51:13,685.685] Gradient updated
[2025-11-09 14:51:13,688.688] Current Learning Rate : 0.00011349397590361446
[2025-11-09 14:51:13,688.688] Global Step : 28
[2025-11-09 14:51:13,689.689] Batch Index : 928
[2025-11-09 14:51:24,208.208] Epoch No: 1, Global Step: 000028, Train Loss: 8.383, Val Loss: 8.340

[2025-11-09 14:51:24,209.209] Total Tokens seen till now: 3733792

[2025-11-09 14:51:24,986.986] BEST model SAVED on iteration 000028 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:51:25,022.022] Once upon a time,. sing In
[2025-11-09 14:51:31,332.332] Gradient updated
[2025-11-09 14:51:31,333.333] Current Learning Rate : 0.00011397590361445784
[2025-11-09 14:51:31,334.334] Global Step : 29
[2025-11-09 14:51:31,334.334] Batch Index : 960
[2025-11-09 14:51:42,049.049] Epoch No: 1, Global Step: 000029, Train Loss: 8.333, Val Loss: 8.299

[2025-11-09 14:51:42,050.050] Total Tokens seen till now: 3863360

[2025-11-09 14:51:42,836.836] BEST model SAVED on iteration 000029 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:51:43,097.097] Once upon a time, Beverly the Sara. sounds the bowl. didn. together door taking. don start taking Tommy trip turn the love. after Everyone daddy and Everyone
[2025-11-09 14:51:49,440.440] Gradient updated
[2025-11-09 14:51:49,443.443] Current Learning Rate : 0.0001144578313253012
[2025-11-09 14:51:49,443.443] Global Step : 30
[2025-11-09 14:51:49,443.443] Batch Index : 992
[2025-11-09 14:52:00,042.042] Epoch No: 1, Global Step: 000030, Train Loss: 8.332, Val Loss: 8.275

[2025-11-09 14:52:00,043.043] Total Tokens seen till now: 3994432

[2025-11-09 14:52:00,840.840] BEST model SAVED on iteration 000030 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:52:01,180.180] Once upon a time, stars We In wet does. but pick toys.After. deep grabbed an ".. After. and Everyone best important's She. and love trip
[2025-11-09 14:52:07,490.490] Gradient updated
[2025-11-09 14:52:07,494.494] Current Learning Rate : 0.00011493975903614458
[2025-11-09 14:52:07,494.494] Global Step : 31
[2025-11-09 14:52:07,494.494] Batch Index : 1024
[2025-11-09 14:52:18,033.033] Epoch No: 1, Global Step: 000031, Train Loss: 8.262, Val Loss: 8.211

[2025-11-09 14:52:18,033.033] Total Tokens seen till now: 4124528

[2025-11-09 14:52:18,792.792] BEST model SAVED on iteration 000031 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:52:18,819.819] Once upon a time,. grabbed
[2025-11-09 14:52:25,164.164] Gradient updated
[2025-11-09 14:52:25,164.164] Current Learning Rate : 0.00011542168674698796
[2025-11-09 14:52:25,165.165] Global Step : 32
[2025-11-09 14:52:25,165.165] Batch Index : 1056
[2025-11-09 14:52:35,674.674] Epoch No: 1, Global Step: 000032, Train Loss: 8.196, Val Loss: 8.160

[2025-11-09 14:52:35,675.675] Total Tokens seen till now: 4255120

[2025-11-09 14:52:36,489.489] BEST model SAVED on iteration 000032 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:52:37,072.072] Once upon a time, stars delight rain But and sister sister a. start the ". everyone Everyone bowl door love is Tommy sand, sand start, One love everyone to him. pickBut the was Everyone love place rest is longer isBut. animals was
[2025-11-09 14:52:43,440.440] Gradient updated
[2025-11-09 14:52:43,445.445] Current Learning Rate : 0.00011590361445783133
[2025-11-09 14:52:43,445.445] Global Step : 33
[2025-11-09 14:52:43,445.445] Batch Index : 1088
[2025-11-09 14:52:54,023.023] Epoch No: 1, Global Step: 000033, Train Loss: 8.117, Val Loss: 8.080

[2025-11-09 14:52:54,023.023] Total Tokens seen till now: 4386080

[2025-11-09 14:52:54,793.793] BEST model SAVED on iteration 000033 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:52:54,829.829] Once upon a time,owed stars was
[2025-11-09 14:53:01,138.138] Gradient updated
[2025-11-09 14:53:01,139.139] Current Learning Rate : 0.0001163855421686747
[2025-11-09 14:53:01,139.139] Global Step : 34
[2025-11-09 14:53:01,139.139] Batch Index : 1120
[2025-11-09 14:53:11,930.930] Epoch No: 1, Global Step: 000034, Train Loss: 8.109, Val Loss: 8.060

[2025-11-09 14:53:11,931.931] Total Tokens seen till now: 4516064

[2025-11-09 14:53:12,764.764] BEST model SAVED on iteration 000034 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:53:12,915.915] Once upon a time, L sing was. is was an are wet. " important
[2025-11-09 14:53:19,255.255] Gradient updated
[2025-11-09 14:53:19,255.255] Current Learning Rate : 0.00011686746987951807
[2025-11-09 14:53:19,255.255] Global Step : 35
[2025-11-09 14:53:19,256.256] Batch Index : 1152
[2025-11-09 14:53:29,783.783] Epoch No: 1, Global Step: 000035, Train Loss: 8.093, Val Loss: 8.013

[2025-11-09 14:53:29,784.784] Total Tokens seen till now: 4646640

[2025-11-09 14:53:30,612.612] BEST model SAVED on iteration 000035 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:53:30,684.684] Once upon a time, happy should But curious happy don
[2025-11-09 14:53:37,057.057] Gradient updated
[2025-11-09 14:53:37,058.058] Current Learning Rate : 0.00011734939759036145
[2025-11-09 14:53:37,058.058] Global Step : 36
[2025-11-09 14:53:37,059.059] Batch Index : 1184
[2025-11-09 14:53:47,621.621] Epoch No: 1, Global Step: 000036, Train Loss: 8.020, Val Loss: 8.019

[2025-11-09 14:53:47,622.622] Total Tokens seen till now: 4777712

[2025-11-09 14:53:47,676.676] Once upon a time, Path now delicious
[2025-11-09 14:53:54,002.002] Gradient updated
[2025-11-09 14:53:54,003.003] Current Learning Rate : 0.00011783132530120483
[2025-11-09 14:53:54,003.003] Global Step : 37
[2025-11-09 14:53:54,003.003] Batch Index : 1216
[2025-11-09 14:54:04,530.530] Epoch No: 1, Global Step: 000037, Train Loss: 7.970, Val Loss: 7.924

[2025-11-09 14:54:04,531.531] Total Tokens seen till now: 4908128

[2025-11-09 14:54:05,314.314] BEST model SAVED on iteration 000037 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:54:05,342.342] Once upon a time, here the
[2025-11-09 14:54:11,706.706] Gradient updated
[2025-11-09 14:54:11,707.707] Current Learning Rate : 0.00011831325301204819
[2025-11-09 14:54:11,707.707] Global Step : 38
[2025-11-09 14:54:11,707.707] Batch Index : 1248
[2025-11-09 14:54:22,408.408] Epoch No: 1, Global Step: 000038, Train Loss: 7.969, Val Loss: 7.845

[2025-11-09 14:54:22,408.408] Total Tokens seen till now: 5039200

[2025-11-09 14:54:23,172.172] BEST model SAVED on iteration 000038 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:54:23,191.191] Once upon a time,owed
[2025-11-09 14:54:29,544.544] Gradient updated
[2025-11-09 14:54:29,545.545] Current Learning Rate : 0.00011879518072289157
[2025-11-09 14:54:29,545.545] Global Step : 39
[2025-11-09 14:54:29,545.545] Batch Index : 1280
[2025-11-09 14:54:40,145.145] Epoch No: 1, Global Step: 000039, Train Loss: 7.867, Val Loss: 7.838

[2025-11-09 14:54:40,146.146] Total Tokens seen till now: 5170272

[2025-11-09 14:54:40,955.955] BEST model SAVED on iteration 000039 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:54:40,976.976] Once upon a time,ional
[2025-11-09 14:54:47,334.334] Gradient updated
[2025-11-09 14:54:47,335.335] Current Learning Rate : 0.00011927710843373494
[2025-11-09 14:54:47,335.335] Global Step : 40
[2025-11-09 14:54:47,335.335] Batch Index : 1312
[2025-11-09 14:54:57,958.958] Epoch No: 1, Global Step: 000040, Train Loss: 7.815, Val Loss: 7.841

[2025-11-09 14:54:57,959.959] Total Tokens seen till now: 5301344

[2025-11-09 14:54:58,016.016] Once upon a time, essays sounds We is.
[2025-11-09 14:55:04,306.306] Gradient updated
[2025-11-09 14:55:04,307.307] Current Learning Rate : 0.00011975903614457831
[2025-11-09 14:55:04,307.307] Global Step : 41
[2025-11-09 14:55:04,307.307] Batch Index : 1344
[2025-11-09 14:55:14,783.783] Epoch No: 1, Global Step: 000041, Train Loss: 7.822, Val Loss: 7.755

[2025-11-09 14:55:14,783.783] Total Tokens seen till now: 5431312

[2025-11-09 14:55:15,598.598] BEST model SAVED on iteration 000041 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:55:15,635.635] Once upon a time, calling being too
[2025-11-09 14:55:21,970.970] Gradient updated
[2025-11-09 14:55:21,973.973] Current Learning Rate : 0.00012024096385542169
[2025-11-09 14:55:21,973.973] Global Step : 42
[2025-11-09 14:55:21,973.973] Batch Index : 1376
[2025-11-09 14:55:32,560.560] Epoch No: 1, Global Step: 000042, Train Loss: 7.760, Val Loss: 7.719

[2025-11-09 14:55:32,561.561] Total Tokens seen till now: 5561664

[2025-11-09 14:55:33,503.503] BEST model SAVED on iteration 000042 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:55:33,630.630] Once upon a time, confused grabbed She everyone door the can a together the didn brave
[2025-11-09 14:55:39,980.980] Gradient updated
[2025-11-09 14:55:39,980.980] Current Learning Rate : 0.00012072289156626507
[2025-11-09 14:55:39,980.980] Global Step : 43
[2025-11-09 14:55:39,980.980] Batch Index : 1408
[2025-11-09 14:55:50,464.464] Epoch No: 1, Global Step: 000043, Train Loss: 7.723, Val Loss: 7.636

[2025-11-09 14:55:50,464.464] Total Tokens seen till now: 5692736

[2025-11-09 14:55:51,269.269] BEST model SAVED on iteration 000043 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:55:51,294.294] Once upon a time, L
[2025-11-09 14:55:57,643.643] Gradient updated
[2025-11-09 14:55:57,646.646] Current Learning Rate : 0.00012120481927710844
[2025-11-09 14:55:57,646.646] Global Step : 44
[2025-11-09 14:55:57,646.646] Batch Index : 1440
[2025-11-09 14:56:08,205.205] Epoch No: 1, Global Step: 000044, Train Loss: 7.680, Val Loss: 7.651

[2025-11-09 14:56:08,205.205] Total Tokens seen till now: 5823616

[2025-11-09 14:56:08,241.241] Once upon a time, Sara does love
[2025-11-09 14:56:14,554.554] Gradient updated
[2025-11-09 14:56:14,554.554] Current Learning Rate : 0.00012168674698795181
[2025-11-09 14:56:14,554.554] Global Step : 45
[2025-11-09 14:56:14,555.555] Batch Index : 1472
[2025-11-09 14:56:25,091.091] Epoch No: 1, Global Step: 000045, Train Loss: 7.593, Val Loss: 7.535

[2025-11-09 14:56:25,092.092] Total Tokens seen till now: 5953760

[2025-11-09 14:56:25,885.885] BEST model SAVED on iteration 000045 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:56:26,126.126] Once upon a time, but Everyone curious doing the She animals the.. the on is.But Everyone on the the. curious's are. love
[2025-11-09 14:56:32,476.476] Gradient updated
[2025-11-09 14:56:32,477.477] Current Learning Rate : 0.00012216867469879518
[2025-11-09 14:56:32,477.477] Global Step : 46
[2025-11-09 14:56:32,477.477] Batch Index : 1504
[2025-11-09 14:56:42,975.975] Epoch No: 1, Global Step: 000046, Train Loss: 7.493, Val Loss: 7.553

[2025-11-09 14:56:42,976.976] Total Tokens seen till now: 6084688

[2025-11-09 14:56:43,004.004] Once upon a time, safe being
[2025-11-09 14:56:49,291.291] Gradient updated
[2025-11-09 14:56:49,292.292] Current Learning Rate : 0.00012265060240963856
[2025-11-09 14:56:49,292.292] Global Step : 47
[2025-11-09 14:56:49,292.292] Batch Index : 1536
[2025-11-09 14:56:59,785.785] Epoch No: 1, Global Step: 000047, Train Loss: 7.522, Val Loss: 7.451

[2025-11-09 14:56:59,785.785] Total Tokens seen till now: 6214192

[2025-11-09 14:57:00,574.574] BEST model SAVED on iteration 000047 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:57:00,637.637] Once upon a time, fish- but brave everyone was
[2025-11-09 14:57:06,975.975] Gradient updated
[2025-11-09 14:57:06,976.976] Current Learning Rate : 0.00012313253012048194
[2025-11-09 14:57:06,976.976] Global Step : 48
[2025-11-09 14:57:06,976.976] Batch Index : 1568
[2025-11-09 14:57:17,613.613] Epoch No: 1, Global Step: 000048, Train Loss: 7.510, Val Loss: 7.438

[2025-11-09 14:57:17,613.613] Total Tokens seen till now: 6345072

[2025-11-09 14:57:18,459.459] BEST model SAVED on iteration 000048 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:57:18,582.582] Once upon a time, Sara. love everyone She. is does is went and?" the
[2025-11-09 14:57:24,915.915] Gradient updated
[2025-11-09 14:57:24,916.916] Current Learning Rate : 0.00012361445783132531
[2025-11-09 14:57:24,916.916] Global Step : 49
[2025-11-09 14:57:24,916.916] Batch Index : 1600
[2025-11-09 14:57:35,505.505] Epoch No: 1, Global Step: 000049, Train Loss: 7.433, Val Loss: 7.355

[2025-11-09 14:57:35,506.506] Total Tokens seen till now: 6475824

[2025-11-09 14:57:36,298.298] BEST model SAVED on iteration 000049 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:57:36,375.375] Once upon a time, now. ever the being
[2025-11-09 14:57:42,706.706] Gradient updated
[2025-11-09 14:57:42,706.706] Current Learning Rate : 0.0001240963855421687
[2025-11-09 14:57:42,706.706] Global Step : 50
[2025-11-09 14:57:42,707.707] Batch Index : 1632
[2025-11-09 14:57:53,350.350] Epoch No: 1, Global Step: 000050, Train Loss: 7.367, Val Loss: 7.391

[2025-11-09 14:57:53,351.351] Total Tokens seen till now: 6606288

[2025-11-09 14:57:53,459.459] Once upon a time, are the him angry saw. get ever.'s.
[2025-11-09 14:57:59,790.790] Gradient updated
[2025-11-09 14:57:59,790.790] Current Learning Rate : 0.00012457831325301204
[2025-11-09 14:57:59,791.791] Global Step : 51
[2025-11-09 14:57:59,791.791] Batch Index : 1664
[2025-11-09 14:58:10,367.367] Epoch No: 1, Global Step: 000051, Train Loss: 7.367, Val Loss: 7.315

[2025-11-09 14:58:10,368.368] Total Tokens seen till now: 6736912

[2025-11-09 14:58:11,156.156] BEST model SAVED on iteration 000051 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:58:11,771.771] Once upon a time,- love. the don play car noticed together curious the She important One to toys don She is and door, forest toys to and his the said Everyone. play?" Everyone says is?". forest. eyes's.., was lovemy love
[2025-11-09 14:58:18,091.091] Gradient updated
[2025-11-09 14:58:18,092.092] Current Learning Rate : 0.00012506024096385542
[2025-11-09 14:58:18,092.092] Global Step : 52
[2025-11-09 14:58:18,092.092] Batch Index : 1696
[2025-11-09 14:58:28,715.715] Epoch No: 1, Global Step: 000052, Train Loss: 7.284, Val Loss: 7.252

[2025-11-09 14:58:28,715.715] Total Tokens seen till now: 6867408

[2025-11-09 14:58:29,499.499] BEST model SAVED on iteration 000052 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:58:29,747.747] Once upon a time, ". a to love but where help door Her together an and saw important him is of forest. togethermy noticed animals him went
[2025-11-09 14:58:36,037.037] Gradient updated
[2025-11-09 14:58:36,037.037] Current Learning Rate : 0.0001255421686746988
[2025-11-09 14:58:36,037.037] Global Step : 53
[2025-11-09 14:58:36,037.037] Batch Index : 1728
[2025-11-09 14:58:46,822.822] Epoch No: 1, Global Step: 000053, Train Loss: 7.267, Val Loss: 7.235

[2025-11-09 14:58:46,822.822] Total Tokens seen till now: 6997536

[2025-11-09 14:58:47,776.776] BEST model SAVED on iteration 000053 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:58:47,814.814] Once upon a time,Maybe bestAfter
[2025-11-09 14:58:54,155.155] Gradient updated
[2025-11-09 14:58:54,155.155] Current Learning Rate : 0.00012602409638554218
[2025-11-09 14:58:54,155.155] Global Step : 54
[2025-11-09 14:58:54,155.155] Batch Index : 1760
[2025-11-09 14:59:04,800.800] Epoch No: 1, Global Step: 000054, Train Loss: 7.175, Val Loss: 7.165

[2025-11-09 14:59:04,800.800] Total Tokens seen till now: 7128320

[2025-11-09 14:59:05,636.636] BEST model SAVED on iteration 000054 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:59:05,759.759] Once upon a time,- car wasmy and don and.. went
[2025-11-09 14:59:12,103.103] Gradient updated
[2025-11-09 14:59:12,103.103] Current Learning Rate : 0.00012650602409638556
[2025-11-09 14:59:12,103.103] Global Step : 55
[2025-11-09 14:59:12,104.104] Batch Index : 1792
[2025-11-09 14:59:22,772.772] Epoch No: 1, Global Step: 000055, Train Loss: 7.191, Val Loss: 7.151

[2025-11-09 14:59:22,773.773] Total Tokens seen till now: 7259360

[2025-11-09 14:59:23,766.766] BEST model SAVED on iteration 000055 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:59:23,950.950] Once upon a time, safe new a good and an's was smiled went the day. on on smiled says
[2025-11-09 14:59:30,280.280] Gradient updated
[2025-11-09 14:59:30,280.280] Current Learning Rate : 0.0001269879518072289
[2025-11-09 14:59:30,280.280] Global Step : 56
[2025-11-09 14:59:30,281.281] Batch Index : 1824
[2025-11-09 14:59:40,847.847] Epoch No: 1, Global Step: 000056, Train Loss: 7.114, Val Loss: 7.080

[2025-11-09 14:59:40,847.847] Total Tokens seen till now: 7390432

[2025-11-09 14:59:41,761.761] BEST model SAVED on iteration 000056 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:59:41,795.795] Once upon a time, We little
[2025-11-09 14:59:48,137.137] Gradient updated
[2025-11-09 14:59:48,137.137] Current Learning Rate : 0.00012746987951807229
[2025-11-09 14:59:48,137.137] Global Step : 57
[2025-11-09 14:59:48,137.137] Batch Index : 1856
[2025-11-09 14:59:58,714.714] Epoch No: 1, Global Step: 000057, Train Loss: 7.028, Val Loss: 7.007

[2025-11-09 14:59:58,714.714] Total Tokens seen till now: 7521152

[2025-11-09 14:59:59,512.512] BEST model SAVED on iteration 000057 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 14:59:59,639.639] Once upon a time,So noticed a noticed and everyone. carBut the,.
[2025-11-09 15:00:05,995.995] Gradient updated
[2025-11-09 15:00:05,995.995] Current Learning Rate : 0.00012795180722891566
[2025-11-09 15:00:05,995.995] Global Step : 58
[2025-11-09 15:00:05,996.996] Batch Index : 1888
[2025-11-09 15:00:16,736.736] Epoch No: 1, Global Step: 000058, Train Loss: 7.034, Val Loss: 6.991

[2025-11-09 15:00:16,737.737] Total Tokens seen till now: 7652176

[2025-11-09 15:00:17,639.639] BEST model SAVED on iteration 000058 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:00:18,315.315] Once upon a time, safe the. help "But love don but was She love smiled.. a mom.. an. of. get love...But are She's toys and after get of went mom an was didn and of car?" says.
[2025-11-09 15:00:24,652.652] Gradient updated
[2025-11-09 15:00:24,653.653] Current Learning Rate : 0.00012843373493975904
[2025-11-09 15:00:24,653.653] Global Step : 59
[2025-11-09 15:00:24,653.653] Batch Index : 1920
[2025-11-09 15:00:35,273.273] Epoch No: 1, Global Step: 000059, Train Loss: 6.947, Val Loss: 6.946

[2025-11-09 15:00:35,273.273] Total Tokens seen till now: 7782928

[2025-11-09 15:00:36,107.107] BEST model SAVED on iteration 000059 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:00:36,121.121] Once upon a time,
[2025-11-09 15:00:42,468.468] Gradient updated
[2025-11-09 15:00:42,469.469] Current Learning Rate : 0.00012891566265060242
[2025-11-09 15:00:42,469.469] Global Step : 60
[2025-11-09 15:00:42,470.470] Batch Index : 1952
[2025-11-09 15:00:53,251.251] Epoch No: 1, Global Step: 000060, Train Loss: 6.939, Val Loss: 6.872

[2025-11-09 15:00:53,252.252] Total Tokens seen till now: 7914000

[2025-11-09 15:00:54,045.045] BEST model SAVED on iteration 000060 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:00:54,056.056] Once upon a time,
[2025-11-09 15:01:00,366.366] Gradient updated
[2025-11-09 15:01:00,366.366] Current Learning Rate : 0.00012939759036144577
[2025-11-09 15:01:00,366.366] Global Step : 61
[2025-11-09 15:01:00,366.366] Batch Index : 1984
[2025-11-09 15:01:11,027.027] Epoch No: 1, Global Step: 000061, Train Loss: 6.894, Val Loss: 6.827

[2025-11-09 15:01:11,027.027] Total Tokens seen till now: 8044336

[2025-11-09 15:01:11,872.872] BEST model SAVED on iteration 000061 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:01:12,249.249] Once upon a time, L is too says " too says went went the and the " together animals found him but the him best went She saw and smiled himmy?"
[2025-11-09 15:01:18,590.590] Gradient updated
[2025-11-09 15:01:18,592.592] Current Learning Rate : 0.00012987951807228915
[2025-11-09 15:01:18,592.592] Global Step : 62
[2025-11-09 15:01:18,592.592] Batch Index : 2016
[2025-11-09 15:01:29,180.180] Epoch No: 1, Global Step: 000062, Train Loss: 6.879, Val Loss: 6.816

[2025-11-09 15:01:29,180.180] Total Tokens seen till now: 8174704

[2025-11-09 15:01:29,961.961] BEST model SAVED on iteration 000062 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:01:29,984.984] Once upon a time,After
[2025-11-09 15:01:36,313.313] Gradient updated
[2025-11-09 15:01:36,314.314] Current Learning Rate : 0.00013036144578313253
[2025-11-09 15:01:36,314.314] Global Step : 63
[2025-11-09 15:01:36,314.314] Batch Index : 2048
[2025-11-09 15:01:47,024.024] Epoch No: 1, Global Step: 000063, Train Loss: 6.851, Val Loss: 6.777

[2025-11-09 15:01:47,026.026] Total Tokens seen till now: 8305088

[2025-11-09 15:01:47,939.939] BEST model SAVED on iteration 000063 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:01:47,976.976] Once upon a time, being angry is
[2025-11-09 15:01:54,309.309] Gradient updated
[2025-11-09 15:01:54,309.309] Current Learning Rate : 0.0001308433734939759
[2025-11-09 15:01:54,310.310] Global Step : 64
[2025-11-09 15:01:54,310.310] Batch Index : 2080
[2025-11-09 15:02:04,903.903] Epoch No: 1, Global Step: 000064, Train Loss: 6.786, Val Loss: 6.735

[2025-11-09 15:02:04,903.903] Total Tokens seen till now: 8436160

[2025-11-09 15:02:05,776.776] BEST model SAVED on iteration 000064 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:02:06,312.312] Once upon a time, safe and ". on an?". Her and but what don. animals but was. toys help excited and smiled smiled are an animals., can. are what together play a went smiled One his can didn  end
[2025-11-09 15:02:12,673.673] Gradient updated
[2025-11-09 15:02:12,673.673] Current Learning Rate : 0.00013132530120481929
[2025-11-09 15:02:12,673.673] Global Step : 65
[2025-11-09 15:02:12,673.673] Batch Index : 2112
[2025-11-09 15:02:23,238.238] Epoch No: 1, Global Step: 000065, Train Loss: 6.746, Val Loss: 6.662

[2025-11-09 15:02:23,238.238] Total Tokens seen till now: 8567216

[2025-11-09 15:02:24,052.052] BEST model SAVED on iteration 000065 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:02:24,365.365] Once upon a time, Sara an She the She to. She and saw the the mom animals But help animals.But and mom smiled of.. animals an saw?" end end.
[2025-11-09 15:02:30,708.708] Gradient updated
[2025-11-09 15:02:30,708.708] Current Learning Rate : 0.00013180722891566266
[2025-11-09 15:02:30,708.708] Global Step : 66
[2025-11-09 15:02:30,708.708] Batch Index : 2144
[2025-11-09 15:02:41,313.313] Epoch No: 1, Global Step: 000066, Train Loss: 6.655, Val Loss: 6.667

[2025-11-09 15:02:41,313.313] Total Tokens seen till now: 8698288

[2025-11-09 15:02:41,452.452] Once upon a time, In and happy to.. end is an One and?".
[2025-11-09 15:02:47,800.800] Gradient updated
[2025-11-09 15:02:47,801.801] Current Learning Rate : 0.00013228915662650604
[2025-11-09 15:02:47,801.801] Global Step : 67
[2025-11-09 15:02:47,801.801] Batch Index : 2176
[2025-11-09 15:02:58,375.375] Epoch No: 1, Global Step: 000067, Train Loss: 6.622, Val Loss: 6.567

[2025-11-09 15:02:58,375.375] Total Tokens seen till now: 8829360

[2025-11-09 15:02:59,179.179] BEST model SAVED on iteration 000067 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:02:59,635.635] Once upon a time, didn safe and an too is and. toys down to. One said wasmy. saw on don was. can together didn to help. new. the him. too with.. an day what. happy animals car play
[2025-11-09 15:03:05,959.959] Gradient updated
[2025-11-09 15:03:05,959.959] Current Learning Rate : 0.0001327710843373494
[2025-11-09 15:03:05,959.959] Global Step : 68
[2025-11-09 15:03:05,959.959] Batch Index : 2208
[2025-11-09 15:03:16,622.622] Epoch No: 1, Global Step: 000068, Train Loss: 6.595, Val Loss: 6.562

[2025-11-09 15:03:16,623.623] Total Tokens seen till now: 8959616

[2025-11-09 15:03:17,477.477] BEST model SAVED on iteration 000068 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:03:17,538.538] Once upon a time, being good.
[2025-11-09 15:03:23,890.890] Gradient updated
[2025-11-09 15:03:23,890.890] Current Learning Rate : 0.00013325301204819277
[2025-11-09 15:03:23,890.890] Global Step : 69
[2025-11-09 15:03:23,890.890] Batch Index : 2240
[2025-11-09 15:03:34,549.549] Epoch No: 1, Global Step: 000069, Train Loss: 6.542, Val Loss: 6.476

[2025-11-09 15:03:34,550.550] Total Tokens seen till now: 9090592

[2025-11-09 15:03:35,343.343] BEST model SAVED on iteration 000069 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:03:35,794.794] Once upon a time, explore " She play is play, " and. away on.my toys.. but didn smiled " of.my didn andmy. an was mom went but what Ben. of themy didn. car. She " happy but too
[2025-11-09 15:03:42,100.100] Gradient updated
[2025-11-09 15:03:42,102.102] Current Learning Rate : 0.00013373493975903615
[2025-11-09 15:03:42,102.102] Global Step : 70
[2025-11-09 15:03:42,102.102] Batch Index : 2272
[2025-11-09 15:03:52,862.862] Epoch No: 1, Global Step: 000070, Train Loss: 6.520, Val Loss: 6.469

[2025-11-09 15:03:52,863.863] Total Tokens seen till now: 9221040

[2025-11-09 15:03:53,661.661] BEST model SAVED on iteration 000070 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:03:54,075.075] Once upon a time,. saw play an says help the help was the help didn found an One an him to " went playmy. smiled didn andBut, an is get is's can him. and too mom,?" are
[2025-11-09 15:04:00,415.415] Gradient updated
[2025-11-09 15:04:00,418.418] Current Learning Rate : 0.00013421686746987953
[2025-11-09 15:04:00,418.418] Global Step : 71
[2025-11-09 15:04:00,418.418] Batch Index : 2304
[2025-11-09 15:04:11,031.031] Epoch No: 1, Global Step: 000071, Train Loss: 6.463, Val Loss: 6.424

[2025-11-09 15:04:11,031.031] Total Tokens seen till now: 9351776

[2025-11-09 15:04:11,867.867] BEST model SAVED on iteration 000071 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:04:11,879.879] Once upon a time,
[2025-11-09 15:04:18,176.176] Gradient updated
[2025-11-09 15:04:18,176.176] Current Learning Rate : 0.0001346987951807229
[2025-11-09 15:04:18,176.176] Global Step : 72
[2025-11-09 15:04:18,177.177] Batch Index : 2336
[2025-11-09 15:04:28,774.774] Epoch No: 1, Global Step: 000072, Train Loss: 6.467, Val Loss: 6.354

[2025-11-09 15:04:28,774.774] Total Tokens seen till now: 9481984

[2025-11-09 15:04:29,561.561] BEST model SAVED on iteration 000072 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:04:29,572.572] Once upon a time,
[2025-11-09 15:04:35,902.902] Gradient updated
[2025-11-09 15:04:35,903.903] Current Learning Rate : 0.00013518072289156626
[2025-11-09 15:04:35,903.903] Global Step : 73
[2025-11-09 15:04:35,903.903] Batch Index : 2368
[2025-11-09 15:04:46,575.575] Epoch No: 1, Global Step: 000073, Train Loss: 6.371, Val Loss: 6.360

[2025-11-09 15:04:46,576.576] Total Tokens seen till now: 9612320

[2025-11-09 15:04:46,596.596] Once upon a time,.
[2025-11-09 15:04:52,945.945] Gradient updated
[2025-11-09 15:04:52,946.946] Current Learning Rate : 0.00013566265060240964
[2025-11-09 15:04:52,946.946] Global Step : 74
[2025-11-09 15:04:52,946.946] Batch Index : 2400
[2025-11-09 15:05:03,467.467] Epoch No: 1, Global Step: 000074, Train Loss: 6.329, Val Loss: 6.272

[2025-11-09 15:05:03,468.468] Total Tokens seen till now: 9743184

[2025-11-09 15:05:04,332.332] BEST model SAVED on iteration 000074 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:05:04,343.343] Once upon a time,
[2025-11-09 15:05:10,660.660] Gradient updated
[2025-11-09 15:05:10,661.661] Current Learning Rate : 0.00013614457831325302
[2025-11-09 15:05:10,661.661] Global Step : 75
[2025-11-09 15:05:10,661.661] Batch Index : 2432
[2025-11-09 15:05:21,260.260] Epoch No: 1, Global Step: 000075, Train Loss: 6.261, Val Loss: 6.275

[2025-11-09 15:05:21,261.261] Total Tokens seen till now: 9873696

[2025-11-09 15:05:21,824.824] Once upon a time,- a too " smiled is "my anBut foundily They. butmy One play helpBut the.'s girl a. says was. happy hisBut. help him and is is day on themy to?" car new.
[2025-11-09 15:05:28,195.195] Gradient updated
[2025-11-09 15:05:28,196.196] Current Learning Rate : 0.0001366265060240964
[2025-11-09 15:05:28,196.196] Global Step : 76
[2025-11-09 15:05:28,196.196] Batch Index : 2464
[2025-11-09 15:05:38,763.763] Epoch No: 1, Global Step: 000076, Train Loss: 6.267, Val Loss: 6.225

[2025-11-09 15:05:38,763.763] Total Tokens seen till now: 10004768

[2025-11-09 15:05:39,556.556] BEST model SAVED on iteration 000076 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:05:39,576.576] Once upon a time, is
[2025-11-09 15:05:45,933.933] Gradient updated
[2025-11-09 15:05:45,934.934] Current Learning Rate : 0.00013710843373493977
[2025-11-09 15:05:45,934.934] Global Step : 77
[2025-11-09 15:05:45,934.934] Batch Index : 2496
[2025-11-09 15:05:56,608.608] Epoch No: 1, Global Step: 000077, Train Loss: 6.251, Val Loss: 6.157

[2025-11-09 15:05:56,609.609] Total Tokens seen till now: 10135840

[2025-11-09 15:05:57,450.450] BEST model SAVED on iteration 000077 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:05:57,462.462] Once upon a time,
[2025-11-09 15:06:03,810.810] Gradient updated
[2025-11-09 15:06:03,810.810] Current Learning Rate : 0.00013759036144578312
[2025-11-09 15:06:03,810.810] Global Step : 78
[2025-11-09 15:06:03,810.810] Batch Index : 2528
[2025-11-09 15:06:14,414.414] Epoch No: 1, Global Step: 000078, Train Loss: 6.130, Val Loss: 6.105

[2025-11-09 15:06:14,415.415] Total Tokens seen till now: 10266880

[2025-11-09 15:06:15,266.266] BEST model SAVED on iteration 000078 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:06:15,279.279] Once upon a time,
[2025-11-09 15:06:21,598.598] Gradient updated
[2025-11-09 15:06:21,598.598] Current Learning Rate : 0.0001380722891566265
[2025-11-09 15:06:21,598.598] Global Step : 79
[2025-11-09 15:06:21,598.598] Batch Index : 2560
[2025-11-09 15:06:32,435.435] Epoch No: 1, Global Step: 000079, Train Loss: 6.113, Val Loss: 6.098

[2025-11-09 15:06:32,435.435] Total Tokens seen till now: 10397440

[2025-11-09 15:06:33,360.360] BEST model SAVED on iteration 000079 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:06:33,372.372] Once upon a time,
[2025-11-09 15:06:39,697.697] Gradient updated
[2025-11-09 15:06:39,701.701] Current Learning Rate : 0.00013855421686746988
[2025-11-09 15:06:39,701.701] Global Step : 80
[2025-11-09 15:06:39,701.701] Batch Index : 2592
[2025-11-09 15:06:50,267.267] Epoch No: 1, Global Step: 000080, Train Loss: 6.056, Val Loss: 6.006

[2025-11-09 15:06:50,267.267] Total Tokens seen till now: 10528080

[2025-11-09 15:06:51,054.054] BEST model SAVED on iteration 000080 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:06:51,066.066] Once upon a time,
[2025-11-09 15:06:57,391.391] Gradient updated
[2025-11-09 15:06:57,395.395] Current Learning Rate : 0.00013903614457831326
[2025-11-09 15:06:57,395.395] Global Step : 81
[2025-11-09 15:06:57,395.395] Batch Index : 2624
[2025-11-09 15:07:08,010.010] Epoch No: 1, Global Step: 000081, Train Loss: 6.001, Val Loss: 5.953

[2025-11-09 15:07:08,010.010] Total Tokens seen till now: 10658384

[2025-11-09 15:07:08,804.804] BEST model SAVED on iteration 000081 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:07:08,867.867] Once upon a time, know. went "my play
[2025-11-09 15:07:15,196.196] Gradient updated
[2025-11-09 15:07:15,196.196] Current Learning Rate : 0.00013951807228915664
[2025-11-09 15:07:15,196.196] Global Step : 82
[2025-11-09 15:07:15,196.196] Batch Index : 2656
[2025-11-09 15:07:25,751.751] Epoch No: 1, Global Step: 000082, Train Loss: 5.967, Val Loss: 5.933

[2025-11-09 15:07:25,751.751] Total Tokens seen till now: 10788912

[2025-11-09 15:07:26,572.572] BEST model SAVED on iteration 000082 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:07:26,613.613] Once upon a time, big was
[2025-11-09 15:07:32,950.950] Gradient updated
[2025-11-09 15:07:32,952.952] Current Learning Rate : 0.00014
[2025-11-09 15:07:32,953.953] Global Step : 83
[2025-11-09 15:07:32,953.953] Batch Index : 2688
[2025-11-09 15:07:43,474.474] Epoch No: 1, Global Step: 000083, Train Loss: 5.941, Val Loss: 5.923

[2025-11-09 15:07:43,474.474] Total Tokens seen till now: 10919920

[2025-11-09 15:07:44,288.288] BEST model SAVED on iteration 000083 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:07:44,298.298] Once upon a time,
[2025-11-09 15:07:50,654.654] Gradient updated
[2025-11-09 15:07:50,655.655] Current Learning Rate : 0.0001404819277108434
[2025-11-09 15:07:50,655.655] Global Step : 84
[2025-11-09 15:07:50,655.655] Batch Index : 2720
[2025-11-09 15:08:01,300.300] Epoch No: 1, Global Step: 000084, Train Loss: 5.922, Val Loss: 5.872

[2025-11-09 15:08:01,300.300] Total Tokens seen till now: 11050928

[2025-11-09 15:08:02,137.137] BEST model SAVED on iteration 000084 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:08:02,153.153] Once upon a time,
[2025-11-09 15:08:08,544.544] Gradient updated
[2025-11-09 15:08:08,547.547] Current Learning Rate : 0.00014096385542168674
[2025-11-09 15:08:08,547.547] Global Step : 85
[2025-11-09 15:08:08,547.547] Batch Index : 2752
[2025-11-09 15:08:19,144.144] Epoch No: 1, Global Step: 000085, Train Loss: 5.853, Val Loss: 5.820

[2025-11-09 15:08:19,144.144] Total Tokens seen till now: 11181600

[2025-11-09 15:08:20,070.070] BEST model SAVED on iteration 000085 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:08:20,595.595] Once upon a time, things I I little. together mom and?" a to but?"ily Ben and smiled can of of is him him go was went fun
[2025-11-09 15:08:26,956.956] Gradient updated
[2025-11-09 15:08:26,960.960] Current Learning Rate : 0.00014144578313253012
[2025-11-09 15:08:26,960.960] Global Step : 86
[2025-11-09 15:08:26,961.961] Batch Index : 2784
[2025-11-09 15:08:37,554.554] Epoch No: 1, Global Step: 000086, Train Loss: 5.812, Val Loss: 5.793

[2025-11-09 15:08:37,554.554] Total Tokens seen till now: 11312288

[2025-11-09 15:08:38,486.486] BEST model SAVED on iteration 000086 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:08:38,497.497] Once upon a time,
[2025-11-09 15:08:44,852.852] Gradient updated
[2025-11-09 15:08:44,855.855] Current Learning Rate : 0.0001419277108433735
[2025-11-09 15:08:44,855.855] Global Step : 87
[2025-11-09 15:08:44,855.855] Batch Index : 2816
[2025-11-09 15:08:55,459.459] Epoch No: 1, Global Step: 000087, Train Loss: 5.805, Val Loss: 5.735

[2025-11-09 15:08:55,460.460] Total Tokens seen till now: 11443360

[2025-11-09 15:08:56,293.293] BEST model SAVED on iteration 000087 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:08:56,813.813] Once upon a time, little happy the excited with Ben. to a the, loved help They "'s and said and.. a. together went with the?".'t and the. little can girl Ben's mom play too the " happy can to
[2025-11-09 15:09:03,119.119] Gradient updated
[2025-11-09 15:09:03,120.120] Current Learning Rate : 0.00014240963855421688
[2025-11-09 15:09:03,120.120] Global Step : 88
[2025-11-09 15:09:03,120.120] Batch Index : 2848
[2025-11-09 15:09:13,786.786] Epoch No: 1, Global Step: 000088, Train Loss: 5.751, Val Loss: 5.663

[2025-11-09 15:09:13,786.786] Total Tokens seen till now: 11573328

[2025-11-09 15:09:14,565.565] BEST model SAVED on iteration 000088 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:09:15,016.016] Once upon a time, the best Ben and I and "'s together the with went of She and on She together to't. sad can mom.my with together are,. can I saw isily
[2025-11-09 15:09:21,379.379] Gradient updated
[2025-11-09 15:09:21,381.381] Current Learning Rate : 0.00014289156626506026
[2025-11-09 15:09:21,382.382] Global Step : 89
[2025-11-09 15:09:21,382.382] Batch Index : 2880
[2025-11-09 15:09:32,101.101] Epoch No: 1, Global Step: 000089, Train Loss: 5.683, Val Loss: 5.648

[2025-11-09 15:09:32,101.101] Total Tokens seen till now: 11704400

[2025-11-09 15:09:32,868.868] BEST model SAVED on iteration 000089 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:09:33,331.331] Once upon a time, little a is, She said Ben.. mommy is had says says, together be the, but day. was so excited with what and are . smiled away
[2025-11-09 15:09:39,671.671] Gradient updated
[2025-11-09 15:09:39,673.673] Current Learning Rate : 0.0001433734939759036
[2025-11-09 15:09:39,674.674] Global Step : 90
[2025-11-09 15:09:39,674.674] Batch Index : 2912
[2025-11-09 15:09:50,177.177] Epoch No: 1, Global Step: 000090, Train Loss: 5.664, Val Loss: 5.603

[2025-11-09 15:09:50,177.177] Total Tokens seen till now: 11835152

[2025-11-09 15:09:50,986.986] BEST model SAVED on iteration 000090 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:09:51,028.028] Once upon a time, things fun,
[2025-11-09 15:09:57,388.388] Gradient updated
[2025-11-09 15:09:57,389.389] Current Learning Rate : 0.000143855421686747
[2025-11-09 15:09:57,389.389] Global Step : 91
[2025-11-09 15:09:57,390.390] Batch Index : 2944
[2025-11-09 15:10:07,947.947] Epoch No: 1, Global Step: 000091, Train Loss: 5.603, Val Loss: 5.566

[2025-11-09 15:10:07,948.948] Total Tokens seen till now: 11966224

[2025-11-09 15:10:08,828.828] BEST model SAVED on iteration 000091 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:10:09,284.284] Once upon a time, can He I too. He. and too and smiled. went and to together himmy't are away had. was him.'sily had.. are mom and littlemy and it. is had girl Ben
[2025-11-09 15:10:15,618.618] Gradient updated
[2025-11-09 15:10:15,620.620] Current Learning Rate : 0.00014433734939759037
[2025-11-09 15:10:15,620.620] Global Step : 92
[2025-11-09 15:10:15,620.620] Batch Index : 2976
[2025-11-09 15:10:26,188.188] Epoch No: 1, Global Step: 000092, Train Loss: 5.547, Val Loss: 5.562

[2025-11-09 15:10:26,189.189] Total Tokens seen till now: 12097168

[2025-11-09 15:10:26,973.973] BEST model SAVED on iteration 000092 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:10:26,985.985] Once upon a time,
[2025-11-09 15:10:33,285.285] Gradient updated
[2025-11-09 15:10:33,285.285] Current Learning Rate : 0.00014481927710843374
[2025-11-09 15:10:33,285.285] Global Step : 93
[2025-11-09 15:10:33,285.285] Batch Index : 3008
[2025-11-09 15:10:43,844.844] Epoch No: 1, Global Step: 000093, Train Loss: 5.559, Val Loss: 5.552

[2025-11-09 15:10:43,845.845] Total Tokens seen till now: 12227344

[2025-11-09 15:10:44,670.670] BEST model SAVED on iteration 000093 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:10:45,124.124] Once upon a time, be little be are They big and on what him to themy saw and I.my. on..'s on is the. mom to help girl too together with had. of to Lily. went him. the together
[2025-11-09 15:10:51,467.467] Gradient updated
[2025-11-09 15:10:51,469.469] Current Learning Rate : 0.00014530120481927712
[2025-11-09 15:10:51,469.469] Global Step : 94
[2025-11-09 15:10:51,469.469] Batch Index : 3040
[2025-11-09 15:11:02,162.162] Epoch No: 1, Global Step: 000094, Train Loss: 5.544, Val Loss: 5.420

[2025-11-09 15:11:02,163.163] Total Tokens seen till now: 12358096

[2025-11-09 15:11:03,277.277] BEST model SAVED on iteration 000094 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:11:03,292.292] Once upon a time,
[2025-11-09 15:11:09,639.639] Gradient updated
[2025-11-09 15:11:09,639.639] Current Learning Rate : 0.00014578313253012047
[2025-11-09 15:11:09,639.639] Global Step : 95
[2025-11-09 15:11:09,639.639] Batch Index : 3072
[2025-11-09 15:11:20,263.263] Epoch No: 1, Global Step: 000095, Train Loss: 5.486, Val Loss: 5.423

[2025-11-09 15:11:20,264.264] Total Tokens seen till now: 12489168

[2025-11-09 15:11:20,441.441] Once upon a time,  knew the. named play. little I day. She He smiled smiled. They Lily
[2025-11-09 15:11:26,797.797] Gradient updated
[2025-11-09 15:11:26,798.798] Current Learning Rate : 0.00014626506024096385
[2025-11-09 15:11:26,798.798] Global Step : 96
[2025-11-09 15:11:26,798.798] Batch Index : 3104
[2025-11-09 15:11:37,357.357] Epoch No: 1, Global Step: 000096, Train Loss: 5.418, Val Loss: 5.420

[2025-11-09 15:11:37,358.358] Total Tokens seen till now: 12620240

[2025-11-09 15:11:37,369.369] Once upon a time,
[2025-11-09 15:11:43,714.714] Gradient updated
[2025-11-09 15:11:43,715.715] Current Learning Rate : 0.00014674698795180723
[2025-11-09 15:11:43,715.715] Global Step : 97
[2025-11-09 15:11:43,715.715] Batch Index : 3136
[2025-11-09 15:11:54,265.265] Epoch No: 1, Global Step: 000097, Train Loss: 5.406, Val Loss: 5.342

[2025-11-09 15:11:54,265.265] Total Tokens seen till now: 12751088

[2025-11-09 15:11:55,061.061] BEST model SAVED on iteration 000097 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:11:55,071.071] Once upon a time,
[2025-11-09 15:12:01,414.414] Gradient updated
[2025-11-09 15:12:01,414.414] Current Learning Rate : 0.0001472289156626506
[2025-11-09 15:12:01,414.414] Global Step : 98
[2025-11-09 15:12:01,414.414] Batch Index : 3168
[2025-11-09 15:12:12,100.100] Epoch No: 1, Global Step: 000098, Train Loss: 5.387, Val Loss: 5.280

[2025-11-09 15:12:12,102.102] Total Tokens seen till now: 12881744

[2025-11-09 15:12:12,957.957] BEST model SAVED on iteration 000098 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:12:13,417.417] Once upon a time, fun. The and  ily and can " They but went. saw the the the. He and girl. and had. She said him to a it. I She his his with the the to. to the and he
[2025-11-09 15:12:19,774.774] Gradient updated
[2025-11-09 15:12:19,775.775] Current Learning Rate : 0.000147710843373494
[2025-11-09 15:12:19,775.775] Global Step : 99
[2025-11-09 15:12:19,775.775] Batch Index : 3200
[2025-11-09 15:12:30,344.344] Epoch No: 1, Global Step: 000099, Train Loss: 5.326, Val Loss: 5.292

[2025-11-09 15:12:30,345.345] Total Tokens seen till now: 13012816

[2025-11-09 15:12:30,355.355] Once upon a time,
[2025-11-09 15:12:36,696.696] Gradient updated
[2025-11-09 15:12:36,699.699] Current Learning Rate : 0.00014819277108433734
[2025-11-09 15:12:36,699.699] Global Step : 100
[2025-11-09 15:12:36,699.699] Batch Index : 3232
[2025-11-09 15:12:47,255.255] Epoch No: 1, Global Step: 000100, Train Loss: 5.266, Val Loss: 5.288

[2025-11-09 15:12:47,255.255] Total Tokens seen till now: 13143408

[2025-11-09 15:12:47,266.266] Once upon a time,
[2025-11-09 15:12:53,587.587] Gradient updated
[2025-11-09 15:12:53,589.589] Current Learning Rate : 0.00014867469879518072
[2025-11-09 15:12:53,590.590] Global Step : 101
[2025-11-09 15:12:53,590.590] Batch Index : 3264
[2025-11-09 15:13:04,078.078] Epoch No: 1, Global Step: 000101, Train Loss: 5.299, Val Loss: 5.244

[2025-11-09 15:13:04,078.078] Total Tokens seen till now: 13273888

[2025-11-09 15:13:04,886.886] BEST model SAVED on iteration 000101 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:13:04,897.897] Once upon a time,
[2025-11-09 15:13:11,233.233] Gradient updated
[2025-11-09 15:13:11,236.236] Current Learning Rate : 0.0001491566265060241
[2025-11-09 15:13:11,236.236] Global Step : 102
[2025-11-09 15:13:11,236.236] Batch Index : 3296
[2025-11-09 15:13:21,917.917] Epoch No: 1, Global Step: 000102, Train Loss: 5.247, Val Loss: 5.190

[2025-11-09 15:13:21,917.917] Total Tokens seen till now: 13404448

[2025-11-09 15:13:22,859.859] BEST model SAVED on iteration 000102 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:13:23,453.453] Once upon a time, but to big. saw and the the a He Lily." play. I to went mom mom in mom the wanted are was that the a with a toomy She  " " to
[2025-11-09 15:13:29,804.804] Gradient updated
[2025-11-09 15:13:29,804.804] Current Learning Rate : 0.00014963855421686747
[2025-11-09 15:13:29,805.805] Global Step : 103
[2025-11-09 15:13:29,805.805] Batch Index : 3328
[2025-11-09 15:13:40,405.405] Epoch No: 1, Global Step: 000103, Train Loss: 5.212, Val Loss: 5.136

[2025-11-09 15:13:40,406.406] Total Tokens seen till now: 13535520

[2025-11-09 15:13:41,328.328] BEST model SAVED on iteration 000103 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:13:41,341.341] Once upon a time,
[2025-11-09 15:13:47,699.699] Gradient updated
[2025-11-09 15:13:47,699.699] Current Learning Rate : 0.00015012048192771085
[2025-11-09 15:13:47,700.700] Global Step : 104
[2025-11-09 15:13:47,700.700] Batch Index : 3360
[2025-11-09 15:13:58,229.229] Epoch No: 1, Global Step: 000104, Train Loss: 5.187, Val Loss: 5.123

[2025-11-09 15:13:58,230.230] Total Tokens seen till now: 13666384

[2025-11-09 15:13:59,013.013] BEST model SAVED on iteration 000104 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:13:59,024.024] Once upon a time,
[2025-11-09 15:14:05,375.375] Gradient updated
[2025-11-09 15:14:05,376.376] Current Learning Rate : 0.00015060240963855423
[2025-11-09 15:14:05,376.376] Global Step : 105
[2025-11-09 15:14:05,376.376] Batch Index : 3392
[2025-11-09 15:14:16,003.003] Epoch No: 1, Global Step: 000105, Train Loss: 5.145, Val Loss: 5.126

[2025-11-09 15:14:16,004.004] Total Tokens seen till now: 13797456

[2025-11-09 15:14:16,014.014] Once upon a time,
[2025-11-09 15:14:22,353.353] Gradient updated
[2025-11-09 15:14:22,354.354] Current Learning Rate : 0.0001510843373493976
[2025-11-09 15:14:22,354.354] Global Step : 106
[2025-11-09 15:14:22,354.354] Batch Index : 3424
[2025-11-09 15:14:32,850.850] Epoch No: 1, Global Step: 000106, Train Loss: 5.128, Val Loss: 5.090

[2025-11-09 15:14:32,851.851] Total Tokens seen till now: 13927824

[2025-11-09 15:14:33,647.647] BEST model SAVED on iteration 000106 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:14:33,658.658] Once upon a time,
[2025-11-09 15:14:40,008.008] Gradient updated
[2025-11-09 15:14:40,008.008] Current Learning Rate : 0.00015156626506024096
[2025-11-09 15:14:40,009.009] Global Step : 107
[2025-11-09 15:14:40,009.009] Batch Index : 3456
[2025-11-09 15:14:50,637.637] Epoch No: 1, Global Step: 000107, Train Loss: 5.075, Val Loss: 5.001

[2025-11-09 15:14:50,637.637] Total Tokens seen till now: 14058896

[2025-11-09 15:14:51,463.463] BEST model SAVED on iteration 000107 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:14:51,474.474] Once upon a time,
[2025-11-09 15:14:57,832.832] Gradient updated
[2025-11-09 15:14:57,833.833] Current Learning Rate : 0.00015204819277108434
[2025-11-09 15:14:57,833.833] Global Step : 108
[2025-11-09 15:14:57,833.833] Batch Index : 3488
[2025-11-09 15:15:08,473.473] Epoch No: 1, Global Step: 000108, Train Loss: 5.051, Val Loss: 4.976

[2025-11-09 15:15:08,473.473] Total Tokens seen till now: 14189968

[2025-11-09 15:15:09,253.253] BEST model SAVED on iteration 000108 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:15:09,264.264] Once upon a time,
[2025-11-09 15:15:15,611.611] Gradient updated
[2025-11-09 15:15:15,612.612] Current Learning Rate : 0.00015253012048192772
[2025-11-09 15:15:15,612.612] Global Step : 109
[2025-11-09 15:15:15,612.612] Batch Index : 3520
[2025-11-09 15:15:26,289.289] Epoch No: 1, Global Step: 000109, Train Loss: 5.018, Val Loss: 4.962

[2025-11-09 15:15:26,290.290] Total Tokens seen till now: 14321040

[2025-11-09 15:15:27,056.056] BEST model SAVED on iteration 000109 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:15:27,070.070] Once upon a time,
[2025-11-09 15:15:33,432.432] Gradient updated
[2025-11-09 15:15:33,433.433] Current Learning Rate : 0.0001530120481927711
[2025-11-09 15:15:33,433.433] Global Step : 110
[2025-11-09 15:15:33,433.433] Batch Index : 3552
[2025-11-09 15:15:44,009.009] Epoch No: 1, Global Step: 000110, Train Loss: 5.014, Val Loss: 4.994

[2025-11-09 15:15:44,009.009] Total Tokens seen till now: 14452064

[2025-11-09 15:15:44,020.020] Once upon a time,
[2025-11-09 15:15:50,382.382] Gradient updated
[2025-11-09 15:15:50,383.383] Current Learning Rate : 0.00015349397590361447
[2025-11-09 15:15:50,383.383] Global Step : 111
[2025-11-09 15:15:50,383.383] Batch Index : 3584
[2025-11-09 15:16:00,876.876] Epoch No: 1, Global Step: 000111, Train Loss: 5.006, Val Loss: 4.910

[2025-11-09 15:16:00,877.877] Total Tokens seen till now: 14582880

[2025-11-09 15:16:01,776.776] BEST model SAVED on iteration 000111 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:16:01,915.915] Once upon a time, saw girl They it She. was on
[2025-11-09 15:16:08,245.245] Gradient updated
[2025-11-09 15:16:08,246.246] Current Learning Rate : 0.00015397590361445782
[2025-11-09 15:16:08,246.246] Global Step : 112
[2025-11-09 15:16:08,246.246] Batch Index : 3616
[2025-11-09 15:16:18,949.949] Epoch No: 1, Global Step: 000112, Train Loss: 4.977, Val Loss: 4.847

[2025-11-09 15:16:18,949.949] Total Tokens seen till now: 14713424

[2025-11-09 15:16:19,715.715] BEST model SAVED on iteration 000112 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:16:19,725.725] Once upon a time,
[2025-11-09 15:16:26,074.074] Gradient updated
[2025-11-09 15:16:26,075.075] Current Learning Rate : 0.0001544578313253012
[2025-11-09 15:16:26,075.075] Global Step : 113
[2025-11-09 15:16:26,075.075] Batch Index : 3648
[2025-11-09 15:16:36,887.887] Epoch No: 1, Global Step: 000113, Train Loss: 4.940, Val Loss: 4.932

[2025-11-09 15:16:36,888.888] Total Tokens seen till now: 14844448

[2025-11-09 15:16:37,544.544] Once upon a time, a saw. is Lily She. but her the the She of and the but. was of a they the they of the of themy." wanted happy and you it happy said and day She.
[2025-11-09 15:16:43,889.889] Gradient updated
[2025-11-09 15:16:43,889.889] Current Learning Rate : 0.00015493975903614458
[2025-11-09 15:16:43,889.889] Global Step : 114
[2025-11-09 15:16:43,889.889] Batch Index : 3680
[2025-11-09 15:16:54,384.384] Epoch No: 1, Global Step: 000114, Train Loss: 4.911, Val Loss: 4.839

[2025-11-09 15:16:54,385.385] Total Tokens seen till now: 14975040

[2025-11-09 15:16:55,224.224] BEST model SAVED on iteration 000114 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:16:55,678.678] Once upon a time, Butmy up but mom. little the. the.'s's the Tim day, it and go.. mom. are and be day. day., said. of the and " he with the the went the
[2025-11-09 15:17:02,033.033] Gradient updated
[2025-11-09 15:17:02,034.034] Current Learning Rate : 0.00015542168674698796
[2025-11-09 15:17:02,034.034] Global Step : 115
[2025-11-09 15:17:02,034.034] Batch Index : 3712
[2025-11-09 15:17:12,678.678] Epoch No: 1, Global Step: 000115, Train Loss: 4.866, Val Loss: 4.822

[2025-11-09 15:17:12,678.678] Total Tokens seen till now: 15105504

[2025-11-09 15:17:13,622.622] BEST model SAVED on iteration 000115 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:17:13,663.663] Once upon a time, the's and
[2025-11-09 15:17:19,990.990] Gradient updated
[2025-11-09 15:17:19,991.991] Current Learning Rate : 0.00015590361445783134
[2025-11-09 15:17:19,991.991] Global Step : 116
[2025-11-09 15:17:19,991.991] Batch Index : 3744
[2025-11-09 15:17:30,626.626] Epoch No: 1, Global Step: 000116, Train Loss: 4.850, Val Loss: 4.819

[2025-11-09 15:17:30,627.627] Total Tokens seen till now: 15235648

[2025-11-09 15:17:31,573.573] BEST model SAVED on iteration 000116 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:17:31,588.588] Once upon a time,
[2025-11-09 15:17:37,954.954] Gradient updated
[2025-11-09 15:17:37,957.957] Current Learning Rate : 0.0001563855421686747
[2025-11-09 15:17:37,957.957] Global Step : 117
[2025-11-09 15:17:37,957.957] Batch Index : 3776
[2025-11-09 15:17:48,502.502] Epoch No: 1, Global Step: 000117, Train Loss: 4.790, Val Loss: 4.741

[2025-11-09 15:17:48,503.503] Total Tokens seen till now: 15366720

[2025-11-09 15:17:49,319.319] BEST model SAVED on iteration 000117 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:17:49,765.765] Once upon a time, a said " He The it had her. The of the He little his the had of the is a her go the was and was so big his but day,'s, " was said,
[2025-11-09 15:17:56,114.114] Gradient updated
[2025-11-09 15:17:56,116.116] Current Learning Rate : 0.00015686746987951807
[2025-11-09 15:17:56,116.116] Global Step : 118
[2025-11-09 15:17:56,116.116] Batch Index : 3808
[2025-11-09 15:18:06,926.926] Epoch No: 1, Global Step: 000118, Train Loss: 4.804, Val Loss: 4.748

[2025-11-09 15:18:06,926.926] Total Tokens seen till now: 15497568

[2025-11-09 15:18:06,941.941] Once upon a time,
[2025-11-09 15:18:13,308.308] Gradient updated
[2025-11-09 15:18:13,308.308] Current Learning Rate : 0.00015734939759036145
[2025-11-09 15:18:13,309.309] Global Step : 119
[2025-11-09 15:18:13,309.309] Batch Index : 3840
[2025-11-09 15:18:23,860.860] Epoch No: 1, Global Step: 000119, Train Loss: 4.743, Val Loss: 4.717

[2025-11-09 15:18:23,863.863] Total Tokens seen till now: 15628448

[2025-11-09 15:18:24,652.652] BEST model SAVED on iteration 000119 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:18:24,663.663] Once upon a time,
[2025-11-09 15:18:31,003.003] Gradient updated
[2025-11-09 15:18:31,004.004] Current Learning Rate : 0.00015783132530120482
[2025-11-09 15:18:31,004.004] Global Step : 120
[2025-11-09 15:18:31,004.004] Batch Index : 3872
[2025-11-09 15:18:41,744.744] Epoch No: 1, Global Step: 000120, Train Loss: 4.747, Val Loss: 4.699

[2025-11-09 15:18:41,745.745] Total Tokens seen till now: 15759104

[2025-11-09 15:18:42,694.694] BEST model SAVED on iteration 000120 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:18:42,708.708] Once upon a time,
[2025-11-09 15:18:49,062.062] Gradient updated
[2025-11-09 15:18:49,062.062] Current Learning Rate : 0.0001583132530120482
[2025-11-09 15:18:49,062.062] Global Step : 121
[2025-11-09 15:18:49,063.063] Batch Index : 3904
[2025-11-09 15:18:59,698.698] Epoch No: 1, Global Step: 000121, Train Loss: 4.730, Val Loss: 4.660

[2025-11-09 15:18:59,699.699] Total Tokens seen till now: 15890016

[2025-11-09 15:19:00,602.602] BEST model SAVED on iteration 000121 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:19:00,615.615] Once upon a time,
[2025-11-09 15:19:06,956.956] Gradient updated
[2025-11-09 15:19:06,957.957] Current Learning Rate : 0.00015879518072289155
[2025-11-09 15:19:06,957.957] Global Step : 122
[2025-11-09 15:19:06,958.958] Batch Index : 3936
[2025-11-09 15:19:17,695.695] Epoch No: 1, Global Step: 000122, Train Loss: 4.676, Val Loss: 4.626

[2025-11-09 15:19:17,696.696] Total Tokens seen till now: 16020608

[2025-11-09 15:19:18,510.510] BEST model SAVED on iteration 000122 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:19:18,523.523] Once upon a time,
[2025-11-09 15:19:24,878.878] Gradient updated
[2025-11-09 15:19:24,878.878] Current Learning Rate : 0.00015927710843373496
[2025-11-09 15:19:24,878.878] Global Step : 123
[2025-11-09 15:19:24,878.878] Batch Index : 3968
[2025-11-09 15:19:35,533.533] Epoch No: 1, Global Step: 000123, Train Loss: 4.719, Val Loss: 4.611

[2025-11-09 15:19:35,533.533] Total Tokens seen till now: 16151472

[2025-11-09 15:19:36,467.467] BEST model SAVED on iteration 000123 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:19:36,509.509] Once upon a time,  and
[2025-11-09 15:19:42,879.879] Gradient updated
[2025-11-09 15:19:42,879.879] Current Learning Rate : 0.0001597590361445783
[2025-11-09 15:19:42,880.880] Global Step : 124
[2025-11-09 15:19:42,880.880] Batch Index : 4000
[2025-11-09 15:19:53,436.436] Epoch No: 1, Global Step: 000124, Train Loss: 4.611, Val Loss: 4.554

[2025-11-09 15:19:53,437.437] Total Tokens seen till now: 16282544

[2025-11-09 15:19:54,230.230] BEST model SAVED on iteration 000124 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:19:54,241.241] Once upon a time,
[2025-11-09 15:20:00,578.578] Gradient updated
[2025-11-09 15:20:00,579.579] Current Learning Rate : 0.0001602409638554217
[2025-11-09 15:20:00,579.579] Global Step : 125
[2025-11-09 15:20:00,579.579] Batch Index : 4032
[2025-11-09 15:20:11,195.195] Epoch No: 1, Global Step: 000125, Train Loss: 4.614, Val Loss: 4.568

[2025-11-09 15:20:11,196.196] Total Tokens seen till now: 16413424

[2025-11-09 15:20:11,210.210] Once upon a time,
[2025-11-09 15:20:17,580.580] Gradient updated
[2025-11-09 15:20:17,581.581] Current Learning Rate : 0.00016072289156626507
[2025-11-09 15:20:17,581.581] Global Step : 126
[2025-11-09 15:20:17,581.581] Batch Index : 4064
[2025-11-09 15:20:28,139.139] Epoch No: 1, Global Step: 000126, Train Loss: 4.626, Val Loss: 4.564

[2025-11-09 15:20:28,141.141] Total Tokens seen till now: 16544496

[2025-11-09 15:20:28,153.153] Once upon a time,
[2025-11-09 15:20:34,505.505] Gradient updated
[2025-11-09 15:20:34,506.506] Current Learning Rate : 0.00016120481927710842
[2025-11-09 15:20:34,506.506] Global Step : 127
[2025-11-09 15:20:34,507.507] Batch Index : 4096
[2025-11-09 15:20:45,031.031] Epoch No: 1, Global Step: 000127, Train Loss: 4.581, Val Loss: 4.486

[2025-11-09 15:20:45,032.032] Total Tokens seen till now: 16675376

[2025-11-09 15:20:45,816.816] BEST model SAVED on iteration 000127 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:20:45,826.826] Once upon a time,
[2025-11-09 15:20:52,189.189] Gradient updated
[2025-11-09 15:20:52,189.189] Current Learning Rate : 0.00016168674698795182
[2025-11-09 15:20:52,190.190] Global Step : 128
[2025-11-09 15:20:52,190.190] Batch Index : 4128
[2025-11-09 15:21:02,865.865] Epoch No: 1, Global Step: 000128, Train Loss: 4.559, Val Loss: 4.540

[2025-11-09 15:21:02,865.865] Total Tokens seen till now: 16806080

[2025-11-09 15:21:02,876.876] Once upon a time,
[2025-11-09 15:21:09,218.218] Gradient updated
[2025-11-09 15:21:09,219.219] Current Learning Rate : 0.00016216867469879518
[2025-11-09 15:21:09,219.219] Global Step : 129
[2025-11-09 15:21:09,219.219] Batch Index : 4160
[2025-11-09 15:21:19,809.809] Epoch No: 1, Global Step: 000129, Train Loss: 4.559, Val Loss: 4.520

[2025-11-09 15:21:19,810.810] Total Tokens seen till now: 16936704

[2025-11-09 15:21:19,821.821] Once upon a time,
[2025-11-09 15:21:26,177.177] Gradient updated
[2025-11-09 15:21:26,178.178] Current Learning Rate : 0.00016265060240963855
[2025-11-09 15:21:26,178.178] Global Step : 130
[2025-11-09 15:21:26,178.178] Batch Index : 4192
[2025-11-09 15:21:36,914.914] Epoch No: 1, Global Step: 000130, Train Loss: 4.521, Val Loss: 4.470

[2025-11-09 15:21:36,915.915] Total Tokens seen till now: 17067040

[2025-11-09 15:21:37,699.699] BEST model SAVED on iteration 000130 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:21:37,709.709] Once upon a time,
[2025-11-09 15:21:44,076.076] Gradient updated
[2025-11-09 15:21:44,077.077] Current Learning Rate : 0.00016313253012048193
[2025-11-09 15:21:44,077.077] Global Step : 131
[2025-11-09 15:21:44,077.077] Batch Index : 4224
[2025-11-09 15:21:54,647.647] Epoch No: 1, Global Step: 000131, Train Loss: 4.506, Val Loss: 4.401

[2025-11-09 15:21:54,648.648] Total Tokens seen till now: 17197904

[2025-11-09 15:21:55,537.537] BEST model SAVED on iteration 000131 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:21:55,550.550] Once upon a time,
[2025-11-09 15:22:01,900.900] Gradient updated
[2025-11-09 15:22:01,901.901] Current Learning Rate : 0.0001636144578313253
[2025-11-09 15:22:01,901.901] Global Step : 132
[2025-11-09 15:22:01,901.901] Batch Index : 4256
[2025-11-09 15:22:12,541.541] Epoch No: 1, Global Step: 000132, Train Loss: 4.445, Val Loss: 4.400

[2025-11-09 15:22:12,542.542] Total Tokens seen till now: 17328208

[2025-11-09 15:22:13,353.353] BEST model SAVED on iteration 000132 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:22:13,364.364] Once upon a time,
[2025-11-09 15:22:19,714.714] Gradient updated
[2025-11-09 15:22:19,714.714] Current Learning Rate : 0.0001640963855421687
[2025-11-09 15:22:19,715.715] Global Step : 133
[2025-11-09 15:22:19,715.715] Batch Index : 4288
[2025-11-09 15:22:30,305.305] Epoch No: 1, Global Step: 000133, Train Loss: 4.526, Val Loss: 4.448

[2025-11-09 15:22:30,306.306] Total Tokens seen till now: 17458912

[2025-11-09 15:22:30,317.317] Once upon a time,
[2025-11-09 15:22:36,687.687] Gradient updated
[2025-11-09 15:22:36,687.687] Current Learning Rate : 0.00016457831325301204
[2025-11-09 15:22:36,687.687] Global Step : 134
[2025-11-09 15:22:36,687.687] Batch Index : 4320
[2025-11-09 15:22:47,235.235] Epoch No: 1, Global Step: 000134, Train Loss: 4.400, Val Loss: 4.396

[2025-11-09 15:22:47,236.236] Total Tokens seen till now: 17589984

[2025-11-09 15:22:48,033.033] BEST model SAVED on iteration 000134 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:22:48,069.069] Once upon a time, little mom the
[2025-11-09 15:22:54,396.396] Gradient updated
[2025-11-09 15:22:54,397.397] Current Learning Rate : 0.00016506024096385542
[2025-11-09 15:22:54,397.397] Global Step : 135
[2025-11-09 15:22:54,397.397] Batch Index : 4352
[2025-11-09 15:23:04,987.987] Epoch No: 1, Global Step: 000135, Train Loss: 4.444, Val Loss: 4.373

[2025-11-09 15:23:04,988.988] Total Tokens seen till now: 17720288

[2025-11-09 15:23:05,871.871] BEST model SAVED on iteration 000135 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:23:05,884.884] Once upon a time,
[2025-11-09 15:23:12,230.230] Gradient updated
[2025-11-09 15:23:12,231.231] Current Learning Rate : 0.0001655421686746988
[2025-11-09 15:23:12,231.231] Global Step : 136
[2025-11-09 15:23:12,231.231] Batch Index : 4384
[2025-11-09 15:23:22,784.784] Epoch No: 1, Global Step: 000136, Train Loss: 4.373, Val Loss: 4.390

[2025-11-09 15:23:22,786.786] Total Tokens seen till now: 17850912

[2025-11-09 15:23:22,798.798] Once upon a time,
[2025-11-09 15:23:29,142.142] Gradient updated
[2025-11-09 15:23:29,142.142] Current Learning Rate : 0.00016602409638554217
[2025-11-09 15:23:29,142.142] Global Step : 137
[2025-11-09 15:23:29,142.142] Batch Index : 4416
[2025-11-09 15:23:39,673.673] Epoch No: 1, Global Step: 000137, Train Loss: 4.388, Val Loss: 4.320

[2025-11-09 15:23:39,673.673] Total Tokens seen till now: 17981104

[2025-11-09 15:23:40,484.484] BEST model SAVED on iteration 000137 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:23:40,496.496] Once upon a time,
[2025-11-09 15:23:46,832.832] Gradient updated
[2025-11-09 15:23:46,833.833] Current Learning Rate : 0.00016650602409638555
[2025-11-09 15:23:46,833.833] Global Step : 138
[2025-11-09 15:23:46,833.833] Batch Index : 4448
[2025-11-09 15:23:57,582.582] Epoch No: 1, Global Step: 000138, Train Loss: 4.375, Val Loss: 4.307

[2025-11-09 15:23:57,582.582] Total Tokens seen till now: 18111568

[2025-11-09 15:23:58,434.434] BEST model SAVED on iteration 000138 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:23:58,445.445] Once upon a time,
[2025-11-09 15:24:04,809.809] Gradient updated
[2025-11-09 15:24:04,810.810] Current Learning Rate : 0.0001669879518072289
[2025-11-09 15:24:04,810.810] Global Step : 139
[2025-11-09 15:24:04,810.810] Batch Index : 4480
[2025-11-09 15:24:15,454.454] Epoch No: 1, Global Step: 000139, Train Loss: 4.374, Val Loss: 4.265

[2025-11-09 15:24:15,454.454] Total Tokens seen till now: 18242640

[2025-11-09 15:24:16,291.291] BEST model SAVED on iteration 000139 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:24:16,302.302] Once upon a time,
[2025-11-09 15:24:22,666.666] Gradient updated
[2025-11-09 15:24:22,667.667] Current Learning Rate : 0.0001674698795180723
[2025-11-09 15:24:22,667.667] Global Step : 140
[2025-11-09 15:24:22,667.667] Batch Index : 4512
[2025-11-09 15:24:33,320.320] Epoch No: 1, Global Step: 000140, Train Loss: 4.295, Val Loss: 4.235

[2025-11-09 15:24:33,321.321] Total Tokens seen till now: 18373568

[2025-11-09 15:24:34,116.116] BEST model SAVED on iteration 000140 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:24:34,126.126] Once upon a time,
[2025-11-09 15:24:40,459.459] Gradient updated
[2025-11-09 15:24:40,460.460] Current Learning Rate : 0.00016795180722891566
[2025-11-09 15:24:40,460.460] Global Step : 141
[2025-11-09 15:24:40,460.460] Batch Index : 4544
[2025-11-09 15:24:51,193.193] Epoch No: 1, Global Step: 000141, Train Loss: 4.342, Val Loss: 4.281

[2025-11-09 15:24:51,194.194] Total Tokens seen till now: 18503728

[2025-11-09 15:24:51,204.204] Once upon a time,
[2025-11-09 15:24:57,562.562] Gradient updated
[2025-11-09 15:24:57,563.563] Current Learning Rate : 0.00016843373493975904
[2025-11-09 15:24:57,563.563] Global Step : 142
[2025-11-09 15:24:57,563.563] Batch Index : 4576
[2025-11-09 15:25:08,116.116] Epoch No: 1, Global Step: 000142, Train Loss: 4.275, Val Loss: 4.266

[2025-11-09 15:25:08,117.117] Total Tokens seen till now: 18634432

[2025-11-09 15:25:08,127.127] Once upon a time,
[2025-11-09 15:25:14,507.507] Gradient updated
[2025-11-09 15:25:14,508.508] Current Learning Rate : 0.00016891566265060242
[2025-11-09 15:25:14,508.508] Global Step : 143
[2025-11-09 15:25:14,508.508] Batch Index : 4608
[2025-11-09 15:25:25,024.024] Epoch No: 1, Global Step: 000143, Train Loss: 4.223, Val Loss: 4.219

[2025-11-09 15:25:25,025.025] Total Tokens seen till now: 18765504

[2025-11-09 15:25:25,805.805] BEST model SAVED on iteration 000143 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:25:25,816.816] Once upon a time,
[2025-11-09 15:25:32,188.188] Gradient updated
[2025-11-09 15:25:32,189.189] Current Learning Rate : 0.00016939759036144577
[2025-11-09 15:25:32,189.189] Global Step : 144
[2025-11-09 15:25:32,189.189] Batch Index : 4640
[2025-11-09 15:25:42,806.806] Epoch No: 1, Global Step: 000144, Train Loss: 4.275, Val Loss: 4.223

[2025-11-09 15:25:42,807.807] Total Tokens seen till now: 18896576

[2025-11-09 15:25:42,819.819] Once upon a time,
[2025-11-09 15:25:49,170.170] Gradient updated
[2025-11-09 15:25:49,171.171] Current Learning Rate : 0.00016987951807228917
[2025-11-09 15:25:49,171.171] Global Step : 145
[2025-11-09 15:25:49,171.171] Batch Index : 4672
[2025-11-09 15:25:59,736.736] Epoch No: 1, Global Step: 000145, Train Loss: 4.257, Val Loss: 4.165

[2025-11-09 15:25:59,737.737] Total Tokens seen till now: 19027152

[2025-11-09 15:26:00,522.522] BEST model SAVED on iteration 000145 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:26:00,542.542] Once upon a time, a
[2025-11-09 15:26:06,917.917] Gradient updated
[2025-11-09 15:26:06,918.918] Current Learning Rate : 0.00017036144578313253
[2025-11-09 15:26:06,919.919] Global Step : 146
[2025-11-09 15:26:06,919.919] Batch Index : 4704
[2025-11-09 15:26:17,611.611] Epoch No: 1, Global Step: 000146, Train Loss: 4.189, Val Loss: 4.130

[2025-11-09 15:26:17,612.612] Total Tokens seen till now: 19158128

[2025-11-09 15:26:18,535.535] BEST model SAVED on iteration 000146 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:26:18,546.546] Once upon a time,
[2025-11-09 15:26:24,904.904] Gradient updated
[2025-11-09 15:26:24,905.905] Current Learning Rate : 0.0001708433734939759
[2025-11-09 15:26:24,905.905] Global Step : 147
[2025-11-09 15:26:24,905.905] Batch Index : 4736
[2025-11-09 15:26:35,506.506] Epoch No: 1, Global Step: 000147, Train Loss: 4.197, Val Loss: 4.180

[2025-11-09 15:26:35,507.507] Total Tokens seen till now: 19288816

[2025-11-09 15:26:35,520.520] Once upon a time,
[2025-11-09 15:26:41,883.883] Gradient updated
[2025-11-09 15:26:41,885.885] Current Learning Rate : 0.00017132530120481928
[2025-11-09 15:26:41,885.885] Global Step : 148
[2025-11-09 15:26:41,885.885] Batch Index : 4768
[2025-11-09 15:26:52,463.463] Epoch No: 1, Global Step: 000148, Train Loss: 4.167, Val Loss: 4.122

[2025-11-09 15:26:52,463.463] Total Tokens seen till now: 19419648

[2025-11-09 15:26:53,232.232] BEST model SAVED on iteration 000148 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:26:53,731.731] Once upon a time, her the a named a a the his with.. He they but but the was his a and. saw a She in the and was so it to the Lily. He was
[2025-11-09 15:27:00,083.083] Gradient updated
[2025-11-09 15:27:00,084.084] Current Learning Rate : 0.00017180722891566263
[2025-11-09 15:27:00,084.084] Global Step : 149
[2025-11-09 15:27:00,084.084] Batch Index : 4800
[2025-11-09 15:27:10,764.764] Epoch No: 1, Global Step: 000149, Train Loss: 4.181, Val Loss: 4.124

[2025-11-09 15:27:10,765.765] Total Tokens seen till now: 19550720

[2025-11-09 15:27:10,778.778] Once upon a time,
[2025-11-09 15:27:17,102.102] Gradient updated
[2025-11-09 15:27:17,103.103] Current Learning Rate : 0.00017228915662650604
[2025-11-09 15:27:17,103.103] Global Step : 150
[2025-11-09 15:27:17,103.103] Batch Index : 4832
[2025-11-09 15:27:27,541.541] Epoch No: 1, Global Step: 000150, Train Loss: 4.172, Val Loss: 4.114

[2025-11-09 15:27:27,542.542] Total Tokens seen till now: 19681296

[2025-11-09 15:27:28,339.339] BEST model SAVED on iteration 000150 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:27:28,351.351] Once upon a time,
[2025-11-09 15:27:34,695.695] Gradient updated
[2025-11-09 15:27:34,696.696] Current Learning Rate : 0.0001727710843373494
[2025-11-09 15:27:34,696.696] Global Step : 151
[2025-11-09 15:27:34,697.697] Batch Index : 4864
[2025-11-09 15:27:45,208.208] Epoch No: 1, Global Step: 000151, Train Loss: 4.142, Val Loss: 4.047

[2025-11-09 15:27:45,209.209] Total Tokens seen till now: 19811584

[2025-11-09 15:27:46,033.033] BEST model SAVED on iteration 000151 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:27:46,295.295] Once upon a time, not his He his that and the was was was somy little. She to his and of all
[2025-11-09 15:27:52,672.672] Gradient updated
[2025-11-09 15:27:52,673.673] Current Learning Rate : 0.00017325301204819277
[2025-11-09 15:27:52,673.673] Global Step : 152
[2025-11-09 15:27:52,674.674] Batch Index : 4896
[2025-11-09 15:28:03,417.417] Epoch No: 1, Global Step: 000152, Train Loss: 4.141, Val Loss: 4.074

[2025-11-09 15:28:03,417.417] Total Tokens seen till now: 19942656

[2025-11-09 15:28:03,427.427] Once upon a time,
[2025-11-09 15:28:09,777.777] Gradient updated
[2025-11-09 15:28:09,778.778] Current Learning Rate : 0.00017373493975903615
[2025-11-09 15:28:09,778.778] Global Step : 153
[2025-11-09 15:28:09,778.778] Batch Index : 4928
[2025-11-09 15:28:20,322.322] Epoch No: 1, Global Step: 000153, Train Loss: 4.066, Val Loss: 4.035

[2025-11-09 15:28:20,323.323] Total Tokens seen till now: 20073056

[2025-11-09 15:28:21,110.110] BEST model SAVED on iteration 000153 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:28:21,121.121] Once upon a time,
[2025-11-09 15:28:27,476.476] Gradient updated
[2025-11-09 15:28:27,477.477] Current Learning Rate : 0.00017421686746987953
[2025-11-09 15:28:27,477.477] Global Step : 154
[2025-11-09 15:28:27,477.477] Batch Index : 4960
[2025-11-09 15:28:38,062.062] Epoch No: 1, Global Step: 000154, Train Loss: 4.030, Val Loss: 4.019

[2025-11-09 15:28:38,062.062] Total Tokens seen till now: 20203792

[2025-11-09 15:28:38,829.829] BEST model SAVED on iteration 000154 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:28:39,102.102] Once upon a time, the It. " his to the she the the. She but a She mom. He.
[2025-11-09 15:28:45,477.477] Gradient updated
[2025-11-09 15:28:45,478.478] Current Learning Rate : 0.0001746987951807229
[2025-11-09 15:28:45,478.478] Global Step : 155
[2025-11-09 15:28:45,478.478] Batch Index : 4992
[2025-11-09 15:28:56,082.082] Epoch No: 1, Global Step: 000155, Train Loss: 4.056, Val Loss: 4.011

[2025-11-09 15:28:56,083.083] Total Tokens seen till now: 20334672

[2025-11-09 15:28:57,016.016] BEST model SAVED on iteration 000155 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:28:57,031.031] Once upon a time,
[2025-11-09 15:29:03,410.410] Gradient updated
[2025-11-09 15:29:03,410.410] Current Learning Rate : 0.00017518072289156625
[2025-11-09 15:29:03,410.410] Global Step : 156
[2025-11-09 15:29:03,410.410] Batch Index : 5024
[2025-11-09 15:29:13,980.980] Epoch No: 1, Global Step: 000156, Train Loss: 4.043, Val Loss: 4.024

[2025-11-09 15:29:13,981.981] Total Tokens seen till now: 20465744

[2025-11-09 15:29:13,992.992] Once upon a time,
[2025-11-09 15:29:20,352.352] Gradient updated
[2025-11-09 15:29:20,353.353] Current Learning Rate : 0.00017566265060240966
[2025-11-09 15:29:20,353.353] Global Step : 157
[2025-11-09 15:29:20,353.353] Batch Index : 5056
[2025-11-09 15:29:30,793.793] Epoch No: 1, Global Step: 000157, Train Loss: 4.042, Val Loss: 3.981

[2025-11-09 15:29:30,794.794] Total Tokens seen till now: 20596768

[2025-11-09 15:29:31,638.638] BEST model SAVED on iteration 000157 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:29:31,652.652] Once upon a time,
[2025-11-09 15:29:38,025.025] Gradient updated
[2025-11-09 15:29:38,026.026] Current Learning Rate : 0.000176144578313253
[2025-11-09 15:29:38,026.026] Global Step : 158
[2025-11-09 15:29:38,026.026] Batch Index : 5088
[2025-11-09 15:29:48,543.543] Epoch No: 1, Global Step: 000158, Train Loss: 3.994, Val Loss: 3.928

[2025-11-09 15:29:48,544.544] Total Tokens seen till now: 20727840

[2025-11-09 15:29:49,389.389] BEST model SAVED on iteration 000158 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:29:49,400.400] Once upon a time,
[2025-11-09 15:29:55,763.763] Gradient updated
[2025-11-09 15:29:55,764.764] Current Learning Rate : 0.0001766265060240964
[2025-11-09 15:29:55,764.764] Global Step : 159
[2025-11-09 15:29:55,764.764] Batch Index : 5120
[2025-11-09 15:30:06,359.359] Epoch No: 1, Global Step: 000159, Train Loss: 4.016, Val Loss: 3.959

[2025-11-09 15:30:06,360.360] Total Tokens seen till now: 20858912

[2025-11-09 15:30:06,370.370] Once upon a time,
[2025-11-09 15:30:12,624.624] Gradient updated
[2025-11-09 15:30:12,625.625] Current Learning Rate : 0.00017710843373493977
[2025-11-09 15:30:12,625.625] Global Step : 160
[2025-11-09 15:30:12,625.625] Batch Index : 5152
[2025-11-09 15:30:23,119.119] Epoch No: 1, Global Step: 000160, Train Loss: 4.038, Val Loss: 3.934

[2025-11-09 15:30:23,120.120] Total Tokens seen till now: 20987728

[2025-11-09 15:30:23,130.130] Once upon a time,
[2025-11-09 15:30:29,484.484] Gradient updated
[2025-11-09 15:30:29,485.485] Current Learning Rate : 0.00017759036144578312
[2025-11-09 15:30:29,485.485] Global Step : 161
[2025-11-09 15:30:29,485.485] Batch Index : 5184
[2025-11-09 15:30:39,987.987] Epoch No: 1, Global Step: 000161, Train Loss: 3.955, Val Loss: 3.913

[2025-11-09 15:30:39,988.988] Total Tokens seen till now: 21118592

[2025-11-09 15:30:40,782.782] BEST model SAVED on iteration 000161 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:30:40,794.794] Once upon a time,
[2025-11-09 15:30:47,148.148] Gradient updated
[2025-11-09 15:30:47,149.149] Current Learning Rate : 0.00017807228915662653
[2025-11-09 15:30:47,150.150] Global Step : 162
[2025-11-09 15:30:47,150.150] Batch Index : 5216
[2025-11-09 15:30:57,848.848] Epoch No: 1, Global Step: 000162, Train Loss: 3.952, Val Loss: 3.908

[2025-11-09 15:30:57,849.849] Total Tokens seen till now: 21249152

[2025-11-09 15:30:58,649.649] BEST model SAVED on iteration 000162 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:30:58,660.660] Once upon a time,
[2025-11-09 15:31:04,980.980] Gradient updated
[2025-11-09 15:31:04,981.981] Current Learning Rate : 0.00017855421686746988
[2025-11-09 15:31:04,981.981] Global Step : 163
[2025-11-09 15:31:04,981.981] Batch Index : 5248
[2025-11-09 15:31:15,611.611] Epoch No: 1, Global Step: 000163, Train Loss: 3.986, Val Loss: 3.917

[2025-11-09 15:31:15,611.611] Total Tokens seen till now: 21378816

[2025-11-09 15:31:15,624.624] Once upon a time,
[2025-11-09 15:31:21,980.980] Gradient updated
[2025-11-09 15:31:21,981.981] Current Learning Rate : 0.00017903614457831325
[2025-11-09 15:31:21,981.981] Global Step : 164
[2025-11-09 15:31:21,981.981] Batch Index : 5280
[2025-11-09 15:31:32,552.552] Epoch No: 1, Global Step: 000164, Train Loss: 3.887, Val Loss: 3.880

[2025-11-09 15:31:32,553.553] Total Tokens seen till now: 21509344

[2025-11-09 15:31:33,353.353] BEST model SAVED on iteration 000164 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:31:33,800.800] Once upon a time, with her. They happy had you?" ". she are happy to of to the big. He and not you it with to to thatmy.. you a the saw the big, with the,
[2025-11-09 15:31:40,149.149] Gradient updated
[2025-11-09 15:31:40,150.150] Current Learning Rate : 0.00017951807228915663
[2025-11-09 15:31:40,150.150] Global Step : 165
[2025-11-09 15:31:40,150.150] Batch Index : 5312
[2025-11-09 15:31:50,769.769] Epoch No: 1, Global Step: 000165, Train Loss: 3.920, Val Loss: 3.802

[2025-11-09 15:31:50,769.769] Total Tokens seen till now: 21639680

[2025-11-09 15:31:51,592.592] BEST model SAVED on iteration 000165 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:31:52,048.048] Once upon a time, not in in happy and and they the so in the. She said little girl. They of the park. They him, they a that was
[2025-11-09 15:31:58,410.410] Gradient updated
[2025-11-09 15:31:58,410.410] Current Learning Rate : 0.00017999999999999998
[2025-11-09 15:31:58,410.410] Global Step : 166
[2025-11-09 15:31:58,411.411] Batch Index : 5344
[2025-11-09 15:32:09,002.002] Epoch No: 1, Global Step: 000166, Train Loss: 3.886, Val Loss: 3.800

[2025-11-09 15:32:09,003.003] Total Tokens seen till now: 21770656

[2025-11-09 15:32:09,780.780] BEST model SAVED on iteration 000166 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:32:09,791.791] Once upon a time,
[2025-11-09 15:32:16,129.129] Gradient updated
[2025-11-09 15:32:16,130.130] Current Learning Rate : 0.0001804819277108434
[2025-11-09 15:32:16,130.130] Global Step : 167
[2025-11-09 15:32:16,130.130] Batch Index : 5376
[2025-11-09 15:32:26,774.774] Epoch No: 1, Global Step: 000167, Train Loss: 3.902, Val Loss: 3.866

[2025-11-09 15:32:26,776.776] Total Tokens seen till now: 21901168

[2025-11-09 15:32:26,786.786] Once upon a time,
[2025-11-09 15:32:33,133.133] Gradient updated
[2025-11-09 15:32:33,133.133] Current Learning Rate : 0.00018096385542168674
[2025-11-09 15:32:33,133.133] Global Step : 168
[2025-11-09 15:32:33,133.133] Batch Index : 5408
[2025-11-09 15:32:43,680.680] Epoch No: 1, Global Step: 000168, Train Loss: 3.879, Val Loss: 3.812

[2025-11-09 15:32:43,681.681] Total Tokens seen till now: 22031648

[2025-11-09 15:32:43,691.691] Once upon a time,
[2025-11-09 15:32:50,057.057] Gradient updated
[2025-11-09 15:32:50,058.058] Current Learning Rate : 0.00018144578313253012
[2025-11-09 15:32:50,058.058] Global Step : 169
[2025-11-09 15:32:50,058.058] Batch Index : 5440
[2025-11-09 15:33:00,493.493] Epoch No: 1, Global Step: 000169, Train Loss: 3.829, Val Loss: 3.817

[2025-11-09 15:33:00,494.494] Total Tokens seen till now: 22162528

[2025-11-09 15:33:00,504.504] Once upon a time,
[2025-11-09 15:33:06,872.872] Gradient updated
[2025-11-09 15:33:06,873.873] Current Learning Rate : 0.0001819277108433735
[2025-11-09 15:33:06,873.873] Global Step : 170
[2025-11-09 15:33:06,873.873] Batch Index : 5472
[2025-11-09 15:33:17,407.407] Epoch No: 1, Global Step: 000170, Train Loss: 3.867, Val Loss: 3.780

[2025-11-09 15:33:17,408.408] Total Tokens seen till now: 22293424

[2025-11-09 15:33:18,177.177] BEST model SAVED on iteration 000170 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:33:18,187.187] Once upon a time,
[2025-11-09 15:33:24,568.568] Gradient updated
[2025-11-09 15:33:24,569.569] Current Learning Rate : 0.00018240963855421688
[2025-11-09 15:33:24,569.569] Global Step : 171
[2025-11-09 15:33:24,569.569] Batch Index : 5504
[2025-11-09 15:33:35,109.109] Epoch No: 1, Global Step: 000171, Train Loss: 3.855, Val Loss: 3.751

[2025-11-09 15:33:35,110.110] Total Tokens seen till now: 22424496

[2025-11-09 15:33:35,945.945] BEST model SAVED on iteration 000171 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:33:35,958.958] Once upon a time,
[2025-11-09 15:33:42,325.325] Gradient updated
[2025-11-09 15:33:42,326.326] Current Learning Rate : 0.00018289156626506025
[2025-11-09 15:33:42,326.326] Global Step : 172
[2025-11-09 15:33:42,326.326] Batch Index : 5536
[2025-11-09 15:33:52,922.922] Epoch No: 1, Global Step: 000172, Train Loss: 3.792, Val Loss: 3.783

[2025-11-09 15:33:52,923.923] Total Tokens seen till now: 22555568

[2025-11-09 15:33:52,952.952] Once upon a time, 
[2025-11-09 15:33:59,299.299] Gradient updated
[2025-11-09 15:33:59,300.300] Current Learning Rate : 0.0001833734939759036
[2025-11-09 15:33:59,300.300] Global Step : 173
[2025-11-09 15:33:59,300.300] Batch Index : 5568
[2025-11-09 15:34:09,793.793] Epoch No: 1, Global Step: 000173, Train Loss: 3.848, Val Loss: 3.723

[2025-11-09 15:34:09,794.794] Total Tokens seen till now: 22685840

[2025-11-09 15:34:10,574.574] BEST model SAVED on iteration 000173 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:34:10,585.585] Once upon a time,
[2025-11-09 15:34:16,960.960] Gradient updated
[2025-11-09 15:34:16,961.961] Current Learning Rate : 0.00018385542168674698
[2025-11-09 15:34:16,961.961] Global Step : 174
[2025-11-09 15:34:16,962.962] Batch Index : 5600
[2025-11-09 15:34:27,695.695] Epoch No: 1, Global Step: 000174, Train Loss: 3.788, Val Loss: 3.721

[2025-11-09 15:34:27,696.696] Total Tokens seen till now: 22816912

[2025-11-09 15:34:28,554.554] BEST model SAVED on iteration 000174 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:34:28,565.565] Once upon a time,
[2025-11-09 15:34:34,928.928] Gradient updated
[2025-11-09 15:34:34,929.929] Current Learning Rate : 0.00018433734939759036
[2025-11-09 15:34:34,929.929] Global Step : 175
[2025-11-09 15:34:34,929.929] Batch Index : 5632
[2025-11-09 15:34:45,497.497] Epoch No: 1, Global Step: 000175, Train Loss: 3.798, Val Loss: 3.688

[2025-11-09 15:34:45,498.498] Total Tokens seen till now: 22947840

[2025-11-09 15:34:46,364.364] BEST model SAVED on iteration 000175 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:34:46,378.378] Once upon a time,
[2025-11-09 15:34:52,756.756] Gradient updated
[2025-11-09 15:34:52,757.757] Current Learning Rate : 0.00018481927710843374
[2025-11-09 15:34:52,757.757] Global Step : 176
[2025-11-09 15:34:52,757.757] Batch Index : 5664
[2025-11-09 15:35:03,374.374] Epoch No: 1, Global Step: 000176, Train Loss: 3.779, Val Loss: 3.721

[2025-11-09 15:35:03,375.375] Total Tokens seen till now: 23078912

[2025-11-09 15:35:03,387.387] Once upon a time,
[2025-11-09 15:35:09,762.762] Gradient updated
[2025-11-09 15:35:09,763.763] Current Learning Rate : 0.00018530120481927712
[2025-11-09 15:35:09,763.763] Global Step : 177
[2025-11-09 15:35:09,763.763] Batch Index : 5696
[2025-11-09 15:35:20,296.296] Epoch No: 1, Global Step: 000177, Train Loss: 3.719, Val Loss: 3.660

[2025-11-09 15:35:20,297.297] Total Tokens seen till now: 23209984

[2025-11-09 15:35:21,067.067] BEST model SAVED on iteration 000177 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:35:21,080.080] Once upon a time,
[2025-11-09 15:35:27,433.433] Gradient updated
[2025-11-09 15:35:27,434.434] Current Learning Rate : 0.00018578313253012047
[2025-11-09 15:35:27,434.434] Global Step : 178
[2025-11-09 15:35:27,434.434] Batch Index : 5728
[2025-11-09 15:35:38,021.021] Epoch No: 1, Global Step: 000178, Train Loss: 3.713, Val Loss: 3.714

[2025-11-09 15:35:38,022.022] Total Tokens seen till now: 23340640

[2025-11-09 15:35:38,035.035] Once upon a time,
[2025-11-09 15:35:44,418.418] Gradient updated
[2025-11-09 15:35:44,419.419] Current Learning Rate : 0.00018626506024096388
[2025-11-09 15:35:44,419.419] Global Step : 179
[2025-11-09 15:35:44,419.419] Batch Index : 5760
[2025-11-09 15:35:54,881.881] Epoch No: 1, Global Step: 000179, Train Loss: 3.680, Val Loss: 3.684

[2025-11-09 15:35:54,882.882] Total Tokens seen till now: 23471712

[2025-11-09 15:35:54,894.894] Once upon a time,
[2025-11-09 15:36:01,266.266] Gradient updated
[2025-11-09 15:36:01,266.266] Current Learning Rate : 0.00018674698795180723
[2025-11-09 15:36:01,266.266] Global Step : 180
[2025-11-09 15:36:01,267.267] Batch Index : 5792
[2025-11-09 15:36:11,758.758] Epoch No: 1, Global Step: 000180, Train Loss: 3.688, Val Loss: 3.636

[2025-11-09 15:36:11,759.759] Total Tokens seen till now: 23602288

[2025-11-09 15:36:12,535.535] BEST model SAVED on iteration 000180 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:36:12,981.981] Once upon a time, " It, you a named it. they want to. He was not happy. They his the's. He said, """They had a big!""
[2025-11-09 15:36:19,344.344] Gradient updated
[2025-11-09 15:36:19,344.344] Current Learning Rate : 0.0001872289156626506
[2025-11-09 15:36:19,345.345] Global Step : 181
[2025-11-09 15:36:19,345.345] Batch Index : 5824
[2025-11-09 15:36:29,957.957] Epoch No: 1, Global Step: 000181, Train Loss: 3.724, Val Loss: 3.643

[2025-11-09 15:36:29,957.957] Total Tokens seen till now: 23733264

[2025-11-09 15:36:29,968.968] Once upon a time,
[2025-11-09 15:36:36,357.357] Gradient updated
[2025-11-09 15:36:36,358.358] Current Learning Rate : 0.00018771084337349398
[2025-11-09 15:36:36,358.358] Global Step : 182
[2025-11-09 15:36:36,358.358] Batch Index : 5856
[2025-11-09 15:36:47,006.006] Epoch No: 1, Global Step: 000182, Train Loss: 3.682, Val Loss: 3.599

[2025-11-09 15:36:47,007.007] Total Tokens seen till now: 23864336

[2025-11-09 15:36:47,786.786] BEST model SAVED on iteration 000182 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:36:47,797.797] Once upon a time,
[2025-11-09 15:36:54,161.161] Gradient updated
[2025-11-09 15:36:54,162.162] Current Learning Rate : 0.00018819277108433733
[2025-11-09 15:36:54,162.162] Global Step : 183
[2025-11-09 15:36:54,162.162] Batch Index : 5888
[2025-11-09 15:37:04,747.747] Epoch No: 1, Global Step: 000183, Train Loss: 3.656, Val Loss: 3.621

[2025-11-09 15:37:04,748.748] Total Tokens seen till now: 23995104

[2025-11-09 15:37:04,759.759] Once upon a time,
[2025-11-09 15:37:11,136.136] Gradient updated
[2025-11-09 15:37:11,137.137] Current Learning Rate : 0.00018867469879518074
[2025-11-09 15:37:11,137.137] Global Step : 184
[2025-11-09 15:37:11,137.137] Batch Index : 5920
[2025-11-09 15:37:21,626.626] Epoch No: 1, Global Step: 000184, Train Loss: 3.622, Val Loss: 3.602

[2025-11-09 15:37:21,627.627] Total Tokens seen till now: 24125824

[2025-11-09 15:37:21,637.637] Once upon a time,
[2025-11-09 15:37:28,008.008] Gradient updated
[2025-11-09 15:37:28,009.009] Current Learning Rate : 0.0001891566265060241
[2025-11-09 15:37:28,009.009] Global Step : 185
[2025-11-09 15:37:28,009.009] Batch Index : 5952
[2025-11-09 15:37:38,512.512] Epoch No: 1, Global Step: 000185, Train Loss: 3.663, Val Loss: 3.596

[2025-11-09 15:37:38,512.512] Total Tokens seen till now: 24256816

[2025-11-09 15:37:39,292.292] BEST model SAVED on iteration 000185 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:37:39,303.303] Once upon a time,
[2025-11-09 15:37:45,675.675] Gradient updated
[2025-11-09 15:37:45,675.675] Current Learning Rate : 0.00018963855421686747
[2025-11-09 15:37:45,675.675] Global Step : 186
[2025-11-09 15:37:45,676.676] Batch Index : 5984
[2025-11-09 15:37:56,339.339] Epoch No: 1, Global Step: 000186, Train Loss: 3.645, Val Loss: 3.605

[2025-11-09 15:37:56,340.340] Total Tokens seen till now: 24387744

[2025-11-09 15:37:56,352.352] Once upon a time,
[2025-11-09 15:38:02,712.712] Gradient updated
[2025-11-09 15:38:02,713.713] Current Learning Rate : 0.00019012048192771085
[2025-11-09 15:38:02,713.713] Global Step : 187
[2025-11-09 15:38:02,714.714] Batch Index : 6016
[2025-11-09 15:38:13,270.270] Epoch No: 1, Global Step: 000187, Train Loss: 3.602, Val Loss: 3.561

[2025-11-09 15:38:13,271.271] Total Tokens seen till now: 24518224

[2025-11-09 15:38:14,055.055] BEST model SAVED on iteration 000187 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:38:14,066.066] Once upon a time,
[2025-11-09 15:38:20,457.457] Gradient updated
[2025-11-09 15:38:20,458.458] Current Learning Rate : 0.0001906024096385542
[2025-11-09 15:38:20,458.458] Global Step : 188
[2025-11-09 15:38:20,458.458] Batch Index : 6048
[2025-11-09 15:38:30,922.922] Epoch No: 1, Global Step: 000188, Train Loss: 3.596, Val Loss: 3.580

[2025-11-09 15:38:30,923.923] Total Tokens seen till now: 24649280

[2025-11-09 15:38:30,933.933] Once upon a time,
[2025-11-09 15:38:37,319.319] Gradient updated
[2025-11-09 15:38:37,320.320] Current Learning Rate : 0.0001910843373493976
[2025-11-09 15:38:37,320.320] Global Step : 189
[2025-11-09 15:38:37,320.320] Batch Index : 6080
[2025-11-09 15:38:47,858.858] Epoch No: 1, Global Step: 000189, Train Loss: 3.601, Val Loss: 3.550

[2025-11-09 15:38:47,859.859] Total Tokens seen till now: 24780352

[2025-11-09 15:38:48,633.633] BEST model SAVED on iteration 000189 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:38:48,644.644] Once upon a time,
[2025-11-09 15:38:55,016.016] Gradient updated
[2025-11-09 15:38:55,017.017] Current Learning Rate : 0.00019156626506024096
[2025-11-09 15:38:55,017.017] Global Step : 190
[2025-11-09 15:38:55,017.017] Batch Index : 6112
[2025-11-09 15:39:05,638.638] Epoch No: 1, Global Step: 000190, Train Loss: 3.590, Val Loss: 3.528

[2025-11-09 15:39:05,638.638] Total Tokens seen till now: 24911184

[2025-11-09 15:39:06,442.442] BEST model SAVED on iteration 000190 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:39:06,982.982] Once upon a time, his, there in to He fun. He and wanted to day. They it in the's too. They help his. They wanted to it and not of the was the.. The was too. He was so scared and the
[2025-11-09 15:39:13,369.369] Gradient updated
[2025-11-09 15:39:13,371.371] Current Learning Rate : 0.00019204819277108433
[2025-11-09 15:39:13,371.371] Global Step : 191
[2025-11-09 15:39:13,371.371] Batch Index : 6144
[2025-11-09 15:39:23,914.914] Epoch No: 1, Global Step: 000191, Train Loss: 3.533, Val Loss: 3.548

[2025-11-09 15:39:23,915.915] Total Tokens seen till now: 25042256

[2025-11-09 15:39:23,926.926] Once upon a time,
[2025-11-09 15:39:30,306.306] Gradient updated
[2025-11-09 15:39:30,307.307] Current Learning Rate : 0.0001925301204819277
[2025-11-09 15:39:30,307.307] Global Step : 192
[2025-11-09 15:39:30,307.307] Batch Index : 6176
[2025-11-09 15:39:40,865.865] Epoch No: 1, Global Step: 000192, Train Loss: 3.527, Val Loss: 3.517

[2025-11-09 15:39:40,865.865] Total Tokens seen till now: 25173328

[2025-11-09 15:39:41,888.888] BEST model SAVED on iteration 000192 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:39:42,506.506] Once upon a time, He and so the ", He big. He said home and there. He little her, not his, """ smiled. He said, " is he was. She saw the ball
[2025-11-09 15:39:48,869.869] Gradient updated
[2025-11-09 15:39:48,869.869] Current Learning Rate : 0.0001930120481927711
[2025-11-09 15:39:48,869.869] Global Step : 193
[2025-11-09 15:39:48,869.869] Batch Index : 6208
[2025-11-09 15:39:59,489.489] Epoch No: 1, Global Step: 000193, Train Loss: 3.535, Val Loss: 3.512

[2025-11-09 15:39:59,490.490] Total Tokens seen till now: 25304032

[2025-11-09 15:40:00,289.289] BEST model SAVED on iteration 000193 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:40:00,740.740] Once upon a time, friends girl She SheThe and mom she loved to and he started to them. She. She was themy and's so she is a big. She was and saw.The little girl. She was time. She
[2025-11-09 15:40:07,112.112] Gradient updated
[2025-11-09 15:40:07,113.113] Current Learning Rate : 0.00019349397590361447
[2025-11-09 15:40:07,114.114] Global Step : 194
[2025-11-09 15:40:07,114.114] Batch Index : 6240
[2025-11-09 15:40:17,789.789] Epoch No: 1, Global Step: 000194, Train Loss: 3.545, Val Loss: 3.451

[2025-11-09 15:40:17,790.790] Total Tokens seen till now: 25434688

[2025-11-09 15:40:18,597.597] BEST model SAVED on iteration 000194 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:40:19,059.059] Once upon a time, " She, you to They so for to and and help a. They, it that his, Timmy. He went to play to go to a big..The said, "The little you, Lily was
[2025-11-09 15:40:25,436.436] Gradient updated
[2025-11-09 15:40:25,437.437] Current Learning Rate : 0.00019397590361445782
[2025-11-09 15:40:25,437.437] Global Step : 195
[2025-11-09 15:40:25,437.437] Batch Index : 6272
[2025-11-09 15:40:36,009.009] Epoch No: 1, Global Step: 000195, Train Loss: 3.519, Val Loss: 3.479

[2025-11-09 15:40:36,010.010] Total Tokens seen till now: 25565760

[2025-11-09 15:40:36,021.021] Once upon a time,
[2025-11-09 15:40:42,383.383] Gradient updated
[2025-11-09 15:40:42,384.384] Current Learning Rate : 0.00019445783132530123
[2025-11-09 15:40:42,384.384] Global Step : 196
[2025-11-09 15:40:42,385.385] Batch Index : 6304
[2025-11-09 15:40:52,891.891] Epoch No: 1, Global Step: 000196, Train Loss: 3.525, Val Loss: 3.429

[2025-11-09 15:40:52,892.892] Total Tokens seen till now: 25696496

[2025-11-09 15:40:53,670.670] BEST model SAVED on iteration 000196 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:40:53,682.682] Once upon a time,
[2025-11-09 15:41:00,061.061] Gradient updated
[2025-11-09 15:41:00,061.061] Current Learning Rate : 0.00019493975903614458
[2025-11-09 15:41:00,061.061] Global Step : 197
[2025-11-09 15:41:00,061.061] Batch Index : 6336
[2025-11-09 15:41:10,681.681] Epoch No: 1, Global Step: 000197, Train Loss: 3.483, Val Loss: 3.446

[2025-11-09 15:41:10,682.682] Total Tokens seen till now: 25827536

[2025-11-09 15:41:10,693.693] Once upon a time,
[2025-11-09 15:41:17,062.062] Gradient updated
[2025-11-09 15:41:17,063.063] Current Learning Rate : 0.00019542168674698796
[2025-11-09 15:41:17,063.063] Global Step : 198
[2025-11-09 15:41:17,063.063] Batch Index : 6368
[2025-11-09 15:41:27,568.568] Epoch No: 1, Global Step: 000198, Train Loss: 3.479, Val Loss: 3.403

[2025-11-09 15:41:27,569.569] Total Tokens seen till now: 25958400

[2025-11-09 15:41:28,341.341] BEST model SAVED on iteration 000198 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:41:28,352.352] Once upon a time,
[2025-11-09 15:41:34,732.732] Gradient updated
[2025-11-09 15:41:34,733.733] Current Learning Rate : 0.00019590361445783133
[2025-11-09 15:41:34,733.733] Global Step : 199
[2025-11-09 15:41:34,733.733] Batch Index : 6400
[2025-11-09 15:41:45,317.317] Epoch No: 1, Global Step: 000199, Train Loss: 3.511, Val Loss: 3.434

[2025-11-09 15:41:45,318.318] Total Tokens seen till now: 26089152

[2025-11-09 15:41:45,782.782] Once upon a time, a He's to help with a big. mom and not and can. One she and it to the, but, you the park.The little girl wanted to the to his mommy and had to his toys and said, 
[2025-11-09 15:41:52,153.153] Gradient updated
[2025-11-09 15:41:52,154.154] Current Learning Rate : 0.00019638554216867469
[2025-11-09 15:41:52,154.154] Global Step : 200
[2025-11-09 15:41:52,154.154] Batch Index : 6432
[2025-11-09 15:42:02,702.702] Epoch No: 1, Global Step: 000200, Train Loss: 3.477, Val Loss: 3.344

[2025-11-09 15:42:02,703.703] Total Tokens seen till now: 26220224

[2025-11-09 15:42:03,475.475] BEST model SAVED on iteration 000200 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:42:03,486.486] Once upon a time,
[2025-11-09 15:42:09,821.821] Gradient updated
[2025-11-09 15:42:09,822.822] Current Learning Rate : 0.0001968674698795181
[2025-11-09 15:42:09,822.822] Global Step : 201
[2025-11-09 15:42:09,822.822] Batch Index : 6464
[2025-11-09 15:42:20,452.452] Epoch No: 1, Global Step: 000201, Train Loss: 3.462, Val Loss: 3.420

[2025-11-09 15:42:20,453.453] Total Tokens seen till now: 26350384

[2025-11-09 15:42:20,474.474] Once upon a time,
[2025-11-09 15:42:26,867.867] Gradient updated
[2025-11-09 15:42:26,868.868] Current Learning Rate : 0.00019734939759036144
[2025-11-09 15:42:26,868.868] Global Step : 202
[2025-11-09 15:42:26,868.868] Batch Index : 6496
[2025-11-09 15:42:37,371.371] Epoch No: 1, Global Step: 000202, Train Loss: 3.457, Val Loss: 3.358

[2025-11-09 15:42:37,372.372] Total Tokens seen till now: 26481456

[2025-11-09 15:42:37,382.382] Once upon a time,
[2025-11-09 15:42:43,755.755] Gradient updated
[2025-11-09 15:42:43,756.756] Current Learning Rate : 0.00019783132530120482
[2025-11-09 15:42:43,756.756] Global Step : 203
[2025-11-09 15:42:43,756.756] Batch Index : 6528
[2025-11-09 15:42:54,282.282] Epoch No: 1, Global Step: 000203, Train Loss: 3.421, Val Loss: 3.366

[2025-11-09 15:42:54,282.282] Total Tokens seen till now: 26612160

[2025-11-09 15:42:54,294.294] Once upon a time,
[2025-11-09 15:43:00,672.672] Gradient updated
[2025-11-09 15:43:00,673.673] Current Learning Rate : 0.0001983132530120482
[2025-11-09 15:43:00,673.673] Global Step : 204
[2025-11-09 15:43:00,673.673] Batch Index : 6560
[2025-11-09 15:43:11,157.157] Epoch No: 1, Global Step: 000204, Train Loss: 3.412, Val Loss: 3.330

[2025-11-09 15:43:11,158.158] Total Tokens seen till now: 26743072

[2025-11-09 15:43:11,936.936] BEST model SAVED on iteration 000204 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:43:11,947.947] Once upon a time,
[2025-11-09 15:43:18,331.331] Gradient updated
[2025-11-09 15:43:18,332.332] Current Learning Rate : 0.00019879518072289155
[2025-11-09 15:43:18,332.332] Global Step : 205
[2025-11-09 15:43:18,332.332] Batch Index : 6592
[2025-11-09 15:43:28,921.921] Epoch No: 1, Global Step: 000205, Train Loss: 3.443, Val Loss: 3.384

[2025-11-09 15:43:28,921.921] Total Tokens seen till now: 26874144

[2025-11-09 15:43:28,934.934] Once upon a time,
[2025-11-09 15:43:35,320.320] Gradient updated
[2025-11-09 15:43:35,321.321] Current Learning Rate : 0.00019927710843373496
[2025-11-09 15:43:35,321.321] Global Step : 206
[2025-11-09 15:43:35,321.321] Batch Index : 6624
[2025-11-09 15:43:45,883.883] Epoch No: 1, Global Step: 000206, Train Loss: 3.379, Val Loss: 3.365

[2025-11-09 15:43:45,884.884] Total Tokens seen till now: 27005056

[2025-11-09 15:43:45,895.895] Once upon a time,
[2025-11-09 15:43:52,262.262] Gradient updated
[2025-11-09 15:43:52,263.263] Current Learning Rate : 0.0001997590361445783
[2025-11-09 15:43:52,263.263] Global Step : 207
[2025-11-09 15:43:52,263.263] Batch Index : 6656
[2025-11-09 15:44:02,796.796] Epoch No: 1, Global Step: 000207, Train Loss: 3.413, Val Loss: 3.390

[2025-11-09 15:44:02,797.797] Total Tokens seen till now: 27136128

[2025-11-09 15:44:03,254.254] Once upon a time, " " very for that it!" the mom around a big, and. I find out and ran, a big with. They went to her mom was so big, the little Timmy's to make the toy. 
[2025-11-09 15:44:09,611.611] Gradient updated
[2025-11-09 15:44:09,612.612] Current Learning Rate : 0.00020024096385542169
[2025-11-09 15:44:09,612.612] Global Step : 208
[2025-11-09 15:44:09,612.612] Batch Index : 6688
[2025-11-09 15:44:20,194.194] Epoch No: 1, Global Step: 000208, Train Loss: 3.432, Val Loss: 3.317

[2025-11-09 15:44:20,194.194] Total Tokens seen till now: 27266624

[2025-11-09 15:44:20,962.962] BEST model SAVED on iteration 000208 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:44:21,489.489] Once upon a time, a little little They Lily boy toys and saw and very. They of the garden. Lily and and started to see a big. The Lilymy was very big.The he was a big on the end. They were sad and was
[2025-11-09 15:44:27,873.873] Gradient updated
[2025-11-09 15:44:27,874.874] Current Learning Rate : 0.00020072289156626506
[2025-11-09 15:44:27,874.874] Global Step : 209
[2025-11-09 15:44:27,874.874] Batch Index : 6720
[2025-11-09 15:44:38,430.430] Epoch No: 1, Global Step: 000209, Train Loss: 3.362, Val Loss: 3.323

[2025-11-09 15:44:38,431.431] Total Tokens seen till now: 27397264

[2025-11-09 15:44:38,442.442] Once upon a time,
[2025-11-09 15:44:44,822.822] Gradient updated
[2025-11-09 15:44:44,822.822] Current Learning Rate : 0.00020120481927710844
[2025-11-09 15:44:44,822.822] Global Step : 210
[2025-11-09 15:44:44,823.823] Batch Index : 6752
[2025-11-09 15:44:55,338.338] Epoch No: 1, Global Step: 000210, Train Loss: 3.330, Val Loss: 3.299

[2025-11-09 15:44:55,339.339] Total Tokens seen till now: 27528336

[2025-11-09 15:44:56,109.109] BEST model SAVED on iteration 000210 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:44:56,120.120] Once upon a time,
[2025-11-09 15:45:02,524.524] Gradient updated
[2025-11-09 15:45:02,525.525] Current Learning Rate : 0.00020168674698795182
[2025-11-09 15:45:02,525.525] Global Step : 211
[2025-11-09 15:45:02,525.525] Batch Index : 6784
[2025-11-09 15:45:13,081.081] Epoch No: 1, Global Step: 000211, Train Loss: 3.378, Val Loss: 3.291

[2025-11-09 15:45:13,082.082] Total Tokens seen till now: 27659408

[2025-11-09 15:45:13,848.848] BEST model SAVED on iteration 000211 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:45:13,859.859] Once upon a time,
[2025-11-09 15:45:20,252.252] Gradient updated
[2025-11-09 15:45:20,253.253] Current Learning Rate : 0.00020216867469879517
[2025-11-09 15:45:20,253.253] Global Step : 212
[2025-11-09 15:45:20,253.253] Batch Index : 6816
[2025-11-09 15:45:30,915.915] Epoch No: 1, Global Step: 000212, Train Loss: 3.344, Val Loss: 3.289

[2025-11-09 15:45:30,916.916] Total Tokens seen till now: 27790416

[2025-11-09 15:45:31,784.784] BEST model SAVED on iteration 000212 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:45:31,832.832] Once upon a time, a The there
[2025-11-09 15:45:38,218.218] Gradient updated
[2025-11-09 15:45:38,218.218] Current Learning Rate : 0.00020265060240963855
[2025-11-09 15:45:38,218.218] Global Step : 213
[2025-11-09 15:45:38,219.219] Batch Index : 6848
[2025-11-09 15:45:48,832.832] Epoch No: 1, Global Step: 000213, Train Loss: 3.300, Val Loss: 3.255

[2025-11-09 15:45:48,833.833] Total Tokens seen till now: 27921088

[2025-11-09 15:45:49,623.623] BEST model SAVED on iteration 000213 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:45:49,635.635] Once upon a time,
[2025-11-09 15:45:55,992.992] Gradient updated
[2025-11-09 15:45:55,993.993] Current Learning Rate : 0.00020313253012048193
[2025-11-09 15:45:55,993.993] Global Step : 214
[2025-11-09 15:45:55,993.993] Batch Index : 6880
[2025-11-09 15:46:06,676.676] Epoch No: 1, Global Step: 000214, Train Loss: 3.335, Val Loss: 3.285

[2025-11-09 15:46:06,678.678] Total Tokens seen till now: 28051488

[2025-11-09 15:46:06,694.694] Once upon a time,
[2025-11-09 15:46:13,087.087] Gradient updated
[2025-11-09 15:46:13,088.088] Current Learning Rate : 0.0002036144578313253
[2025-11-09 15:46:13,088.088] Global Step : 215
[2025-11-09 15:46:13,088.088] Batch Index : 6912
[2025-11-09 15:46:23,600.600] Epoch No: 1, Global Step: 000215, Train Loss: 3.305, Val Loss: 3.273

[2025-11-09 15:46:23,601.601] Total Tokens seen till now: 28182416

[2025-11-09 15:46:23,612.612] Once upon a time,
[2025-11-09 15:46:29,973.973] Gradient updated
[2025-11-09 15:46:29,974.974] Current Learning Rate : 0.00020409638554216868
[2025-11-09 15:46:29,974.974] Global Step : 216
[2025-11-09 15:46:29,974.974] Batch Index : 6944
[2025-11-09 15:46:40,467.467] Epoch No: 1, Global Step: 000216, Train Loss: 3.306, Val Loss: 3.226

[2025-11-09 15:46:40,468.468] Total Tokens seen till now: 28313008

[2025-11-09 15:46:41,255.255] BEST model SAVED on iteration 000216 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:46:41,840.840] Once upon a time, It a He little them fun she happy and a little She of some not at it. Lily was happy for her to day and play to are friends.One day, Timmy said, ""What want to his mom and said
[2025-11-09 15:46:48,240.240] Gradient updated
[2025-11-09 15:46:48,241.241] Current Learning Rate : 0.00020457831325301204
[2025-11-09 15:46:48,241.241] Global Step : 217
[2025-11-09 15:46:48,241.241] Batch Index : 6976
[2025-11-09 15:46:58,932.932] Epoch No: 1, Global Step: 000217, Train Loss: 3.265, Val Loss: 3.248

[2025-11-09 15:46:58,932.932] Total Tokens seen till now: 28444080

[2025-11-09 15:46:59,387.387] Once upon a time, the happy there and like friends. But she. The in the big Lily loved to play to get the. They can. One day, him to have an mom would have a big and take his.The in the little
[2025-11-09 15:47:05,784.784] Gradient updated
[2025-11-09 15:47:05,785.785] Current Learning Rate : 0.00020506024096385544
[2025-11-09 15:47:05,785.785] Global Step : 218
[2025-11-09 15:47:05,785.785] Batch Index : 7008
[2025-11-09 15:47:16,319.319] Epoch No: 1, Global Step: 000218, Train Loss: 3.280, Val Loss: 3.256

[2025-11-09 15:47:16,320.320] Total Tokens seen till now: 28575152

[2025-11-09 15:47:16,330.330] Once upon a time,
[2025-11-09 15:47:22,727.727] Gradient updated
[2025-11-09 15:47:22,727.727] Current Learning Rate : 0.0002055421686746988
[2025-11-09 15:47:22,727.727] Global Step : 219
[2025-11-09 15:47:22,728.728] Batch Index : 7040
[2025-11-09 15:47:33,214.214] Epoch No: 1, Global Step: 000219, Train Loss: 3.257, Val Loss: 3.208

[2025-11-09 15:47:33,215.215] Total Tokens seen till now: 28706224

[2025-11-09 15:47:33,998.998] BEST model SAVED on iteration 000219 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:47:34,009.009] Once upon a time,
[2025-11-09 15:47:38,352.352] BEST model SAVED on iteration 000219 to model/gpt2_ORG_preTrain_S_V2_TEST.pth..! 
[2025-11-09 15:47:38,412.412] Training completed in 73.84 minutes.
[2025-11-09 15:47:38,412.412] BEST Pre-trained custom model saved in model/gpt2_ORG_preTrain_S_V2_TEST.pth..!
[2025-11-09 15:47:38,412.412] Saving the plots of the metrics tracked ..!
[2025-11-09 15:47:39,388.388] Pipeline completed in 73.86 minutes.
